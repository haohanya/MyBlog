{"posts":[{"title":"Activiti7 工作流引擎","content":"Activiti7工作流引擎什么是工作流工作流介绍工作流(Workflow)，就是通过计算机对业务流程自动化执行管理。它主要解决的是“使在多个参与者之间按照某种预定义的规则自动进行传递文档、信息或任务的过程，从而实现某个预期的业务目标，或者促使此目标的实现”。工作流系统一个软件系统中具有工作流的功能，我们把它称为工作流系统，一个系统中工作流的功能是什么？就是对系统的业务流程进行自动化管理，所以工作流是建立在业务流程的基础上，所以一个软件的系统核心根本上还是系统的业务流程，工作流只是协助进行业务流程管理。即使没有工作流业务系统也可以开发运行，只不过有了工作流可以更好的管理业务流程，提高系统的可扩展性。适用行业消费品行业，制造业，电信服务业，银证险等金融服务业，物流服务业，物业服务业，物业管理，大中型进出口贸易公司，政府事业机构，研究院所及教育服务业等，特别是大的跨国企业和集团公司。具体应用关键业务流程：订单、报价处理、合同审核、客户电话处理、供应链管理等行政管理类:出差申请、加班申请、请假申请、用车申请、各种办公用品申请、购买申请、日报周报等凡是原来手工流转处理的行政表单。人事管理类：员工培训安排、绩效考评、职位变动处理、员工档案信息管理等。财务相关类：付款请求、应收款处理、日常报销处理、出差报销、预算和计划申请等。客户服务类：客户信息管理、客户投诉、请求处理、售后服务管理等。特殊服务类：ISO系列对应流程、质量管理对应流程、产品数据信息管理、贸易公司报关处理、物流公司货物跟踪处理等各种通过表单逐步手工流转完成的任务均可应用工作流软件自动规范地实施。工作流实现方式在没有专门的工作流引擎之前，我们之前为了实现流程控制，通常的做法就是采用状态字段的值来跟踪流程的变化情况。这样不用角色的用户，通过状态字段的取值来决定记录是否显示。针对有权限可以查看的记录，当前用户根据自己的角色来决定审批是否合格的操作。如果合格将状态字段设置一个值，来代表合格；当然如果不合格也需要设置一个值来代表不合格的情况。这是一种最为原始的方式。通过状态字段虽然做到了流程控制，但是当我们的流程发生变更的时候，这种方式所编写的代码也要进行调整。那么有没有专业的方式来实现工作流的管理呢？并且可以做到业务流程变化之后，我们的程序可以不用改变，如果可以实现这样的效果，那么我们的业务系统的适应能力就得到了极大提升。工作流实现原理分析什么是Activiti7Activiti介绍Alfresco软件在2010年5月17日宣布Activiti业务流程管理（BPM）开源项目的正式启动，其首席架构师由业务流程管理BPM的专家TomBaeyens担任，TomBaeyens就是原来jbpm的架构师，而jbpm是一个非常有名的工作流引擎，当然activiti也是一个工作流引擎。Activiti是一个工作流引擎，activiti可以将业务系统中复杂的业务流程抽取出来，使用专门的建模语言（BPMN2.0）进行定义，业务系统按照预先定义的流程进行执行，实现了业务系统的业务流程由activiti进行管理，减少业务系统由于流程变更进行系统升级改造的工作量，从而提高系统的健壮性，同时也减少了系统开发维护成本。官方网站：https://www.activiti.org/目前最新版本：Activiti7.0.0.BetaBPMBPM（BusinessProcessManagement），即业务流程管理，是一种以规范化的构造端到端的卓越业务流程为中心，以持续的提高组织业务绩效为目的系统化方法，常见商业管理教育如EMBA、MBA等均将BPM包含在内。企业流程管理主要是对企业内部改革，改变企业职能管理机构重叠、中间层次多、流程不闭环等，做到机构不重叠、业务不重复，达到缩短流程周期、节约运作资本、提高企业效益的作用。BPM软件BPM软件就是根据企业中业务环境的变化，推进人与人之间、人与系统之间以及系统与系统之间的整合及调整的经营方法与解决方案的IT工具。通常以Internet方式实现信息传递、数据同步、业务监控和企业业务流程的持续升级优化，从而实现跨应用、跨部门、跨合作伙伴与客户的企业运作。通过BPM软件对企业内部及外部的业务流程的整个生命周期进行建模、自动化、管理监控和优化，使企业成本降低，利润得以大幅提升。BPM软件在企业中应用领域广泛，凡是有业务流程的地方都可以BPM软件进行管理，比如企业人事办公管理、采购流程管理、公文审批流程管理、财务管理等。BPMNBPMN（BusinessProcessModelAndNotation）-业务流程模型和符号是由BPMI（BusinessProcessManagementInitiative）开发的一套标准的业务流程建模符号，使用BPMN提供的符号可以创建业务流程。2004年5月发布了BPMN1.0规范.BPMI于2005年9月并入OMG（TheObjectManagementGroup对象管理组织)组织。OMG于2011年1月发布BPMN2.0的最终版本。BPMN是目前被各BPM厂商广泛接受的BPM标准。Activiti就是使用BPMN2.0进行流程建模、流程执行管理，它包括很多的建模符号Event用一个圆圈表示，它是流程中运行过程中发生的事情。活动用圆角矩形表示，一个流程由一个活动或多个活动组成一个bpmn图形的例子：首先当事人发起一个请假单；其次他所在部门的经理对请假单进行审核；然后人事经理进行复核并进行备案；最后请假流程结束。Bpmn图形其实是通过xml表示业务流程，上边的.bpmn文件使用文本编辑器打开：&lt;?xmlversion=&quot;1.0&quot;encoding=&quot;UTF-8&quot;?&gt;&lt;definitionsxmlns=&quot;http://www.omg.org/spec/BPMN/20100524/MODEL&quot;xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;xmlns:xsd=&quot;http://www.w3.org/2001/XMLSchema&quot;xmlns:activiti=&quot;http://activiti.org/bpmn&quot;xmlns:bpmndi=&quot;http://www.omg.org/spec/BPMN/20100524/DI&quot;xmlns:omgdc=&quot;http://www.omg.org/spec/DD/20100524/DC&quot;xmlns:omgdi=&quot;http://www.omg.org/spec/DD/20100524/DI&quot;typeLanguage=&quot;http://www.w3.org/2001/XMLSchema&quot;expressionLanguage=&quot;http://www.w3.org/1999/XPath&quot;targetNamespace=&quot;http://www.activiti.org/test&quot;&gt;&lt;processid=&quot;myProcess&quot;name=&quot;Myprocess&quot;isExecutable=&quot;true&quot;&gt;&lt;startEventid=&quot;startevent1&quot;name=&quot;Start&quot;&gt;&lt;/startEvent&gt;&lt;userTaskid=&quot;usertask1&quot;name=&quot;创建请假单&quot;&gt;&lt;/userTask&gt;&lt;sequenceFlowid=&quot;flow1&quot;sourceRef=&quot;startevent1&quot;targetRef=&quot;usertask1&quot;&gt;&lt;/sequenceFlow&gt;&lt;userTaskid=&quot;usertask2&quot;name=&quot;部门经理审核&quot;&gt;&lt;/userTask&gt;&lt;sequenceFlowid=&quot;flow2&quot;sourceRef=&quot;usertask1&quot;targetRef=&quot;usertask2&quot;&gt;&lt;/sequenceFlow&gt;&lt;userTaskid=&quot;usertask3&quot;name=&quot;人事复核&quot;&gt;&lt;/userTask&gt;&lt;sequenceFlowid=&quot;flow3&quot;sourceRef=&quot;usertask2&quot;targetRef=&quot;usertask3&quot;&gt;&lt;/sequenceFlow&gt;&lt;endEventid=&quot;endevent1&quot;name=&quot;End&quot;&gt;&lt;/endEvent&gt;&lt;sequenceFlowid=&quot;flow4&quot;sourceRef=&quot;usertask3&quot;targetRef=&quot;endevent1&quot;&gt;&lt;/sequenceFlow&gt;&lt;/process&gt;&lt;bpmndi:BPMNDiagramid=&quot;BPMNDiagram_myProcess&quot;&gt;&lt;bpmndi:BPMNPlanebpmnElement=&quot;myProcess&quot;id=&quot;BPMNPlane_myProcess&quot;&gt;&lt;bpmndi:BPMNShapebpmnElement=&quot;startevent1&quot;id=&quot;BPMNShape_startevent1&quot;&gt;&lt;omgdc:Boundsheight=&quot;35.0&quot;width=&quot;35.0&quot;x=&quot;130.0&quot;y=&quot;160.0&quot;&gt;&lt;/omgdc:Bounds&gt;&lt;/bpmndi:BPMNShape&gt;&lt;bpmndi:BPMNShapebpmnElement=&quot;usertask1&quot;id=&quot;BPMNShape_usertask1&quot;&gt;&lt;omgdc:Boundsheight=&quot;55.0&quot;width=&quot;105.0&quot;x=&quot;210.0&quot;y=&quot;150.0&quot;&gt;&lt;/omgdc:Bounds&gt;&lt;/bpmndi:BPMNShape&gt;&lt;bpmndi:BPMNShapebpmnElement=&quot;usertask2&quot;id=&quot;BPMNShape_usertask2&quot;&gt;&lt;omgdc:Boundsheight=&quot;55.0&quot;width=&quot;105.0&quot;x=&quot;360.0&quot;y=&quot;150.0&quot;&gt;&lt;/omgdc:Bounds&gt;&lt;/bpmndi:BPMNShape&gt;&lt;bpmndi:BPMNShapebpmnElement=&quot;usertask3&quot;id=&quot;BPMNShape_usertask3&quot;&gt;&lt;omgdc:Boundsheight=&quot;55.0&quot;width=&quot;105.0&quot;x=&quot;510.0&quot;y=&quot;150.0&quot;&gt;&lt;/omgdc:Bounds&gt;&lt;/bpmndi:BPMNShape&gt;&lt;bpmndi:BPMNShapebpmnElement=&quot;endevent1&quot;id=&quot;BPMNShape_endevent1&quot;&gt;&lt;omgdc:Boundsheight=&quot;35.0&quot;width=&quot;35.0&quot;x=&quot;660.0&quot;y=&quot;160.0&quot;&gt;&lt;/omgdc:Bounds&gt;&lt;/bpmndi:BPMNShape&gt;&lt;bpmndi:BPMNEdgebpmnElement=&quot;flow1&quot;id=&quot;BPMNEdge_flow1&quot;&gt;&lt;omgdi:waypointx=&quot;165.0&quot;y=&quot;177.0&quot;&gt;&lt;/omgdi:waypoint&gt;&lt;omgdi:waypointx=&quot;210.0&quot;y=&quot;177.0&quot;&gt;&lt;/omgdi:waypoint&gt;&lt;/bpmndi:BPMNEdge&gt;&lt;bpmndi:BPMNEdgebpmnElement=&quot;flow2&quot;id=&quot;BPMNEdge_flow2&quot;&gt;&lt;omgdi:waypointx=&quot;315.0&quot;y=&quot;177.0&quot;&gt;&lt;/omgdi:waypoint&gt;&lt;omgdi:waypointx=&quot;360.0&quot;y=&quot;177.0&quot;&gt;&lt;/omgdi:waypoint&gt;&lt;/bpmndi:BPMNEdge&gt;&lt;bpmndi:BPMNEdgebpmnElement=&quot;flow3&quot;id=&quot;BPMNEdge_flow3&quot;&gt;&lt;omgdi:waypointx=&quot;465.0&quot;y=&quot;177.0&quot;&gt;&lt;/omgdi:waypoint&gt;&lt;omgdi:waypointx=&quot;510.0&quot;y=&quot;177.0&quot;&gt;&lt;/omgdi:waypoint&gt;&lt;/bpmndi:BPMNEdge&gt;&lt;bpmndi:BPMNEdgebpmnElement=&quot;flow4&quot;id=&quot;BPMNEdge_flow4&quot;&gt;&lt;omgdi:waypointx=&quot;615.0&quot;y=&quot;177.0&quot;&gt;&lt;/omgdi:waypoint&gt;&lt;omgdi:waypointx=&quot;660.0&quot;y=&quot;177.0&quot;&gt;&lt;/omgdi:waypoint&gt;&lt;/bpmndi:BPMNEdge&gt;&lt;/bpmndi:BPMNPlane&gt;&lt;/bpmndi:BPMNDiagram&gt;&lt;/definitions&gt;Activit如何使用1、部署activitiActiviti是一个工作流引擎（其实就是一堆jar包API），业务系统使用activiti来对系统的业务流程进行自动化管理，为了方便业务系统访问(操作)activiti的接口或功能，通常将activiti环境与业务系统的环境集成在一起。2、流程定义使用activiti流程建模工具(activity-designer)定义业务流程(.bpmn文件)。.bpmn文件就是业务流程定义文件，通过xml定义业务流程。如果使用其它公司开发的工作作引擎一般都提供了可视化的建模工具(ProcessDesigner)用于生成流程定义文件，建模工具操作直观，一般都支持图形化拖拽方式、多窗口的用户界面、丰富的过程图形元素、过程元素拷贝、粘贴、删除等功能。3、流程定义部署向activiti部署业务流程定义（.bpmn文件）。使用activiti提供的api向activiti中部署.bpmn文件（一般情况还需要一块儿部署业务流程的图片.png）4、启动一个流程实例（ProcessInstance）启动一个流程实例表示开始一次业务流程的运行，比如员工请假流程部署完成，如果张三要请假就可以启动一个流程实例，如果李四要请假也启动一个流程实例，两个流程的执行互相不影响，就好比定义一个java类，实例化两个对象一样，部署的流程就好比java类，启动一个流程实例就好比new一个java对象。5、用户查询待办任务(Task)因为现在系统的业务流程已经交给activiti管理，通过activiti就可以查询当前流程执行到哪了，当前用户需要办理什么任务了，这些activiti帮我们管理了，而不像上边需要我们在sql语句中的where条件中指定当前查询的状态值是多少。6、用户办理任务用户查询待办任务后，就可以办理某个任务，如果这个任务办理完成还需要其它用户办理，比如采购单创建后由部门经理审核，这个过程也是由activiti帮我们完成了，不需要我们在代码中硬编码指定下一个任务办理人了。7、流程结束当任务办理完成没有下一个任务/结点了，这个流程实例就完成了。环境准备三个环境第一个环境：没有加入工作流IHRM系统作用：主要是为activiti工作流引擎的引入提供场景第二个环境：activiti测试环境作用：用于测试activiti的api，提供各种service接口。需要创建一个数据库：仅仅有activiti的数据表第三个环境：activiti应用环境，加入工作流的SaaS-IHRM系统需要创建一个数据库：包括activiti的数据表和业务表（IHRM系统的表）开发环境Jdk1.8Mysql5+Tomcat7NavicatideaActiviti环境Activiti7.0.0.Beta1默认支持spring5IDEA流程设计器在插件内搜索actiBPM并下载Activiti支持的数据库Activiti的运行需要数据库支撑，需要安装activiti数据库，支持如下版本：创建mysql数据库CREATEDATABASEactivitiDEFAULTCHARACTERSETutf8;加入maven依赖的坐标&lt;properties&gt;&lt;slf4j.version&gt;1.6.6&lt;/slf4j.version&gt;&lt;log4j.version&gt;1.2.12&lt;/log4j.version&gt;&lt;/properties&gt;&lt;dependencies&gt;&lt;dependency&gt;&lt;groupId&gt;org.activiti&lt;/groupId&gt;&lt;artifactId&gt;activiti-engine&lt;/artifactId&gt;&lt;version&gt;7.0.0.Beta1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;&lt;groupId&gt;org.activiti&lt;/groupId&gt;&lt;artifactId&gt;activiti-spring&lt;/artifactId&gt;&lt;version&gt;7.0.0.Beta1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;&lt;groupId&gt;org.activiti&lt;/groupId&gt;&lt;artifactId&gt;activiti-bpmn-model&lt;/artifactId&gt;&lt;version&gt;7.0.0.Beta1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;&lt;groupId&gt;org.activiti&lt;/groupId&gt;&lt;artifactId&gt;activiti-bpmn-converter&lt;/artifactId&gt;&lt;version&gt;7.0.0.Beta1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;&lt;groupId&gt;org.activiti&lt;/groupId&gt;&lt;artifactId&gt;activiti-json-converter&lt;/artifactId&gt;&lt;version&gt;7.0.0.Beta1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;&lt;groupId&gt;org.activiti&lt;/groupId&gt;&lt;artifactId&gt;activiti-bpmn-layout&lt;/artifactId&gt;&lt;version&gt;7.0.0.Beta1&lt;/version&gt;&lt;!--有个包下载不了需要手动下载jar包打包到本地mvninstall:install-file-DgroupId=com.github.jgraph-DartifactId=jgraphx-Dversion=v3.9.3-Dpackaging=jar-Dfile=jgraphx-v3.9.3.jar--&gt;&lt;/dependency&gt;&lt;dependency&gt;&lt;groupId&gt;org.activiti.cloud&lt;/groupId&gt;&lt;artifactId&gt;activiti-cloud-services-api&lt;/artifactId&gt;&lt;version&gt;7.0.0.Beta1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;&lt;groupId&gt;mysql&lt;/groupId&gt;&lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;&lt;version&gt;8.0.20&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;&lt;groupId&gt;junit&lt;/groupId&gt;&lt;artifactId&gt;junit&lt;/artifactId&gt;&lt;version&gt;4.12&lt;/version&gt;&lt;/dependency&gt;&lt;!--logstart--&gt;&lt;dependency&gt;&lt;groupId&gt;log4j&lt;/groupId&gt;&lt;artifactId&gt;log4j&lt;/artifactId&gt;&lt;version&gt;${log4j.version}&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;&lt;groupId&gt;org.slf4j&lt;/groupId&gt;&lt;artifactId&gt;slf4j-api&lt;/artifactId&gt;&lt;version&gt;${slf4j.version}&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;&lt;groupId&gt;org.slf4j&lt;/groupId&gt;&lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt;&lt;version&gt;${slf4j.version}&lt;/version&gt;&lt;/dependency&gt;&lt;!--logend--&gt;&lt;dependency&gt;&lt;groupId&gt;org.mybatis&lt;/groupId&gt;&lt;artifactId&gt;mybatis&lt;/artifactId&gt;&lt;version&gt;3.4.5&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;&lt;groupId&gt;commons-dbcp&lt;/groupId&gt;&lt;artifactId&gt;commons-dbcp&lt;/artifactId&gt;&lt;version&gt;1.4&lt;/version&gt;&lt;/dependency&gt;&lt;/dependencies&gt;log4j.properties#SetrootcategoryprioritytoINFOanditsonlyappendertoCONSOLE.#log4j.rootCategory=INFO,CONSOLEdebuginfowarnerrorfatallog4j.rootCategory=debug,CONSOLE,LOGFILE#SettheenterpriseloggercategorytoFATALanditsonlyappendertoCONSOLE.log4j.logger.org.apache.axis.enterprise=FATAL,CONSOLE#CONSOLEissettobeaConsoleAppenderusingaPatternLayout.log4j.appender.CONSOLE=org.apache.log4j.ConsoleAppenderlog4j.appender.CONSOLE.layout=org.apache.log4j.PatternLayoutlog4j.appender.CONSOLE.layout.ConversionPattern=%d{ISO8601}%-6r[%15.15t]%-5p%30.30c%x-%m\\n#LOGFILEissettobeaFileappenderusingaPatternLayout.log4j.appender.LOGFILE=org.apache.log4j.FileAppenderlog4j.appender.LOGFILE.File=d:\\axis.loglog4j.appender.LOGFILE.Append=truelog4j.appender.LOGFILE.layout=org.apache.log4j.PatternLayoutlog4j.appender.LOGFILE.layout.ConversionPattern=%d{ISO8601}%-6r[%15.15t]%-5p%30.30c%x-%m\\nactiviti.cfg.xml&lt;?xmlversion=&quot;1.0&quot;encoding=&quot;UTF-8&quot;?&gt;&lt;beansxmlns=&quot;http://www.springframework.org/schema/beans&quot;xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;xsi:schemaLocation=&quot;http://www.springframework.org/schema/beanshttp://www.springframework.org/schema/beans/spring-beans.xsd&quot;&gt;&lt;!--数据库连接池--&gt;&lt;beanid=&quot;dataSource&quot;class=&quot;org.apache.commons.dbcp.BasicDataSource&quot;&gt;&lt;propertyname=&quot;driverClassName&quot;value=&quot;com.mysql.cj.jdbc.Driver&quot;/&gt;&lt;propertyname=&quot;url&quot;value=&quot;jdbc:mysql://localhost:3306/activiti?serverTimezone=UTC&amp;amp;useUnicode=true&amp;amp;characterEncoding=utf8&amp;amp;useSSL=true&quot;/&gt;&lt;propertyname=&quot;username&quot;value=&quot;root&quot;/&gt;&lt;propertyname=&quot;password&quot;value=&quot;root&quot;/&gt;&lt;propertyname=&quot;maxActive&quot;value=&quot;3&quot;/&gt;&lt;propertyname=&quot;maxIdle&quot;value=&quot;1&quot;/&gt;&lt;/bean&gt;&lt;!--processEngineConfiguration用来创建ProcessEngine，在创建ProcessEngine时会执行数据库的操作。--&gt;&lt;beanid=&quot;processEngineConfiguration&quot;class=&quot;org.activiti.engine.impl.cfg.StandaloneProcessEngineConfiguration&quot;&gt;&lt;propertyname=&quot;dataSource&quot;ref=&quot;dataSource&quot;/&gt;&lt;propertyname=&quot;databaseSchemaUpdate&quot;value=&quot;true&quot;/&gt;&lt;/bean&gt;&lt;!--&lt;beanid=&quot;processEngineConfiguration&quot;class=&quot;org.activiti.engine.impl.cfg.StandaloneProcessEngineConfiguration&quot;&gt;&lt;propertyname=&quot;jdbcDriver&quot;value=&quot;com.mysql.cj.jdbc.Driver&quot;/&gt;&lt;propertyname=&quot;jdbcUrl&quot;value=&quot;jdbc:mysql://localhost:3306/activiti?serverTimezone=UTC&amp;amp;useUnicode=true&amp;amp;characterEncoding=utf8&amp;amp;useSSL=true&quot;/&gt;&lt;propertyname=&quot;jdbcUsername&quot;value=&quot;root&quot;/&gt;&lt;propertyname=&quot;jdbcPassword&quot;value=&quot;root&quot;/&gt;&lt;propertyname=&quot;databaseSchemaUpdate&quot;value=&quot;true&quot;/&gt;&lt;/bean&gt;--&gt;&lt;/beans&gt;关于processEngineConfiguration中的databaseSchemaUpdate参数，通过此参数设计activiti数据表的处理策略，参数如下：false（默认）：检查数据库表的版本和依赖库的版本，如果版本不匹配就抛出异常。true:构建流程引擎时，执行检查，如果需要就执行更新。如果表不存在，就创建。create-drop:构建流程引擎时创建数据库表，关闭流程引擎时删除这些表。drop-create：先删除表再创建表。create:构建流程引擎时创建数据库表，关闭流程引擎时不删除这些表。注意：在activiti.cfg.xml配置文件中的dataSource和processEngineConfiguration也可以使用一次性配置出来。编写程序创建ProcessEngineConfiguration，通过ProcessEngineConfiguration创建ProcessEngine，在创建ProcessEngine时会自动创建数据库。@TestpublicvoidcreateProcessEngine(){ProcessEngineConfigurationconfiguration=ProcessEngineConfiguration.createProcessEngineConfigurationFromResource(&quot;activiti.cfg.xml&quot;);ProcessEngineprocessEngine=configuration.buildProcessEngine();System.out.println(processEngine);}1、运行以上程序段即可完成activiti数据库创建，通过改变activiti.cfg.xml中databaseSchemaUpdate参数的值执行不同的数据表处理策略。2、上边的方法createProcessEngineConfigurationFromResource在执行时在activiti.cfg.xml中找固定的名称processEngineConfiguration也可以使用重载方法调用，这时可以不用限定processEngineConfiguration名称数据库表的命名规则Activiti的表都以ACT_开头。第二部分是表示表的用途的两个字母标识。用途也和服务的API对应。_ACT_RE_*:'RE'表示repository。这个前缀的表包含了流程定义和流程静态资源（图片，规则，等等）。ACT_RU_*:'RU'表示runtime。这些运行时的表，包含流程实例，任务，变量，异步任务，等运行中的数据。Activiti只在流程实例执行过程中保存这些数据，在流程结束时就会删除这些记录。这样运行时表可以一直很小速度很快。ACT_HI_*:'HI'表示history。这些表包含历史数据，比如历史流程实例，变量，任务等等。ACT_GE_*:GE表示general。通用数据，用于不同场景下。Activiti服务架构图在新版本中，我们通过实验可以发现IdentityService，FormService两个Serivce都已经删除了activiti.cfg.xmlactiviti的引擎配置文件，包括：ProcessEngineConfiguration的定义、数据源定义、事务管理器等，此文件其实就是一个spring配置文件，下面是一个基本的配置只配置了ProcessEngineConfiguration和数据源：&lt;!--数据库连接池--&gt;&lt;beanid=&quot;dataSource&quot;class=&quot;org.apache.commons.dbcp.BasicDataSource&quot;&gt;&lt;propertyname=&quot;driverClassName&quot;value=&quot;com.mysql.cj.jdbc.Driver&quot;/&gt;&lt;propertyname=&quot;url&quot;value=&quot;jdbc:mysql://localhost:3306/activiti?serverTimezone=UTC&amp;amp;useUnicode=true&amp;amp;characterEncoding=utf8&amp;amp;useSSL=true&quot;/&gt;&lt;propertyname=&quot;username&quot;value=&quot;root&quot;/&gt;&lt;propertyname=&quot;password&quot;value=&quot;root&quot;/&gt;&lt;propertyname=&quot;maxActive&quot;value=&quot;3&quot;/&gt;&lt;propertyname=&quot;maxIdle&quot;value=&quot;1&quot;/&gt;&lt;/bean&gt;&lt;beanid=&quot;processEngineConfiguration&quot;class=&quot;org.activiti.engine.impl.cfg.StandaloneProcessEngineConfiguration&quot;&gt;&lt;!--数据源--&gt;&lt;propertyname=&quot;dataSource&quot;ref=&quot;dataSource&quot;/&gt;&lt;!--数据库策略--&gt;&lt;propertyname=&quot;databaseSchemaUpdate&quot;value=&quot;true&quot;/&gt;&lt;/bean&gt;ProcessEngineConfiguration流程引擎的配置类，通过ProcessEngineConfiguration可以创建工作流引擎ProceccEngine，常用的两种方法如下：StandaloneProcessEngineConfiguration通过org.activiti.engine.impl.cfg.StandaloneProcessEngineConfigurationActiviti可以单独运行，使用它创建的ProcessEngine，Activiti会自己处理事务。配置文件方式：通常在activiti.cfg.xml配置文件中定义一个id为processEngineConfiguration的bean，这里会使用spring的依赖注入来构建引擎。方法如下：&lt;beanid=&quot;processEngineConfiguration&quot;class=&quot;org.activiti.engine.impl.cfg.StandaloneProcessEngineConfiguration&quot;&gt;&lt;!--数据源--&gt;&lt;propertyname=&quot;dataSource&quot;ref=&quot;dataSource&quot;/&gt;&lt;!--数据库策略--&gt;&lt;propertyname=&quot;databaseSchemaUpdate&quot;value=&quot;true&quot;/&gt;&lt;/bean&gt;SpringProcessEngineConfiguration通过org.activiti.spring.SpringProcessEngineConfiguration与Spring整合。创建spring与activiti的整合配置文件：activity-spring.cfg.xml（名称不固定）&lt;beansxmlns=&quot;http://www.springframework.org/schema/beans&quot;xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;xmlns:mvc=&quot;http://www.springframework.org/schema/mvc&quot;xmlns:context=&quot;http://www.springframework.org/schema/context&quot;xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot;xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot;xsi:schemaLocation=&quot;http://www.springframework.org/schema/beanshttp://www.springframework.org/schema/beans/spring-beans-3.1.xsdhttp://www.springframework.org/schema/mvchttp://www.springframework.org/schema/mvc/spring-mvc-3.1.xsdhttp://www.springframework.org/schema/contexthttp://www.springframework.org/schema/context/spring-context-3.1.xsdhttp://www.springframework.org/schema/aophttp://www.springframework.org/schema/aop/spring-aop-3.1.xsdhttp://www.springframework.org/schema/txhttp://www.springframework.org/schema/tx/spring-tx-3.1.xsd&quot;&gt;&lt;!--工作流引擎配置bean--&gt;&lt;beanid=&quot;processEngineConfiguration&quot;class=&quot;org.activiti.spring.SpringProcessEngineConfiguration&quot;&gt;&lt;!--数据源--&gt;&lt;propertyname=&quot;dataSource&quot;ref=&quot;dataSource&quot;/&gt;&lt;!--使用spring事务管理器--&gt;&lt;propertyname=&quot;transactionManager&quot;ref=&quot;transactionManager&quot;/&gt;&lt;!--数据库策略--&gt;&lt;propertyname=&quot;databaseSchemaUpdate&quot;value=&quot;drop-create&quot;/&gt;&lt;!--activiti的定时任务关闭--&gt;&lt;propertyname=&quot;jobExecutorActivate&quot;value=&quot;false&quot;/&gt;&lt;/bean&gt;&lt;!--流程引擎--&gt;&lt;beanid=&quot;processEngine&quot;class=&quot;org.activiti.spring.ProcessEngineFactoryBean&quot;&gt;&lt;propertyname=&quot;processEngineConfiguration&quot;ref=&quot;processEngineConfiguration&quot;/&gt;&lt;/bean&gt;&lt;!--资源服务service--&gt;&lt;beanid=&quot;repositoryService&quot;factory-bean=&quot;processEngine&quot;factory-method=&quot;getRepositoryService&quot;/&gt;&lt;!--流程运行service--&gt;&lt;beanid=&quot;runtimeService&quot;factory-bean=&quot;processEngine&quot;factory-method=&quot;getRuntimeService&quot;/&gt;&lt;!--任务管理service--&gt;&lt;beanid=&quot;taskService&quot;factory-bean=&quot;processEngine&quot;factory-method=&quot;getTaskService&quot;/&gt;&lt;!--历史管理service--&gt;&lt;beanid=&quot;historyService&quot;factory-bean=&quot;processEngine&quot;factory-method=&quot;getHistoryService&quot;/&gt;&lt;!--用户管理service--&gt;&lt;beanid=&quot;identityService&quot;factory-bean=&quot;processEngine&quot;factory-method=&quot;getIdentityService&quot;/&gt;&lt;!--引擎管理service--&gt;&lt;beanid=&quot;managementService&quot;factory-bean=&quot;processEngine&quot;factory-method=&quot;getManagementService&quot;/&gt;&lt;!--数据源--&gt;&lt;beanid=&quot;dataSource&quot;class=&quot;org.apache.commons.dbcp.BasicDataSource&quot;&gt;&lt;propertyname=&quot;driverClassName&quot;value=&quot;com.mysql.jdbc.Driver&quot;/&gt;&lt;propertyname=&quot;url&quot;value=&quot;jdbc:mysql://localhost:3306/activiti&quot;/&gt;&lt;propertyname=&quot;username&quot;value=&quot;root&quot;/&gt;&lt;propertyname=&quot;password&quot;value=&quot;mysql&quot;/&gt;&lt;propertyname=&quot;maxActive&quot;value=&quot;3&quot;/&gt;&lt;propertyname=&quot;maxIdle&quot;value=&quot;1&quot;/&gt;&lt;/bean&gt;&lt;!--事务管理器--&gt;&lt;beanid=&quot;transactionManager&quot;class=&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;&gt;&lt;propertyname=&quot;dataSource&quot;ref=&quot;dataSource&quot;/&gt;&lt;/bean&gt;&lt;!--通知--&gt;&lt;tx:adviceid=&quot;txAdvice&quot;transaction-manager=&quot;transactionManager&quot;&gt;&lt;tx:attributes&gt;&lt;!--传播行为--&gt;&lt;tx:methodname=&quot;save*&quot;propagation=&quot;REQUIRED&quot;/&gt;&lt;tx:methodname=&quot;insert*&quot;propagation=&quot;REQUIRED&quot;/&gt;&lt;tx:methodname=&quot;delete*&quot;propagation=&quot;REQUIRED&quot;/&gt;&lt;tx:methodname=&quot;update*&quot;propagation=&quot;REQUIRED&quot;/&gt;&lt;tx:methodname=&quot;find*&quot;propagation=&quot;SUPPORTS&quot;read-only=&quot;true&quot;/&gt;&lt;tx:methodname=&quot;get*&quot;propagation=&quot;SUPPORTS&quot;read-only=&quot;true&quot;/&gt;&lt;/tx:attributes&gt;&lt;/tx:advice&gt;&lt;!--切面，根据具体项目修改切点配置--&gt;&lt;aop:configproxy-target-class=&quot;true&quot;&gt;&lt;aop:advisoradvice-ref=&quot;txAdvice&quot;pointcut=&quot;execution(*cn.kgc.ihrm.service.impl.*.*(..))&quot;/&gt;&lt;/aop:config&gt;&lt;/beans&gt;创建processEngineConfigurationProcessEngineConfigurationconfiguration=ProcessEngineConfiguration.createProcessEngineConfigurationFromResource(&quot;activiti.cfg.xml&quot;);上边的代码要求activiti.cfg.xml中必须有一个processEngineConfiguration的bean也可以使用下边的方法，更改bean的名字：ProcessEngineConfiguration.createProcessEngineConfigurationFromResource(Stringresource,StringbeanName);ProcessEngine工作流引擎，相当于一个门面接口，通过ProcessEngineConfiguration创建processEngine，通过ProcessEngine创建各个service接口。一般创建方式//通过ProcessEngineConfiguration创建ProcessEngineProcessEngineprocessEngine=processEngineConfiguration.buildProcessEngine();简单创建方式将activiti.cfg.xml文件名及路径固定，且activiti.cfg.xml文件中有processEngineConfiguration的配置，可以使用如下代码创建processEngine://使用classpath下的activiti.cfg.xml中的配置创建processEngineProcessEngineprocessEngine=ProcessEngines.getDefaultProcessEngine();System.out.println(processEngine);ServiceService创建方式通过ProcessEngine创建Service，Service是工作流引擎提供用于进行工作流部署、执行、管理的服务接口。方式如下：RuntimeServiceruntimeService=processEngine.getRuntimeService();RepositoryServicerepositoryService=processEngine.getRepositoryService();TaskServicetaskService=processEngine.getTaskService();HistoryServicehistoryService=processEngine.getHistoryService();Service总览RepositoryServiceactiviti的资源管理类RuntimeServiceactiviti的流程运行管理类TaskServiceactiviti的任务管理类HistoryServiceactiviti的历史管理类ManagerServiceactiviti的引擎管理类RepositoryService是activiti的资源管理类，提供了管理和控制流程发布包和流程定义的操作。使用工作流建模工具设计的业务流程图需要使用此service将流程定义文件的内容部署到计算机。除了部署流程定义以外还可以：查询引擎中的发布包和流程定义。暂停或激活发布包，对应全部和特定流程定义。暂停意味着它们不能再执行任何操作了，激活是对应的反向操作。获得多种资源，像是包含在发布包里的文件，或引擎自动生成的流程图。获得流程定义的pojo版本，可以用来通过java解析流程，而不必通过xml。RuntimeService它是activiti的流程运行管理类。可以从这个服务类中获取很多关于流程执行相关的信息TaskService是activiti的任务管理类。可以从这个类中获取任务的信息。HistoryService是activiti的历史管理类，可以查询历史信息，执行流程时，引擎会保存很多数据（根据配置），比如流程实例启动时间，任务的参与者，完成任务的时间，每个流程实例的执行路径，等等。这个服务主要通过查询功能来获得这些数据。ManagementService是activiti的引擎管理类，提供了对Activiti流程引擎的管理和维护功能，这些功能不在工作流驱动的应用程序中使用，主要用于Activiti系统的日常维护。Activiti7入门体验流程定义Activiti-Designer使用Palette（画板）在idea中安装activiti-designer插件即可使用，画板中包括以下结点：Connection—连接Event---事件Task---任务Gateway---网关Container—容器Boundaryevent—边界事件Intermediateevent--中间事件流程图设计完毕保存生成.bpmn文件。新建流程File--&gt;new--&gt;BpmnFile--&gt;holiday.bpmn绘制流程在properties视图指定每个任务结点的负责人，比如下边是填写请假单的负责人为zhangsan生成png图片先将bpmn文件修改成xml文件然后右键点这个xml文件，在选项中选择diagrams，然后选择showDesigner就可以看到流程图，然后Exporttofile保存png文件。解决转换图片乱码问题1、在idea安装目录下的bin目录找到idea64.exe.vmoptions和idea.exe.vmoptions2、编辑器打开分别添加-Dfile.encoding=UTF-83、重启后若还是乱码，选择Help--&gt;EditCustomVMOptions...4、添加第二步内容5、重启部署流程定义部署流程定义就是要将上边绘制的图形即流程定义（.bpmn）部署在工作流程引擎activiti中，方法如下：使用ProcessEngine创建RepositoryService，代码如下：/***创建RepositoryService*/@TestpublicvoidcreateRepositoryService(){//获取repositoryServiceRepositoryServicerepositoryService=processEngine.getRepositoryService();//部署对象Deploymentdeployment=repositoryService.createDeployment()//error：org.activiti.bpmn.exceptions.XMLException:cvc-complex-type.2.4.a:发现了以元素'process'开头的无效内容//.disableSchemaValidation()//禁用架构验证,如果出现上面注释的那个错误需要禁用这个.addClasspathResource(&quot;diagram/holiday.bpmn&quot;)//bpmn文件.addClasspathResource(&quot;diagram/holiday.png&quot;)//图片文件.name(&quot;请假申请流程&quot;).deploy();System.out.println(&quot;流程部署id:&quot;+deployment.getId());System.out.println(&quot;流程部署名称:&quot;+deployment.getName());}执行此操作后activiti会将上边代码中指定的bpm文件和图片文件保存在activiti数据库。启动一个流程实例流程定义部署在activiti后就可以通过工作流管理业务流程了，也就是说上边部署的请假申请流程可以使用了。针对该流程0，启动一个流程表示发起一个新的请假申请单，这就相当于java类与java对象的关系，类定义好后需要new创建一个对象使用，当然可以new多个对象。对于请假申请流程，张三发起一个请假申请单需要启动一个流程实例，请假申请单发起一个请假单也需要启动一个流程实例。代码如下/***启动一个流程实例*/@TestpublicvoidstartProcessInstance(){//获取RunTimeServiceRuntimeServiceruntimeService=processEngine.getRuntimeService();//根据流程定义key启动流程ProcessInstanceprocessInstance=runtimeService.startProcessInstanceByKey(&quot;myProcess_1&quot;);System.out.println(&quot;流程定义id：&quot;+processInstance.getProcessDefinitionId());System.out.println(&quot;流程实例id：&quot;+processInstance.getId());System.out.println(&quot;当前活动Id：&quot;+processInstance.getActivityId());}任务查询流程启动后，各各任务的负责人就可以查询自己当前需要处理的任务，查询出来的任务都是该用户的待办任务。/***查询当前个人待执行的任务*/@TestpublicvoidfindPersonalTaskList(){//任务负责人Stringassignee=&quot;lisi&quot;;//创建TaskServiceTaskServicetaskService=processEngine.getTaskService();List&lt;Task&gt;list=taskService.createTaskQuery()//.processDefinitionKey(&quot;myProcess_1&quot;)//.taskAssignee(assignee)//只查询该任务负责人的任务.list();for(Tasktask:list){System.out.println(&quot;流程实例id：&quot;+task.getProcessInstanceId());System.out.println(&quot;任务id：&quot;+task.getId());System.out.println(&quot;任务负责人：&quot;+task.getAssignee());System.out.println(&quot;任务名称：&quot;+task.getName());}}任务处理任务负责人查询待办任务，选择任务进行处理，完成任务/***完成任务*Table：act_hi_taskinst*/@TestpublicvoidcompletTask(){//任务idStringtaskId=&quot;15002&quot;;//创建TaskServiceTaskServicetaskService=processEngine.getTaskService();//完成任务taskService.complete(taskId);System.out.println(&quot;完成任务id=&quot;+taskId);}流程定义流程定义流程定义是线下按照bpmn2.0标准去描述业务流程，通常使用activiti-explorer（web控制台）或activiti-eclipse-designer插件对业务流程进行建模，这两种方式都遵循bpmn2.0标准。本教程使用activiti-eclipse-designer插件完成流程建模。使用designer设计器绘制流程，会生成两个文件：.bpmn和.png流程定义部署么是流程定义部署将线下定义的流程部署到activiti数据库中，这就是流程定义部署，通过调用activiti的api将流程定义的bpmn和png两个文件一个一个添加部署到activiti中，也可以将两个文件打成zip包进行部署。单个文件部署方式分别将bpmn文件和png图片文件部署。/***单个文件部署方式*/@TestpublicvoiddeployProcess(){//获取repositoryServiceRepositoryServicerepositoryService=processEngine.getRepositoryService();//bpmn输入流InputStreaminputStream_bpmn=this.getClass().getClassLoader().getResourceAsStream(&quot;diagram/holiday.bpmn&quot;);//图片输入流InputStreaminputStream_png=this.getClass().getClassLoader().getResourceAsStream(&quot;diagram/holiday.png&quot;);//流程部署对象Deploymentdeployment=repositoryService.createDeployment().disableSchemaValidation()//禁用架构验证.addInputStream(&quot;holiday.bpmn&quot;,inputStream_bpmn).addInputStream(&quot;holiday.png&quot;,inputStream_png).deploy();System.out.println(&quot;流程部署id：&quot;+deployment.getId());System.out.println(&quot;流程部署名称：&quot;+deployment.getName());}执行此操作后activiti会将上边代码中指定的bpm文件和图片文件保存在activiti数据库。压缩包部署方式将holiday.bpmn和holiday.png压缩成zip包。/***压缩包部署方式*/@TestpublicvoiddeployProcessByZip(){//定义zip输入流InputStreaminputStream=this.getClass().getClassLoader().getResourceAsStream(&quot;diagram/diagram.zip&quot;);ZipInputStreamzipInputStream=newZipInputStream(inputStream);//获取repositoryServiceRepositoryServicerepositoryService=processEngine.getRepositoryService();//流程部署Deploymentdeployment=repositoryService.createDeployment().disableSchemaValidation()//禁用架构验证.addZipInputStream(zipInputStream).deploy();System.out.println(&quot;流程部署id：&quot;+deployment.getId());System.out.println(&quot;流程部署名称：&quot;+deployment.getName());}执行此操作后activiti会将上边代码中指定的bpm文件和图片文件保存在activiti数据库。操作数据表流程定义部署后操作activiti数据表如下：SELECT*FROMact_re_deployment流程定义部署表，记录流程部署信息SELECT*FROMact_re_procdef流程定义表，记录流程定义信息SELECT*FROMact_ge_bytearray资源表说明：act_re_deployment和act_re_procdef一对多关系，一次部署在流程部署表生成一条记录，但一次部署可以部署多个流程定义，每个流程定义在流程定义表生成一条记录。每一个流程定义在act_ge_bytearray会存在两个资源记录，bpmn和png。建议：一次部署一个流程，这样部署表和流程定义表是一对一有关系，方便读取流程部署及流程定义信息。流程定义查询查询部署的流程定义。/***流程定义查询*/@TestpublicvoidqueryProceccDefinition(){//流程定义keyStringprocessDefinitionKey=&quot;myProcess_1&quot;;//获取repositoryServiceRepositoryServicerepositoryService=processEngine.getRepositoryService();//查询流程定义ProcessDefinitionQueryprocessDefinitionQuery=repositoryService.createProcessDefinitionQuery();//遍历查询结果List&lt;ProcessDefinition&gt;list=processDefinitionQuery.processDefinitionKey(processDefinitionKey).orderByProcessDefinitionVersion().desc().list();for(ProcessDefinitionprocessDefinition:list){System.out.println(&quot;------------------------&quot;);System.out.println(&quot;流程部署id：&quot;+processDefinition.getDeploymentId());System.out.println(&quot;流程定义id：&quot;+processDefinition.getId());System.out.println(&quot;流程定义名称：&quot;+processDefinition.getName());System.out.println(&quot;流程定义key：&quot;+processDefinition.getKey());System.out.println(&quot;流程定义版本：&quot;+processDefinition.getVersion());}}流程定义删除删除已经部署成功的流程定义。/***删除已经部署成功的流程定义*/@TestpublicvoiddeleteDeployment(){//流程部署idStringdeploymentId=&quot;22501&quot;;//通过流程引擎获取repositoryServiceRepositoryServicerepositoryService=processEngine.getRepositoryService();//删除流程定义，如果该流程定义已有流程实例启动则删除时出错repositoryService.deleteDeployment(deploymentId);//设置true级联删除流程定义，即使该流程有流程实例启动也可以删除，设置为false非级别删除方式，如果流程//repositoryService.deleteDeployment(deploymentId,true);}说明：使用repositoryService删除流程定义如果该流程定义下没有正在运行的流程，则可以用普通删除。如果该流程定义下存在已经运行的流程，使用普通删除报错，可用级联删除方法将流程及相关记录全部删除。项目开发中使用级联删除的情况比较多，删除操作一般只开放给超级管理员使用流程定义资源查询方式1通过流程定义对象获取流程定义资源，获取bpmn和png。/***流程定义资源查询方式一*@throwsIOException*/@TestpublicvoidgetProcessResources()throwsIOException{//流程定义id//Table：ACT_RE_PROCDEFStringprocessDefinitionId=&quot;myProcess_1:1:2504&quot;;//获取repositoryServiceRepositoryServicerepositoryService=processEngine.getRepositoryService();//流程定义对象ProcessDefinitionprocessDefinition=repositoryService.createProcessDefinitionQuery().processDefinitionId(processDefinitionId).singleResult();//获取bpmnStringresource_bpmn=processDefinition.getResourceName();//获取pngStringresource_png=processDefinition.getDiagramResourceName();//资源信息System.out.println(&quot;bpmn：&quot;+resource_bpmn);System.out.println(&quot;png：&quot;+resource_png);Filefile_png=newFile(&quot;d:/purchasingflow01.png&quot;);Filefile_bpmn=newFile(&quot;d:/purchasingflow01.bpmn&quot;);//输出bpmnInputStreamresourceAsStream=null;resourceAsStream=repositoryService.getResourceAsStream(processDefinition.getDeploymentId(),resource_bpmn);FileOutputStreamfileOutputStream=newFileOutputStream(file_bpmn);byte[]b=newbyte[1024];intlen=-1;while((len=resourceAsStream.read(b,0,1024))!=-1){fileOutputStream.write(b,0,len);}//输出图片resourceAsStream=repositoryService.getResourceAsStream(processDefinition.getDeploymentId(),resource_png);fileOutputStream=newFileOutputStream(file_png);//byte[]b=newbyte[1024];//intlen=-1;while((len=resourceAsStream.read(b,0,1024))!=-1){fileOutputStream.write(b,0,len);}}方式2通过查询流程部署信息获取流程定义资源/***获取流程定义图片资源方式二*@throwsIOException*/@TestpublicvoidgetProcessResources2()throwsIOException{//流程部署idStringdeploymentId=&quot;2501&quot;;//通过流程引擎获取repositoryServiceRepositoryServicerepositoryService=processEngine.getRepositoryService();//读取资源名称List&lt;String&gt;resources=repositoryService.getDeploymentResourceNames(deploymentId);Stringresource_image=null;//获取图片for(Stringresource_name:resources){if(resource_name.indexOf(&quot;.png&quot;)&gt;=0){resource_image=resource_name;}}//图片输入流InputStreaminputStream=repositoryService.getResourceAsStream(deploymentId,resource_image);FileexportFile=newFile(&quot;d:/holiday.png&quot;);FileOutputStreamfileOutputStream=newFileOutputStream(exportFile);byte[]buffer=newbyte[1024];intlen=-1;//输出图片while((len=inputStream.read(buffer))!=-1){fileOutputStream.write(buffer,0,len);}inputStream.close();fileOutputStream.close();}说明：deploymentId为流程部署IDresource_name为act_ge_bytearray表中NAME_列的值使用repositoryService的getDeploymentResourceNames方法可以获取指定部署下得所有文件的名称使用repositoryService的getResourceAsStream方法传入部署ID和资源图片名称可以获取部署下指定名称文件的输入流最后的将输入流中的图片资源进行输出。流程历史信息的查看即使流程定义已经删除了，流程执行的历史信息通过前面的分析，依然保存在activiti的act_hi_*相关的表中。所以我们还是可以查询流程执行的历史信息，可以通过HistoryService来查看相关的历史记录。/***流程历史信息的查看*/@TestpublicvoidtestHistoric01(){HistoryServicehistoryService=processEngine.getHistoryService();HistoricActivityInstanceQueryquery=historyService.createHistoricActivityInstanceQuery();query.processInstanceId(&quot;12501&quot;);List&lt;HistoricActivityInstance&gt;list=query.list();for(HistoricActivityInstanceai:list){System.out.println(ai.getActivityId());System.out.println(ai.getActivityName());System.out.println(ai.getProcessDefinitionId());System.out.println(ai.getProcessInstanceId());System.out.println(&quot;==============================&quot;);}}","link":"https://haohanya.github.io/post/activiti7-gong-zuo-liu-yin-qing/"},{"title":"ElasticSearch（二）","content":"ElasticSearch编程操作创建工程，导入坐标&lt;dependency&gt;&lt;groupId&gt;org.elasticsearch&lt;/groupId&gt;&lt;artifactId&gt;elasticsearch&lt;/artifactId&gt;&lt;version&gt;5.6.8&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;&lt;groupId&gt;org.elasticsearch.client&lt;/groupId&gt;&lt;artifactId&gt;transport&lt;/artifactId&gt;&lt;version&gt;5.6.8&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;&lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt;&lt;artifactId&gt;log4j-to-slf4j&lt;/artifactId&gt;&lt;version&gt;2.9.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;&lt;groupId&gt;org.slf4j&lt;/groupId&gt;&lt;artifactId&gt;slf4j-api&lt;/artifactId&gt;&lt;version&gt;1.7.24&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;&lt;groupId&gt;org.slf4j&lt;/groupId&gt;&lt;artifactId&gt;slf4j-simple&lt;/artifactId&gt;&lt;version&gt;1.7.21&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;&lt;groupId&gt;log4j&lt;/groupId&gt;&lt;artifactId&gt;log4j&lt;/artifactId&gt;&lt;version&gt;1.2.12&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;&lt;groupId&gt;junit&lt;/groupId&gt;&lt;artifactId&gt;junit&lt;/artifactId&gt;&lt;version&gt;4.12&lt;/version&gt;&lt;/dependency&gt;创建索引index/***创建索引*@throwsException*/@TestpublicvoidtestCreateIndex()throwsException{//创建Client连接对象Settingssettings=Settings.builder().put(&quot;cluster.name&quot;,&quot;elasticsearch&quot;).build();TransportClientclient=newPreBuiltTransportClient(settings).addTransportAddress(newInetSocketTransportAddress(InetAddress.getByName(&quot;127.0.0.1&quot;),9300));//创建名称为blog2的索引client.admin().indices().prepareCreate(&quot;blog2&quot;).get();//释放资源client.close();}创建映射mapping/***创建映射Mappings*@throwsException*/@TestpublicvoidtestCreateMappings()throwsException{//创建Client连接对象Settingssettings=Settings.builder().put(&quot;cluster.name&quot;,&quot;elasticsearch&quot;).build();TransportClientclient=newPreBuiltTransportClient(settings).addTransportAddress(newInetSocketTransportAddress(InetAddress.getByName(&quot;127.0.0.1&quot;),9300));//添加映射/***格式：*&quot;mappings&quot;:{&quot;article&quot;:{&quot;dynamic&quot;:&quot;false&quot;,&quot;properties&quot;:{&quot;id&quot;:{&quot;type&quot;:&quot;string&quot;},&quot;content&quot;:{&quot;type&quot;:&quot;string&quot;},&quot;author&quot;:{&quot;type&quot;:&quot;string&quot;}}}}*//*XContentBuilderbuilder=XContentFactory.jsonBuilder();builder.startObject().startObject(&quot;article&quot;).startObject(&quot;properties&quot;).startObject(&quot;id&quot;).field(&quot;type&quot;,&quot;integer&quot;).field(&quot;store&quot;,&quot;yes&quot;).endObject().startObject(&quot;title&quot;).field(&quot;type&quot;,&quot;string&quot;).field(&quot;store&quot;,&quot;yes&quot;).field(&quot;analyzer&quot;,&quot;ik_smart&quot;).endObject().startObject(&quot;content&quot;).field(&quot;type&quot;,&quot;string&quot;).field(&quot;store&quot;,&quot;yes&quot;).field(&quot;analyzer&quot;,&quot;ik_smart&quot;).endObject().endObject().endObject().endObject();*/Map&lt;String,String&gt;fieldType=newHashMap&lt;&gt;();fieldType.put(&quot;type&quot;,&quot;integer&quot;);fieldType.put(&quot;store&quot;,&quot;yes&quot;);Map&lt;String,String&gt;field2Type=newHashMap&lt;&gt;();field2Type.put(&quot;type&quot;,&quot;string&quot;);field2Type.put(&quot;store&quot;,&quot;yes&quot;);field2Type.put(&quot;analyzer&quot;,&quot;ik_smart&quot;);Map&lt;String,Object&gt;fields=newHashMap&lt;&gt;();fields.put(&quot;id&quot;,fieldType);fields.put(&quot;title&quot;,field2Type);fields.put(&quot;content&quot;,field2Type);Map&lt;String,Object&gt;properties=newHashMap&lt;&gt;();properties.put(&quot;properties&quot;,fields);Map&lt;String,Object&gt;builder=newHashMap&lt;&gt;();builder.put(&quot;article&quot;,properties);//创建映射PutMappingRequestmappingRequest=Requests.putMappingRequest(&quot;blog2&quot;).type(&quot;article&quot;).source(builder);client.admin().indices().putMapping(mappingRequest).get();//释放资源client.close();}建立文档document建立文档（通过XContentBuilder）/***创建文档通过XContentBuilder*/@TestpublicvoidtestCreateDocument()throwsException{//创建Client连接对象Settingssettings=Settings.builder().put(&quot;cluster.name&quot;,&quot;elasticsearch&quot;).build();TransportClientclient=newPreBuiltTransportClient(settings);client.addTransportAddress(newInetSocketTransportAddress(InetAddress.getByName(&quot;127.0.0.1&quot;),9300));//创建文档信息XContentBuilderbuilder=XContentFactory.jsonBuilder().startObject().field(&quot;id&quot;,1).field(&quot;title&quot;,&quot;ElasticSearch是一个基于Lucene的搜索服务器&quot;).field(&quot;content&quot;,&quot;它提供了一个分布式多用户能力的全文搜索引擎，基于RESTfulweb接口。Elasticsearch是用Java开发的，并作为Apache许可条款下的开放源码发布，是当前流行的企业级搜索引擎。设计用于云计算中，能够达到实时搜索，稳定，可靠，快速，安装使用方便。&quot;).endObject();//建立文档对象/***参数1：索引对象*参数2：类型*参数3：建立id*/client.prepareIndex(&quot;blog2&quot;,&quot;article&quot;,&quot;1&quot;).setSource(builder);//释放资源client.close();}建立文档（通过实体类转json）/***创建文档通过*@throwsException*/@TestpublicvoidtestCreateDocumentByEntity()throwsException{//创建Client连接对象Settingssettings=Settings.builder().put(&quot;cluster.name&quot;,&quot;elasticsearch&quot;).build();TransportClientclient=newPreBuiltTransportClient(settings);client.addTransportAddress(newInetSocketTransportAddress(InetAddress.getByName(&quot;127.0.0.1&quot;),9300));//描述json数据Articlearticle=newArticle();article.setId(2);article.setTitle(&quot;2搜索工作其实很快乐&quot;);article.setContent(&quot;2我们希望我们的搜索解决方案要快，我们希望有一个零配置和一个完全免费的搜索模式，我们希望能够简单地使用JSON通过HTTP的索引数据，我们希望我们的搜索服务器始终可用，我们希望能够一台开始并扩展到数百，我们要实时搜索，我们要简单的多租户，我们希望建立一个云的解决方案。Elasticsearch旨在解决所有这些问题和更多的问题。&quot;);//建立文档//jackson//ObjectMapperobjectMapper=newObjectMapper();//client.prepareIndex(&quot;blog2&quot;,&quot;article&quot;,article.getId().toString())//.setSource(objectMapper.writeValueAsString(article).getBytes(),XContentType.JSON).get();//fastjsonclient.prepareIndex(&quot;blog2&quot;,&quot;article&quot;,article.getId().toString()).setSource(JSON.toJSONBytes(article),XContentType.JSON).get();//释放资源client.close();}查询文档操作关键词查询/***关键词查询*@throwsException*/@TestpublicvoidtestTermQuery()throwsException{//1、创建Client连接对象Settingssettings=Settings.builder().put(&quot;cluster.name&quot;,&quot;elasticsearch&quot;).build();TransportClientclient=newPreBuiltTransportClient(settings);client.addTransportAddress(newInetSocketTransportAddress(InetAddress.getByName(&quot;127.0.0.1&quot;),9300));//2、设置搜索条件SearchResponsesearchResponse=client.prepareSearch(&quot;blog2&quot;).setTypes(&quot;article&quot;).setQuery(QueryBuilders.termQuery(&quot;content&quot;,&quot;搜索&quot;)).get();//3、遍历搜索结果数据SearchHitshits=searchResponse.getHits();//获取命中次数，查询结果有多少对象System.out.println(&quot;查询结果有：&quot;+hits.getTotalHits()+&quot;条&quot;);Iterator&lt;SearchHit&gt;iterator=hits.iterator();while(iterator.hasNext()){SearchHitsearchHit=iterator.next();//每个查询对象System.out.println(searchHit.getSourceAsString());//获取字符串格式打印System.out.println(&quot;title:&quot;+searchHit.getSource().get(&quot;title&quot;));}//4、释放资源client.close();}字符串查询/***字符串查询*@throwsException*/@TestpublicvoidtestStringQuery()throwsException{//1、创建Client连接对象Settingssettings=Settings.builder().put(&quot;cluster.name&quot;,&quot;elasticsearch&quot;).build();TransportClientclient=newPreBuiltTransportClient(settings);client.addTransportAddress(newInetSocketTransportAddress(InetAddress.getByName(&quot;127.0.0.1&quot;),9300));//2、设置搜索条件SearchResponsesearchResponse=client.prepareSearch(&quot;blog2&quot;).setTypes(&quot;article&quot;).setQuery(QueryBuilders.queryStringQuery(&quot;搜索&quot;)).get();//3、遍历搜索结果数据SearchHitshits=searchResponse.getHits();//获取命中次数，查询结果有多少对象System.out.println(&quot;查询结果有：&quot;+hits.getTotalHits()+&quot;条&quot;);Iterator&lt;SearchHit&gt;iterator=hits.iterator();while(iterator.hasNext()){SearchHitsearchHit=iterator.next();//每个查询对象System.out.println(searchHit.getSourceAsString());//获取字符串格式打印System.out.println(&quot;title:&quot;+searchHit.getSource().get(&quot;title&quot;));}//4、释放资源client.close();}使用文档ID查询文档/***使用文档ID查询文档*@throwsException*/@TestpublicvoidtestIdQuery()throwsException{//1、创建Client连接对象Settingssettings=Settings.builder().put(&quot;cluster.name&quot;,&quot;elasticsearch&quot;).build();TransportClientclient=newPreBuiltTransportClient(settings);client.addTransportAddress(newInetSocketTransportAddress(InetAddress.getByName(&quot;127.0.0.1&quot;),9300));//client对象为TransportClient对象SearchResponseresponse=client.prepareSearch(&quot;blog2&quot;).setTypes(&quot;article&quot;)//设置要查询的id.setQuery(QueryBuilders.idsQuery().addIds(&quot;1&quot;,&quot;2&quot;))//执行查询.get();//取查询结果SearchHitssearchHits=response.getHits();//取查询结果总记录数System.out.println(searchHits.getTotalHits());Iterator&lt;SearchHit&gt;hitIterator=searchHits.iterator();while(hitIterator.hasNext()){SearchHitsearchHit=hitIterator.next();//打印整行数据System.out.println(searchHit.getSourceAsString());}}查询文档分页操作批量插入数据/***批量插入100条数据*@throwsException*/@TestpublicvoidtestCreateDocument100()throwsException{//1、创建Client连接对象Settingssettings=Settings.builder().put(&quot;cluster.name&quot;,&quot;elasticsearch&quot;).build();TransportClientclient=newPreBuiltTransportClient(settings);client.addTransportAddress(newInetSocketTransportAddress(InetAddress.getByName(&quot;127.0.0.1&quot;),9300));for(inti=1;i&lt;=100;i++){//描述json数据Articlearticle=newArticle();article.setId(i);article.setTitle(i+&quot;搜索工作其实很快乐&quot;);article.setContent(i+&quot;我们希望我们的搜索解决方案要快，我们希望有一个零配置和一个完全免费的搜索模式，我们希望能够简单地使用JSON通过HTTP的索引数据，我们希望我们的搜索服务器始终可用，我们希望能够一台开始并扩展到数百，我们要实时搜索，我们要简单的多租户，我们希望建立一个云的解决方案。Elasticsearch旨在解决所有这些问题和更多的问题。&quot;);//建立文档client.prepareIndex(&quot;blog2&quot;,&quot;article&quot;,article.getId().toString()).setSource(JSON.toJSONBytes(article),XContentType.JSON).get();}//释放资源client.close();}分页查询/***分页查询*@throwsException*/@Testpublicvoidtest10()throwsException{//1、创建Client连接对象Settingssettings=Settings.builder().put(&quot;cluster.name&quot;,&quot;elasticsearch&quot;).build();TransportClientclient=newPreBuiltTransportClient(settings);client.addTransportAddress(newInetSocketTransportAddress(InetAddress.getByName(&quot;127.0.0.1&quot;),9300));//搜索数据SearchRequestBuildersearchRequestBuilder=client.prepareSearch(&quot;blog2&quot;).setTypes(&quot;article&quot;).setQuery(QueryBuilders.matchAllQuery());//默认每页10条记录//查询第1页数据，每页5条//setFrom()：从第几条开始检索，默认是0。//setSize():每页最多显示的记录数。searchRequestBuilder.setFrom(0).setSize(5);SearchResponsesearchResponse=searchRequestBuilder.get();SearchHitshits=searchResponse.getHits();//获取命中次数，查询结果有多少对象System.out.println(&quot;查询结果有：&quot;+hits.getTotalHits()+&quot;条&quot;);Iterator&lt;SearchHit&gt;iterator=hits.iterator();while(iterator.hasNext()){SearchHitsearchHit=iterator.next();//每个查询对象System.out.println(searchHit.getSourceAsString());//获取字符串格式打印System.out.println(&quot;id:&quot;+searchHit.getSource().get(&quot;id&quot;));System.out.println(&quot;title:&quot;+searchHit.getSource().get(&quot;title&quot;));System.out.println(&quot;content:&quot;+searchHit.getSource().get(&quot;content&quot;));System.out.println(&quot;-----------------------------------------&quot;);}//释放资源client.close();}查询结果高亮操作/***搜索高亮*@throwsException*/@Testpublicvoidtest11()throwsException{//1、创建Client连接对象Settingssettings=Settings.builder().put(&quot;cluster.name&quot;,&quot;elasticsearch&quot;).build();TransportClientclient=newPreBuiltTransportClient(settings);client.addTransportAddress(newInetSocketTransportAddress(InetAddress.getByName(&quot;127.0.0.1&quot;),9300));//搜索数据SearchRequestBuildersearchRequestBuilder=client.prepareSearch(&quot;blog2&quot;).setTypes(&quot;article&quot;).setQuery(QueryBuilders.termQuery(&quot;title&quot;,&quot;搜索&quot;));//设置高亮数据HighlightBuilderhiBuilder=newHighlightBuilder();hiBuilder.preTags(&quot;&lt;fontstyle='color:red'&gt;&quot;);hiBuilder.postTags(&quot;&lt;/font&gt;&quot;);hiBuilder.field(&quot;title&quot;);searchRequestBuilder.highlighter(hiBuilder);//获得查询结果数据SearchResponsesearchResponse=searchRequestBuilder.get();//获取查询结果集SearchHitssearchHits=searchResponse.getHits();System.out.println(&quot;共搜到:&quot;+searchHits.getTotalHits()+&quot;条结果!&quot;);//遍历结果for(SearchHithit:searchHits){System.out.println(&quot;String方式打印文档搜索内容:&quot;);System.out.println(hit.getSourceAsString());System.out.println(&quot;Map方式打印高亮内容&quot;);System.out.println(hit.getHighlightFields());System.out.println(&quot;遍历高亮集合，打印高亮片段:&quot;);Text[]text=hit.getHighlightFields().get(&quot;title&quot;).getFragments();for(Textstr:text){System.out.println(str);}}//释放资源client.close();}SpringDataElasticSearch使用SpringDataElasticSearch简介什么是SpringDataSpringData是一个用于简化数据库访问，并支持云服务的开源框架。其主要目标是使得对数据的访问变得方便快捷，并支持map-reduce框架和云计算数据服务。SpringData可以极大的简化JPA的写法，可以在几乎不用写实现的情况下，实现对数据的访问和操作。除了CRUD外，还包括如分页、排序等一些常用的功能。SpringData的官网：http://projects.spring.io/spring-data/什么是SpringDataElasticSearchSpringDataElasticSearch基于springdataAPI简化elasticSearch操作，将原始操作elasticSearch的客户端API进行封装。SpringData为Elasticsearch项目提供集成搜索引擎。SpringDataElasticsearchPOJO的关键功能区域为中心的模型与Elastichsearch交互文档和轻松地编写一个存储库数据访问层。官方网站：http://projects.spring.io/spring-data-elasticsearch/SpringDataElasticSearch入门1、导入依赖&lt;dependency&gt;&lt;groupId&gt;org.elasticsearch&lt;/groupId&gt;&lt;artifactId&gt;elasticsearch&lt;/artifactId&gt;&lt;version&gt;5.6.8&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;&lt;groupId&gt;org.elasticsearch.client&lt;/groupId&gt;&lt;artifactId&gt;transport&lt;/artifactId&gt;&lt;version&gt;5.6.8&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;&lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt;&lt;artifactId&gt;log4j-to-slf4j&lt;/artifactId&gt;&lt;version&gt;2.9.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;&lt;groupId&gt;org.slf4j&lt;/groupId&gt;&lt;artifactId&gt;slf4j-api&lt;/artifactId&gt;&lt;version&gt;1.7.24&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;&lt;groupId&gt;org.slf4j&lt;/groupId&gt;&lt;artifactId&gt;slf4j-simple&lt;/artifactId&gt;&lt;version&gt;1.7.21&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;&lt;groupId&gt;log4j&lt;/groupId&gt;&lt;artifactId&gt;log4j&lt;/artifactId&gt;&lt;version&gt;1.2.12&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;&lt;groupId&gt;junit&lt;/groupId&gt;&lt;artifactId&gt;junit&lt;/artifactId&gt;&lt;version&gt;4.12&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;&lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt;&lt;artifactId&gt;jackson-core&lt;/artifactId&gt;&lt;version&gt;2.8.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;&lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt;&lt;artifactId&gt;jackson-databind&lt;/artifactId&gt;&lt;version&gt;2.8.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;&lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt;&lt;artifactId&gt;jackson-annotations&lt;/artifactId&gt;&lt;version&gt;2.8.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;&lt;groupId&gt;org.springframework.data&lt;/groupId&gt;&lt;artifactId&gt;spring-data-elasticsearch&lt;/artifactId&gt;&lt;version&gt;3.0.5.RELEASE&lt;/version&gt;&lt;exclusions&gt;&lt;exclusion&gt;&lt;groupId&gt;org.elasticsearch.plugin&lt;/groupId&gt;&lt;artifactId&gt;transport-netty4-client&lt;/artifactId&gt;&lt;/exclusion&gt;&lt;/exclusions&gt;&lt;/dependency&gt;&lt;dependency&gt;&lt;groupId&gt;org.springframework&lt;/groupId&gt;&lt;artifactId&gt;spring-test&lt;/artifactId&gt;&lt;version&gt;5.0.4.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;&lt;groupId&gt;org.projectlombok&lt;/groupId&gt;&lt;artifactId&gt;lombok&lt;/artifactId&gt;&lt;version&gt;1.18.12&lt;/version&gt;&lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt;&lt;groupId&gt;com.alibaba&lt;/groupId&gt;&lt;artifactId&gt;fastjson&lt;/artifactId&gt;&lt;version&gt;1.2.72&lt;/version&gt;&lt;/dependency&gt;2、写实体Article@lombok.DatapublicclassArticle{privateIntegerid;privateStringtitle;privateStringcontent;}3、Daoimportcom.cn.entity.Article;importorg.springframework.data.elasticsearch.repository.ElasticsearchRepository;importorg.springframework.stereotype.Repository;@RepositorypublicinterfaceArticleRepositoryextendsElasticsearchRepository&lt;Article,Integer&gt;{}4、Serviceimportcom.cn.entity.Article;publicinterfaceArticleService{voidsave(Articlearticle);}importcom.cn.dao.ArticleRepository;importcom.cn.entity.Article;importcom.cn.service.ArticleService;importorg.springframework.stereotype.Service;importjavax.annotation.Resource;@ServicepublicclassArticleServiceImplimplementsArticleService{@ResourceprivateArticleRepositoryarticleRepository;@Overridepublicvoidsave(Articlearticle){articleRepository.save(article);}}5、配置applicationContext.xml&lt;?xmlversion=&quot;1.0&quot;encoding=&quot;UTF-8&quot;?&gt;&lt;beansxmlns=&quot;http://www.springframework.org/schema/beans&quot;xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;xmlns:context=&quot;http://www.springframework.org/schema/context&quot;xmlns:elasticsearch=&quot;http://www.springframework.org/schema/data/elasticsearch&quot;xsi:schemaLocation=&quot;http://www.springframework.org/schema/beanshttp://www.springframework.org/schema/beans/spring-beans.xsdhttp://www.springframework.org/schema/contexthttp://www.springframework.org/schema/context/spring-context.xsdhttp://www.springframework.org/schema/data/elasticsearchhttp://www.springframework.org/schema/data/elasticsearch/spring-elasticsearch-1.0.xsd&quot;&gt;&lt;!--扫描Dao包，自动创建实例--&gt;&lt;elasticsearch:repositoriesbase-package=&quot;com.cn.dao&quot;/&gt;&lt;!--扫描Service包，创建Service的实体--&gt;&lt;context:component-scanbase-package=&quot;com.cn.service&quot;/&gt;&lt;!--配置elasticSearch的连接--&gt;&lt;!--配置elasticSearch的连接--&gt;&lt;elasticsearch:transport-clientid=&quot;client&quot;cluster-nodes=&quot;localhost:9300&quot;cluster-name=&quot;elasticsearch&quot;/&gt;&lt;!--ElasticSearch模版对象--&gt;&lt;beanid=&quot;elasticsearchTemplate&quot;class=&quot;org.springframework.data.elasticsearch.core.ElasticsearchTemplate&quot;&gt;&lt;constructor-argname=&quot;client&quot;ref=&quot;client&quot;/&gt;&lt;/bean&gt;&lt;/beans&gt;6、配置实体基于springdataelasticsearch注解配置索引、映射和实体的关系importorg.springframework.data.annotation.Id;importorg.springframework.data.elasticsearch.annotations.Document;importorg.springframework.data.elasticsearch.annotations.Field;importorg.springframework.data.elasticsearch.annotations.FieldType;@lombok.Data//@Document文档对象（索引信息、文档类型）@Document(indexName=&quot;blog3&quot;,type=&quot;article&quot;)publicclassArticle{//@Id文档主键唯一标识@Id//@Field每个文档的字段配置（类型、是否分词、是否存储、分词器）@Field(store=true,index=false,type=FieldType.Integer)privateIntegerid;@Field(index=true,analyzer=&quot;ik_smart&quot;,store=true,searchAnalyzer=&quot;ik_smart&quot;,type=FieldType.text)privateStringtitle;@Field(index=true,analyzer=&quot;ik_smart&quot;,store=true,searchAnalyzer=&quot;ik_smart&quot;,type=FieldType.text)privateStringcontent;}其中，注解解释如下：@Document(indexName=&quot;blob3&quot;,type=&quot;article&quot;)：indexName：索引的名称（必填项）type：索引的类型@Id：主键的唯一标识@Field(index=true,analyzer=&quot;ik_smart&quot;,store=true,searchAnalyzer=&quot;ik_smart&quot;,type=FieldType.text)index：是否设置分词analyzer：存储时使用的分词器searchAnalyze：搜索时使用的分词器store：是否存储type:数据类型7、创建测试类SpringDataESTestpackagecom.cn.test;importcom.cn.entity.Article;importcom.cn.service.ArticleService;importorg.elasticsearch.client.transport.TransportClient;importorg.junit.Test;importorg.junit.runner.RunWith;importorg.springframework.data.elasticsearch.core.ElasticsearchTemplate;importorg.springframework.test.context.ContextConfiguration;importorg.springframework.test.context.junit4.SpringJUnit4ClassRunner;importjavax.annotation.Resource;@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations=&quot;classpath:applicationContext.xml&quot;)publicclassSpringDataESTest{@ResourceprivateArticleServicearticleService;@ResourceprivateTransportClientclient;@ResourceprivateElasticsearchTemplateelasticsearchTemplate;/**创建索引和映射*/@TestpublicvoidcreateIndex(){elasticsearchTemplate.createIndex(Article.class);elasticsearchTemplate.putMapping(Article.class);}/**测试保存文档*/@TestpublicvoidsaveArticle(){Articlearticle=newArticle();article.setId(100);article.setTitle(&quot;测试SpringDataElasticSearch&quot;);article.setContent(&quot;SpringDataElasticSearch基于springdataAPI简化elasticSearch操作，将原始操作elasticSearch的客户端API进行封装\\n&quot;+&quot;SpringData为ElasticsearchElasticsearch项目提供集成搜索引擎&quot;);articleService.save(article);}}SpringDataElasticSearch的常用操作增删改查方法测试packagecom.cn.test;importcom.cn.entity.Article;importcom.cn.service.ArticleService;importorg.elasticsearch.client.transport.TransportClient;importorg.junit.Test;importorg.junit.runner.RunWith;importorg.springframework.data.domain.Page;importorg.springframework.data.domain.PageRequest;importorg.springframework.data.domain.Pageable;importorg.springframework.data.elasticsearch.core.ElasticsearchTemplate;importorg.springframework.test.context.ContextConfiguration;importorg.springframework.test.context.junit4.SpringJUnit4ClassRunner;importjavax.annotation.Resource;@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations=&quot;classpath:applicationContext.xml&quot;)publicclassSpringDataESTest{@ResourceprivateArticleServicearticleService;@ResourceprivateTransportClientclient;@ResourceprivateElasticsearchTemplateelasticsearchTemplate;/**创建索引和映射*/@TestpublicvoidcreateIndex(){elasticsearchTemplate.createIndex(Article.class);elasticsearchTemplate.putMapping(Article.class);}/**测试保存文档*/@TestpublicvoidsaveArticle(){Articlearticle=newArticle();article.setId(100);article.setTitle(&quot;测试SpringDataElasticSearch&quot;);article.setContent(&quot;SpringDataElasticSearch基于springdataAPI简化elasticSearch操作，将原始操作elasticSearch的客户端API进行封装\\n&quot;+&quot;SpringData为ElasticsearchElasticsearch项目提供集成搜索引擎&quot;);articleService.save(article);}/***测试更新*/@Testpublicvoidupdate(){Articlearticle=newArticle();article.setId(1001);article.setTitle(&quot;elasticSearch3.0版本发布...更新&quot;);article.setContent(&quot;ElasticSearch是一个基于Lucene的搜索服务器。它提供了一个分布式多用户能力的全文搜索引擎，基于RESTfulweb接口&quot;);articleService.save(article);}/***测试删除*/@Testpublicvoiddelete(){Articlearticle=newArticle();article.setId(1001);articleService.delete(article);}/***批量插入*/@Testpublicvoidsave100(){for(inti=1;i&lt;=100;i++){Articlearticle=newArticle();article.setId(i);article.setTitle(i+&quot;elasticSearch3.0版本发布..，更新&quot;);article.setContent(i+&quot;ElasticSearch是一个基于Lucene的搜索服务器。它提供了一个分布式多用户能力的全文搜索引擎，基于RESTfulweb接口&quot;);articleService.save(article);}}/***分页查询*/@TestpublicvoidfindAllPage(){Pageablepageable=PageRequest.of(1,10);Page&lt;Article&gt;page=articleService.findAll(pageable);for(Articlearticle:page.getContent()){System.out.println(article);}}}常用查询命名规则关键字命名规则解释示例andfindByField1AndField2根据Field1和Field2获得数据findByTitleAndContentorfindByField1OrField2根据Field1或Field2获得数据findByTitleOrContentisfindByField根据Field获得数据findByTitlenotfindByFieldNot根据Field获得补集数据findByTitleNotbetweenfindByFieldBetween获得指定范围的数据findByPriceBetweenlessThanEqualfindByFieldLessThan获得小于等于指定值的数据findByPriceLessThan使用Elasticsearch的原生查询对象进行查询。@TestpublicvoidfindByNativeQuery(){//创建一个SearchQuery对象SearchQuerysearchQuery=newNativeSearchQueryBuilder()//设置查询条件，此处可以使用QueryBuilders创建多种查询.withQuery(QueryBuilders.queryStringQuery(&quot;备份节点上没有数据&quot;).defaultField(&quot;title&quot;))//还可以设置分页信息.withPageable(PageRequest.of(1,5))//创建SearchQuery对象.build();//使用模板对象执行查询elasticsearchTemplate.queryForList(searchQuery,Article.class).forEach(a-&gt;System.out.println(a));}","link":"https://haohanya.github.io/post/elasticsearch/"},{"title":" ElasticSearch（一）","content":"ElasticSearch简介什么是ElasticSearchElaticsearch，简称为es，es是一个开源的高扩展的分布式全文检索引擎，它可以近乎实时的存储、检索数据；本身扩展性很好，可以扩展到上百台服务器，处理PB级别的数据。es也使用Java开发并使用Lucene作为其核心来实现所有索引和搜索的功能，但是它的目的是通过简单的RESTfulAPI来隐藏Lucene的复杂性，从而让全文搜索变得简单。ElasticSearch的使用案例2013年初，GitHub抛弃了Solr，采取ElasticSearch来做PB级的搜索。“GitHub使用ElasticSearch搜索20TB的数据，包括13亿文件和1300亿行代码”维基百科：启动以elasticsearch为基础的核心搜索架构SoundCloud：“SoundCloud使用ElasticSearch为1.8亿用户提供即时而精准的音乐搜索服务”百度：百度目前广泛使用ElasticSearch作为文本数据分析，采集百度所有服务器上的各类指标数据及用户自定义数据，通过对各种数据进行多维分析展示，辅助定位分析实例异常或业务层面异常。目前覆盖百度内部20多个业务线（包括casio、云分析、网盟、预测、文库、直达号、钱包、风控等），单集群最大100台机器，200个ES节点，每天导入30TB+数据新浪使用ES分析处理32亿条实时日志阿里使用ES构建挖财自己的日志采集和分析体系ElasticSearch对比SolrSolr利用Zookeeper进行分布式管理，而Elasticsearch自身带有分布式协调管理功能;Solr支持更多格式的数据，而Elasticsearch仅支持json文件格式；Solr官方提供的功能更多，而Elasticsearch本身更注重于核心功能，高级功能多有第三方插件提供；Solr在传统的搜索应用中表现好于Elasticsearch，但在处理实时搜索应用时效率明显低于ElasticsearchElasticSearch安装与启动下载ES压缩包ElasticSearch分为Linux和Window版本，基于我们主要学习的是ElasticSearch的Java客户端的使用，所以我们课程中使用的是安装较为简便的Window版本，项目上线后，公司的运维人员会安装Linux版的ES供我们连接使用。ElasticSearch的官方地址：https://www.elastic.co/products/elasticsearch安装ES服务Window版的ElasticSearch的安装很简单，类似Window版的Tomcat，解压开即安装完毕，解压后的ElasticSearch的目录结构如下：修改elasticsearch配置文件：config/elasticsearch.yml，增加以下两句命令：http.cors.enabled:truehttp.cors.allow‐origin:&quot;*&quot;此步为允许elasticsearch跨越访问，如果不安装后面的elasticsearch-head是可以不修改，直接启动。启动ES服务点击ElasticSearch下的bin目录下的elasticsearch.bat启动注意：9300是tcp通讯端口，集群间和TCPClient都执行该端口，9200是http协议的RESTful接口。通过浏览器访问ElasticSearch服务器，看到如下返回的json信息，代表服务启动成功：注意：ElasticSearch是使用java开发的，且本版本的es需要的jdk版本要是1.8以上，所以安装ElasticSearch之前保证JDK1.8+安装完毕，并正确的配置好JDK环境变量，否则启动ElasticSearch失败。安装ES的图形化界面插件ElasticSearch不同于Solr自带图形化界面，我们可以通过安装ElasticSearch的head插件，完成图形化界面的效果，完成索引数据的查看。安装插件的方式有两种，在线安装和本地安装。本文档采用本地安装方式进行head插件的安装。elasticsearch-5-*以上版本安装head需要安装node和grunt下载head插件：https://github.com/mobz/elasticsearch-head将elasticsearch-head-master压缩包解压到任意目录，但是要和elasticsearch的安装目录区别开下载nodejs：https://nodejs.org/en/download/将grunt安装为全局命令，Grunt是基于Node.js的项目构建工具npminstall‐ggrunt‐cli进入elasticsearch-head-master目录启动head，在命令提示符下输入命令npminstallgruntserver打开浏览器，输入http://localhost:9100，看到如下页面ElasticSearch相关概念(术语)概述Elasticsearch是面向文档(documentoriented)的，这意味着它可以存储整个对象或文档(document)。然而它不仅仅是存储，还会索引(index)每个文档的内容使之可以被搜索。在Elasticsearch中，你可以对文档（而非成行成列的数据）进行索引、搜索、排序、过滤。Elasticsearch比传统关系型数据库如下：RelationalDB‐&gt;Databases‐&gt;Tables‐&gt;Rows‐&gt;ColumnsElasticsearch‐&gt;Indices‐&gt;Types‐&gt;Documents‐&gt;FieldsElasticsearch核心概念索引index一个索引就是一个拥有几分相似特征的文档的集合。比如说，你可以有一个客户数据的索引，另一个产品目录的索引，还有一个订单数据的索引。一个索引由一个名字来标识（必须全部是小写字母的），并且当我们要对对应于这个索引中的文档进行索引、搜索、更新和删除的时候，都要使用到这个名字。在一个集群中，可以定义任意多的索引类型type在一个索引中，你可以定义一种或多种类型。一个类型是你的索引的一个逻辑上的分类/分区，其语义完全由你来定。通常，会为具有一组共同字段的文档定义一个类型。比如说，我们假设你运营一个博客平台并且将你所有的数据存储到一个索引中。在这个索引中，你可以为用户数据定义一个类型，为博客数据定义另一个类型，当然，也可以为评论数据定义另一个类型。字段Field相当于是数据表的字段，对文档数据根据不同属性进行的分类标识映射mappingmapping是处理数据的方式和规则方面做一些限制，如某个字段的数据类型、默认值、分析器、是否被索引等等，这些都是映射里面可以设置的，其它就是处理es里面数据的一些使用规则设置也叫做映射，按着最优规则处理数据对性能提高很大，因此才需要建立映射，并且需要思考如何建立映射才能对性能更好文档document一个文档是一个可被索引的基础信息单元。比如，你可以拥有某一个客户的文档，某一个产品的一个文档，当然，也可以拥有某个订单的一个文档。文档以JSON（JavascriptObjectNotation）格式来表示，而JSON是一个到处存在的互联网数据交互格式。在一个index/type里面，你可以存储任意多的文档。注意，尽管一个文档，物理上存在于一个索引之中，文档必须被索引/赋予一个索引的type。接近实时NRTElasticsearch是一个接近实时的搜索平台。这意味着，从索引一个文档直到这个文档能够被搜索到有一个轻微的延迟（通常是1秒以内）集群cluster一个集群就是由一个或多个节点组织在一起，它们共同持有整个的数据，并一起提供索引和搜索功能。一个集群由一个唯一的名字标识，这个名字默认就是“elasticsearch”。这个名字是重要的，因为一个节点只能通过指定某个集群的名字，来加入这个集群节点node一个节点是集群中的一个服务器，作为集群的一部分，它存储数据，参与集群的索引和搜索功能。和集群类似，一个节点也是由一个名字来标识的，默认情况下，这个名字是一个随机的漫威漫画角色的名字，这个名字会在启动的时候赋予节点。这个名字对于管理工作来说挺重要的，因为在这个管理过程中，你会去确定网络中的哪些服务器对应于Elasticsearch集群中的哪些节点。一个节点可以通过配置集群名称的方式来加入一个指定的集群。默认情况下，每个节点都会被安排加入到一个叫做“elasticsearch”的集群中，这意味着，如果你在你的网络中启动了若干个节点，并假定它们能够相互发现彼此，它们将会自动地形成并加入到一个叫做“elasticsearch”的集群中。在一个集群里，只要你想，可以拥有任意多个节点。而且，如果当前你的网络中没有运行任何Elasticsearch节点，这时启动一个节点，会默认创建并加入一个叫做“elasticsearch”的集群分片和复制shards&amp;replicas一个索引可以存储超出单个结点硬件限制的大量数据。比如，一个具有10亿文档的索引占据1TB的磁盘空间，而任一节点都没有这样大的磁盘空间；或者单个节点处理搜索请求，响应太慢。为了解决这个问题，Elasticsearch提供了将索引划分成多份的能力，这些份就叫做分片。当你创建一个索引的时候，你可以指定你想要的分片的数量。每个分片本身也是一个功能完善并且独立的“索引”，这个“索引”可以被放置到集群中的任何节点上。分片很重要，主要有两方面的原因：​1）允许你水平分割/扩展你的内容容量。​2）允许你在分片（潜在地，位于多个节点上）之上进行分布式的、并行的操作，进而提高性能/吞吐量。至于一个分片怎样分布，它的文档怎样聚合回搜索请求，是完全由Elasticsearch管理的，对于作为用户的你来说，这些都是透明的。在一个网络/云的环境里，失败随时都可能发生，在某个分片/节点不知怎么的就处于离线状态，或者由于任何原因消失了，这种情况下，有一个故障转移机制是非常有用并且是强烈推荐的。为此目的，Elasticsearch允许你创建分片的一份或多份拷贝，这些拷贝叫做复制分片，或者直接叫复制。复制之所以重要，有两个主要原因：在分片/节点失败的情况下，提供了高可用性。因为这个原因，注意到复制分片从不与原/主要（original/primary）分片置于同一节点上是非常重要的。扩展你的搜索量/吞吐量，因为搜索可以在所有的复制上并行运行。总之，每个索引可以被分成多个分片。一个索引也可以被复制0次（意思是没有复制）或多次。一旦复制了，每个索引就有了主分片（作为复制源的原来的分片）和复制分片（主分片的拷贝）之别。分片和复制的数量可以在索引创建的时候指定。在索引创建之后，你可以在任何时候动态地改变复制的数量，但是你事后不能改变分片的数量。默认情况下，Elasticsearch中的每个索引被分片5个主分片和1个复制，这意味着，如果你的集群中至少有两个节点，你的索引将会有5个主分片和另外5个复制分片（1个完全拷贝），这样的话每个索引总共就有10个分片。ElasticSearch的客户端操作下载PostManPostman官网：https://www.getpostman.com使用Postman工具进行Restful接口访问ElasticSearch的接口语法curl‐X'😕/:/?&lt;QUERY_STRING&gt;'‐d''参数解释VERB适当的HTTP方法或谓词:GET、POST、PUT、HEAD或者DELETEPROTOCOLhttp或者https（如果你在Elasticsearch前面有一个https代理）HOSTElasticsearch集群中任意节点的主机名，或者用localhost代表本地机器上的节点PORT运行ElasticsearchHTTP服务的端口号，默认是9200PATHAPI的终端路径（例如_count将返回集群中文档数量）。Path可能包含多个组件，例如：_cluster/stats和_nodes/stats/jvmQUERY_STRING任意可选的查询字符串参数(例如?pretty将格式化地输出JSON返回值，使其更容易阅读)BODY一个JSON格式的请求体(如果请求需要的话)创建索引index和映射mappingcurlPUThttp://127.0.0.1:9200/blog1body{&quot;mappings&quot;:{&quot;article&quot;:{&quot;properties&quot;:{&quot;id&quot;:{&quot;type&quot;:&quot;long&quot;,&quot;store&quot;:true,&quot;index&quot;:&quot;not_analyzed&quot;},&quot;title&quot;:{&quot;type&quot;:&quot;text&quot;,&quot;store&quot;:true,&quot;index&quot;:&quot;analyzed&quot;,&quot;analyzer&quot;:&quot;standard&quot;},&quot;content&quot;:{&quot;type&quot;:&quot;text&quot;,&quot;store&quot;:true,&quot;index&quot;:&quot;analyzed&quot;,&quot;analyzer&quot;:&quot;standard&quot;}}}}}response{&quot;acknowledged&quot;:true,&quot;shards_acknowledged&quot;:true,&quot;index&quot;:&quot;blog1&quot;}创建索引后设置Mapping可以在创建索引时设置mapping信息，当然也可以先创建索引然后再设置mapping。在上一个步骤中不设置maping信息，直接使用put方法创建一个索引，然后设置mapping信息。curlposthttp://127.0.0.1:9200/blog2/hello/_mappingbody{&quot;hello&quot;:{&quot;properties&quot;:{&quot;id&quot;:{&quot;type&quot;:&quot;long&quot;,&quot;store&quot;:true},&quot;title&quot;:{&quot;type&quot;:&quot;text&quot;,&quot;store&quot;:true,&quot;index&quot;:true,&quot;analyzer&quot;:&quot;standard&quot;},&quot;content&quot;:{&quot;type&quot;:&quot;text&quot;,&quot;store&quot;:true,&quot;index&quot;:true,&quot;analyzer&quot;:&quot;standard&quot;}}}}response{&quot;acknowledged&quot;:true}删除索引indexcurldeletehttp://127.0.0.1:9200/blog1response{&quot;acknowledged&quot;:true}创建文档documentcurlposthttp://127.0.0.1:9200/blog1/article/1body{&quot;id&quot;:1,&quot;title&quot;:&quot;ElasticSearch是一个基于Lucene的搜索服务器&quot;,&quot;content&quot;:&quot;它提供了一个分布式多用户能力的全文搜索引擎，基于RESTfulweb接口。Elasticsearch是用Java开发的，并作为Apache许可条款下的开放源码发布，是当前流行的企业级搜索引擎。设计用于云计算中，能够达到实时搜索，稳定，可靠，快速，安装使用方便。&quot;}response{&quot;_index&quot;:&quot;blog1&quot;,&quot;_type&quot;:&quot;article&quot;,&quot;_id&quot;:&quot;1&quot;,&quot;_version&quot;:1,&quot;result&quot;:&quot;created&quot;,&quot;_shards&quot;:{&quot;total&quot;:2,&quot;successful&quot;:1,&quot;failed&quot;:0},&quot;created&quot;:true}修改文档documentcurlposthttp://127.0.0.1:9200/blog1/article/1body{&quot;id&quot;:1,&quot;title&quot;:&quot;[修改]ElasticSearch是一个基于Lucene的搜索服务器&quot;,&quot;content&quot;:&quot;[修改]它提供了一个分布式多用户能力的全文搜索引擎，基于RESTfulweb接口。Elasticsearch是用Java开发的，并作为Apache许可条款下的开放源码发布，是当前流行的企业级搜索引擎。设计用于云计算中，能够达到实时搜索，稳定，可靠，快速，安装使用方便。&quot;}response{&quot;_index&quot;:&quot;blog1&quot;,&quot;_type&quot;:&quot;article&quot;,&quot;_id&quot;:&quot;1&quot;,&quot;_version&quot;:2,&quot;result&quot;:&quot;updated&quot;,&quot;_shards&quot;:{&quot;total&quot;:2,&quot;successful&quot;:1,&quot;failed&quot;:0},&quot;created&quot;:false}删除文档documentcurldeletehttp://127.0.0.1:9200/blog1/article/1response{&quot;found&quot;:true,&quot;_index&quot;:&quot;blog1&quot;,&quot;_type&quot;:&quot;article&quot;,&quot;_id&quot;:&quot;1&quot;,&quot;_version&quot;:3,&quot;result&quot;:&quot;deleted&quot;,&quot;_shards&quot;:{&quot;total&quot;:2,&quot;successful&quot;:1,&quot;failed&quot;:0}}查询文档-根据id查询curlgethttp://127.0.0.1:9200/blog1/article/1response{&quot;_index&quot;:&quot;blog1&quot;,&quot;_type&quot;:&quot;article&quot;,&quot;_id&quot;:&quot;1&quot;,&quot;_version&quot;:1,&quot;found&quot;:true,&quot;_source&quot;:{&quot;id&quot;:1,&quot;title&quot;:&quot;[修改]ElasticSearch是一个基于Lucene的搜索服务器&quot;,&quot;content&quot;:&quot;[修改]它提供了一个分布式多用户能力的全文搜索引擎，基于RESTfulweb接口。Elasticsearch是用Java开发的，并作为Apache许可条款下的开放源码发布，是当前流行的企业级搜索引擎。设计用于云计算中，能够达到实时搜索，稳定，可靠，快速，安装使用方便。&quot;}}查询文档-querystring查询curlposthttp://127.0.0.1:9200/blog1/article/_searchbody{&quot;query&quot;:{&quot;query_string&quot;:{&quot;default_field&quot;:&quot;title&quot;,&quot;query&quot;:&quot;搜索服务器&quot;}}}response{&quot;took&quot;:24,&quot;timed_out&quot;:false,&quot;_shards&quot;:{&quot;total&quot;:5,&quot;successful&quot;:5,&quot;skipped&quot;:0,&quot;failed&quot;:0},&quot;hits&quot;:{&quot;total&quot;:1,&quot;max_score&quot;:1.4002227,&quot;hits&quot;:[{&quot;_index&quot;:&quot;blog1&quot;,&quot;_type&quot;:&quot;article&quot;,&quot;_id&quot;:&quot;1&quot;,&quot;_score&quot;:1.4002227,&quot;_source&quot;:{&quot;id&quot;:1,&quot;title&quot;:&quot;[修改]ElasticSearch是一个基于Lucene的搜索服务器&quot;,&quot;content&quot;:&quot;[修改]它提供了一个分布式多用户能力的全文搜索引擎，基于RESTfulweb接口。Elasticsearch是用Java开发的，并作为Apache许可条款下的开放源码发布，是当前流行的企业级搜索引擎。设计用于云计算中，能够达到实时搜索，稳定，可靠，快速，安装使用方便。&quot;}}]}}注意：将搜索内容&quot;搜索服务器&quot;修改为&quot;钢索&quot;，同样也能搜索到文档，这是因为ES是歪果仁开发的产品，所以对中文分词不友好，需要使用分词插件（IK分词器）来解决中文分词问题查询文档-term查询curlposthttp://127.0.0.1:9200/blog1/article/_searchbody{&quot;query&quot;:{&quot;term&quot;:{&quot;title&quot;:&quot;搜索&quot;}}}response{&quot;took&quot;:1,&quot;timed_out&quot;:false,&quot;_shards&quot;:{&quot;total&quot;:5,&quot;successful&quot;:5,&quot;skipped&quot;:0,&quot;failed&quot;:0},&quot;hits&quot;:{&quot;total&quot;:0,&quot;max_score&quot;:null,&quot;hits&quot;:[]}}ElasticSearch集成IK分词器上述查询存在问题分析在进行字符串查询时，我们发现去搜索&quot;搜索服务器&quot;和&quot;钢索&quot;都可以搜索到数据；而在进行词条查询时，我们搜索&quot;搜索&quot;却没有搜索到数据；究其原因是ElasticSearch的标准分词器导致的，当我们创建索引时，字段使用的是标准分词器：&quot;analyzer&quot;:&quot;standard&quot;//标准分词器例如对&quot;我是程序员&quot;进行分词标准分词器分词效果测试：curlgethttp://127.0.0.1:9200/_analyze?analyzer=standard&amp;pretty=true&amp;text=我是程序员分词结果{&quot;tokens&quot;:[{&quot;token&quot;:&quot;我&quot;,&quot;start_offset&quot;:0,&quot;end_offset&quot;:1,&quot;type&quot;:&quot;&lt;IDEOGRAPHIC&gt;&quot;,&quot;position&quot;:0},{&quot;token&quot;:&quot;是&quot;,&quot;start_offset&quot;:1,&quot;end_offset&quot;:2,&quot;type&quot;:&quot;&lt;IDEOGRAPHIC&gt;&quot;,&quot;position&quot;:1},{&quot;token&quot;:&quot;程&quot;,&quot;start_offset&quot;:2,&quot;end_offset&quot;:3,&quot;type&quot;:&quot;&lt;IDEOGRAPHIC&gt;&quot;,&quot;position&quot;:2},{&quot;token&quot;:&quot;序&quot;,&quot;start_offset&quot;:3,&quot;end_offset&quot;:4,&quot;type&quot;:&quot;&lt;IDEOGRAPHIC&gt;&quot;,&quot;position&quot;:3},{&quot;token&quot;:&quot;员&quot;,&quot;start_offset&quot;:4,&quot;end_offset&quot;:5,&quot;type&quot;:&quot;&lt;IDEOGRAPHIC&gt;&quot;,&quot;position&quot;:4}]}而我们需要的分词效果是：我、是、程序、程序员这样的话就需要对中文支持良好的分析器的支持，支持中文分词的分词器有很多，word分词器、庖丁解牛、盘古分词、Ansj分词等，但我们常用的还是下面要介绍的IK分词器。IK分词器简介IKAnalyzer是一个开源的，基于java语言开发的轻量级的中文分词工具包。从2006年12月推出1.0版开始，IKAnalyzer已经推出了3个大版本。最初，它是以开源项目Lucene为应用主体的，结合词典分词和文法分析算法的中文分词组件。新版本的IKAnalyzer3.0则发展为面向Java的公用分词组件，独立于Lucene项目，同时提供了对Lucene的默认优化实现。IK分词器3.0的特性如下：采用了特有的“正向迭代最细粒度切分算法“，具有60万字/秒的高速处理能力。采用了多子处理器分析模式，支持：英文字母（IP地址、Email、URL）、数字（日期，常用中文数量词，罗马数字，科学计数法），中文词汇（姓名、地名处理）等分词处理。对中英联合支持不是很好,在这方面的处理比较麻烦.需再做一次查询,同时是支持个人词条的优化的词典存储，更小的内存占用。支持用户词典扩展定义。针对Lucene全文检索优化的查询分析器IKQueryParser；采用歧义分析算法优化查询关键字的搜索排列组合，能极大的提高Lucene检索的命中率。ElasticSearch集成IK分词器IK分词器的安装1、下载地址：https://github.com/medcl/elasticsearch-analysis-ik/releases2、解压，将解压后的elasticsearch文件夹拷贝到elasticsearch-5.6.8\\plugins下，并重命名文件夹为analysis-ik3、重新启动ElasticSearch，即可加载IK分词器IK分词器测试IK提供了两个分词算法ik_smart和ik_max_word其中ik_smart为最少切分，ik_max_word为最细粒度划分1、最小切分curlgethttp://127.0.0.1:9200/_analyze?analyzer=ik_smart&amp;pretty=true&amp;text=我是程序员response{&quot;tokens&quot;:[{&quot;token&quot;:&quot;我&quot;,&quot;start_offset&quot;:0,&quot;end_offset&quot;:1,&quot;type&quot;:&quot;CN_CHAR&quot;,&quot;position&quot;:0},{&quot;token&quot;:&quot;是&quot;,&quot;start_offset&quot;:1,&quot;end_offset&quot;:2,&quot;type&quot;:&quot;CN_CHAR&quot;,&quot;position&quot;:1},{&quot;token&quot;:&quot;程序员&quot;,&quot;start_offset&quot;:2,&quot;end_offset&quot;:5,&quot;type&quot;:&quot;CN_WORD&quot;,&quot;position&quot;:2}]}2、最细切分curlgethttp://127.0.0.1:9200/_analyze?analyzer=ik_max_word&amp;pretty=true&amp;text=我是程序员response{&quot;tokens&quot;:[{&quot;token&quot;:&quot;我&quot;,&quot;start_offset&quot;:0,&quot;end_offset&quot;:1,&quot;type&quot;:&quot;CN_CHAR&quot;,&quot;position&quot;:0},{&quot;token&quot;:&quot;是&quot;,&quot;start_offset&quot;:1,&quot;end_offset&quot;:2,&quot;type&quot;:&quot;CN_CHAR&quot;,&quot;position&quot;:1},{&quot;token&quot;:&quot;程序员&quot;,&quot;start_offset&quot;:2,&quot;end_offset&quot;:5,&quot;type&quot;:&quot;CN_WORD&quot;,&quot;position&quot;:2},{&quot;token&quot;:&quot;程序&quot;,&quot;start_offset&quot;:2,&quot;end_offset&quot;:4,&quot;type&quot;:&quot;CN_WORD&quot;,&quot;position&quot;:3},{&quot;token&quot;:&quot;员&quot;,&quot;start_offset&quot;:4,&quot;end_offset&quot;:5,&quot;type&quot;:&quot;CN_CHAR&quot;,&quot;position&quot;:4}]}修改索引映射mapping重建索引删除原有blog1索引curldeletehttp://127.0.0.1:9200/blog1创建blog1索引，此时分词器使用ik_max_wordcurlputhttp://127.0.0.1:9200/blog1body{&quot;mappings&quot;:{&quot;article&quot;:{&quot;properties&quot;:{&quot;id&quot;:{&quot;type&quot;:&quot;long&quot;,&quot;store&quot;:true,&quot;index&quot;:&quot;not_analyzed&quot;},&quot;title&quot;:{&quot;type&quot;:&quot;text&quot;,&quot;store&quot;:true,&quot;index&quot;:&quot;analyzed&quot;,&quot;analyzer&quot;:&quot;ik_max_word&quot;},&quot;content&quot;:{&quot;type&quot;:&quot;text&quot;,&quot;store&quot;:true,&quot;index&quot;:&quot;analyzed&quot;,&quot;analyzer&quot;:&quot;ik_max_word&quot;}}}}}创建文档curlposthttp://127.0.0.1:9200/blog1/article/1body{&quot;id&quot;:1,&quot;title&quot;:&quot;ElasticSearch是一个基于Lucene的搜索服务器&quot;,&quot;content&quot;:&quot;它提供了一个分布式多用户能力的全文搜索引擎，基于RESTfulweb接口。Elasticsearch是用Java开发的，并作为Apache许可条款下的开放源码发布，是当前流行的企业级搜索引擎。设计用于云计算中，能够达到实时搜索，稳定，可靠，快速，安装使用方便。&quot;}测试queryString查询curlposthttp://127.0.0.1:9200/blog1/article/_searchresponse{&quot;took&quot;:101,&quot;timed_out&quot;:false,&quot;_shards&quot;:{&quot;total&quot;:5,&quot;successful&quot;:5,&quot;skipped&quot;:0,&quot;failed&quot;:0},&quot;hits&quot;:{&quot;total&quot;:1,&quot;max_score&quot;:1.012641,&quot;hits&quot;:[{&quot;_index&quot;:&quot;blog1&quot;,&quot;_type&quot;:&quot;article&quot;,&quot;_id&quot;:&quot;1&quot;,&quot;_score&quot;:1.012641,&quot;_source&quot;:{&quot;id&quot;:1,&quot;title&quot;:&quot;ElasticSearch是一个基于Lucene的搜索服务器&quot;,&quot;content&quot;:&quot;它提供了一个分布式多用户能力的全文搜索引擎，基于RESTfulweb接口。Elasticsearch是用Java开发的，并作为Apache许可条款下的开放源码发布，是当前流行的企业级搜索引擎。设计用于云计算中，能够达到实时搜索，稳定，可靠，快速，安装使用方便。&quot;}}]}}这次再次测试钢索则无法搜索到内容term测试curlposthttp://127.0.0.1:9200/blog1/article/_searchbody{&quot;query&quot;:{&quot;term&quot;:{&quot;title&quot;:&quot;搜索&quot;}}}response{&quot;took&quot;:5,&quot;timed_out&quot;:false,&quot;_shards&quot;:{&quot;total&quot;:5,&quot;successful&quot;:5,&quot;skipped&quot;:0,&quot;failed&quot;:0},&quot;hits&quot;:{&quot;total&quot;:1,&quot;max_score&quot;:0.25316024,&quot;hits&quot;:[{&quot;_index&quot;:&quot;blog1&quot;,&quot;_type&quot;:&quot;article&quot;,&quot;_id&quot;:&quot;1&quot;,&quot;_score&quot;:0.25316024,&quot;_source&quot;:{&quot;id&quot;:1,&quot;title&quot;:&quot;ElasticSearch是一个基于Lucene的搜索服务器&quot;,&quot;content&quot;:&quot;它提供了一个分布式多用户能力的全文搜索引擎，基于RESTfulweb接口。Elasticsearch是用Java开发的，并作为Apache许可条款下的开放源码发布，是当前流行的企业级搜索引擎。设计用于云计算中，能够达到实时搜索，稳定，可靠，快速，安装使用方便。&quot;}}]}}ElasticSearch集群ES集群是一个P2P类型(使用gossip协议)的分布式系统，除了集群状态管理以外，其他所有的请求都可以发送到集群内任意一台节点上，这个节点可以自己找到需要转发给哪些节点，并且直接跟这些节点通信。所以，从网络架构及服务配置上来说，构建集群所需要的配置极其简单。在Elasticsearch2.0之前，无阻碍的网络下，所有配置了相同cluster.name的节点都自动归属到一个集群中。2.0版本之后，基于安全的考虑避免开发环境过于随便造成的麻烦，从2.0版本开始，默认的自动发现方式改为了单播(unicast)方式。配置里提供几台节点的地址，ES将其视作gossiprouter角色，借以完成集群的发现。由于这只是ES内一个很小的功能，所以gossiprouter角色并不需要单独配置，每个ES节点都可以担任。所以，采用单播方式的集群，各节点都配置相同的几个节点列表作为router即可。集群中节点数量没有限制，一般大于等于2个节点就可以看做是集群了。一般处于高性能及高可用方面来考虑一般集群中的节点数量都是3个及3个以上。集群的相关概念集群cluster一个集群就是由一个或多个节点组织在一起，它们共同持有整个的数据，并一起提供索引和搜索功能。一个集群由一个唯一的名字标识，这个名字默认就是“elasticsearch”。这个名字是重要的，因为一个节点只能通过指定某个集群的名字，来加入这个集群节点node一个节点是集群中的一个服务器，作为集群的一部分，它存储数据，参与集群的索引和搜索功能。和集群类似，一个节点也是由一个名字来标识的，默认情况下，这个名字是一个随机的漫威漫画角色的名字，这个名字会在启动的时候赋予节点。这个名字对于管理工作来说挺重要的，因为在这个管理过程中，你会去确定网络中的哪些服务器对应于Elasticsearch集群中的哪些节点。一个节点可以通过配置集群名称的方式来加入一个指定的集群。默认情况下，每个节点都会被安排加入到一个叫做“elasticsearch”的集群中，这意味着，如果你在你的网络中启动了若干个节点，并假定它们能够相互发现彼此，它们将会自动地形成并加入到一个叫做“elasticsearch”的集群中。在一个集群里，只要你想，可以拥有任意多个节点。而且，如果当前你的网络中没有运行任何Elasticsearch节点，这时启动一个节点，会默认创建并加入一个叫做“elasticsearch”的集群。分片和复制shards&amp;replicas一个索引可以存储超出单个结点硬件限制的大量数据。比如，一个具有10亿文档的索引占据1TB的磁盘空间，而任一节点都没有这样大的磁盘空间；或者单个节点处理搜索请求，响应太慢。为了解决这个问题，Elasticsearch提供了将索引划分成多份的能力，这些份就叫做分片。当你创建一个索引的时候，你可以指定你想要的分片的数量。每个分片本身也是一个功能完善并且独立的“索引”，这个“索引”可以被放置到集群中的任何节点上。分片很重要，主要有两方面的原因：1）允许你水平分割/扩展你的内容容量。2）允许你在分片（潜在地，位于多个节点上）之上进行分布式的、并行的操作，进而提高性能/吞吐量。至于一个分片怎样分布，它的文档怎样聚合回搜索请求，是完全由Elasticsearch管理的，对于作为用户的你来说，这些都是透明的。在一个网络/云的环境里，失败随时都可能发生，在某个分片/节点不知怎么的就处于离线状态，或者由于任何原因消失了，这种情况下，有一个故障转移机制是非常有用并且是强烈推荐的。为此目的，Elasticsearch允许你创建分片的一份或多份拷贝，这些拷贝叫做复制分片，或者直接叫复制。复制之所以重要，有两个主要原因：在分片/节点失败的情况下，提供了高可用性。因为这个原因，注意到复制分片从不与原/主要（original/primary）分片置于同一节点上是非常重要的。扩展你的搜索量/吞吐量，因为搜索可以在所有的复制上并行运行。总之，每个索引可以被分成多个分片。一个索引也可以被复制0次（意思是没有复制）或多次。一旦复制了，每个索引就有了主分片（作为复制源的原来的分片）和复制分片（主分片的拷贝）之别。分片和复制的数量可以在索引创建的时候指定。在索引创建之后，你可以在任何时候动态地改变复制的数量，但是你事后不能改变分片的数量。默认情况下，Elasticsearch中的每个索引被分片5个主分片和1个复制，这意味着，如果你的集群中至少有两个节点，你的索引将会有5个主分片和另外5个复制分片（1个完全拷贝），这样的话每个索引总共就有10个分片。集群的搭建准备三台elasticsearch服务器创建elasticsearch-cluster文件夹，在内部复制三个elasticsearch服务修改每台服务器配置修改elasticsearch-cluster\\node*\\config\\elasticsearch.yml配置文件node1节点：#节点3的配置信息：#集群名称，保证唯一cluster.name:my-elasticsearch#节点名称，必须不一样node.name:node-1#必须为本机的ip地址network.host:127.0.0.1#服务端口号，在同一机器下必须不一样http.port:9200#集群间通信端口号，在同一机器下必须不一样transport.tcp.port:9300#设置集群自动发现机器ip集合discovery.zen.ping.unicast.hosts:[&quot;127.0.0.1:9300&quot;,&quot;127.0.0.1:9301&quot;,&quot;127.0.0.1:9302&quot;]node2节点：#节点3的配置信息：#集群名称，保证唯一cluster.name:my-elasticsearch#节点名称，必须不一样node.name:node-2#必须为本机的ip地址network.host:127.0.0.1#服务端口号，在同一机器下必须不一样http.port:9201#集群间通信端口号，在同一机器下必须不一样transport.tcp.port:9301#设置集群自动发现机器ip集合discovery.zen.ping.unicast.hosts:[&quot;127.0.0.1:9300&quot;,&quot;127.0.0.1:9301&quot;,&quot;127.0.0.1:9302&quot;]node3节点：#节点3的配置信息：#集群名称，保证唯一cluster.name:my-elasticsearch#节点名称，必须不一样node.name:node-3#必须为本机的ip地址network.host:127.0.0.1#服务端口号，在同一机器下必须不一样http.port:9202#集群间通信端口号，在同一机器下必须不一样transport.tcp.port:9302#设置集群自动发现机器ip集合discovery.zen.ping.unicast.hosts:[&quot;127.0.0.1:9300&quot;,&quot;127.0.0.1:9301&quot;,&quot;127.0.0.1:9302&quot;]启动各个节点服务器双击elasticsearch-cluster\\node*\\bin\\elasticsearch.bat集群测试添加索引和映射curlputhttp://127.0.0.1:9200/blog1body{&quot;mappings&quot;:{&quot;article&quot;:{&quot;properties&quot;:{&quot;id&quot;:{&quot;type&quot;:&quot;long&quot;,&quot;store&quot;:true,&quot;index&quot;:&quot;not_analyzed&quot;},&quot;title&quot;:{&quot;type&quot;:&quot;text&quot;,&quot;store&quot;:true,&quot;index&quot;:&quot;analyzed&quot;,&quot;analyzer&quot;:&quot;ik_max_word&quot;},&quot;content&quot;:{&quot;type&quot;:&quot;text&quot;,&quot;store&quot;:true,&quot;index&quot;:&quot;analyzed&quot;,&quot;analyzer&quot;:&quot;ik_max_word&quot;}}}}}添加文档curlposthttp://127.0.0.1:9200/blog1/article/1body{&quot;id&quot;:1,&quot;title&quot;:&quot;ElasticSearch是一个基于Lucene的搜索服务器&quot;,&quot;content&quot;:&quot;它提供了一个分布式多用户能力的全文搜索引擎，基于RESTfulweb接口。Elasticsearch是用Java开发的，并作为Apache许可条款下的开放源码发布，是当前流行的企业级搜索引擎。设计用于云计算中，能够达到实时搜索，稳定，可靠，快速，安装使用方便。&quot;}response{&quot;_index&quot;:&quot;blog1&quot;,&quot;_type&quot;:&quot;article&quot;,&quot;_id&quot;:&quot;1&quot;,&quot;_version&quot;:1,&quot;result&quot;:&quot;created&quot;,&quot;_shards&quot;:{&quot;total&quot;:2,&quot;successful&quot;:1,&quot;failed&quot;:0},&quot;created&quot;:true}使用elasticsearch-header查看集群情况如果分片副本出现UNASSIGNED可能原因是配置出错或者是硬盘使用率大于80%，可以调整使用率来解决curlputhttp://127.0.0.1:9200/_cluster/settingsbody{&quot;transient&quot;:{&quot;cluster.routing.allocation.disk.watermark.low&quot;:&quot;95%&quot;}}","link":"https://haohanya.github.io/post/elasticsearch1/"},{"title":"RabbitMQ（二）","content":"RabbitMQ高级特性消息可靠性投递ConsumerACK消费段限流TTL死信队列延迟队列日志与监控消息可靠性分析与追踪管理RabbitMQ实际应用问题消息可靠性消息幂等性RabbitMQ高级特性消息可靠性投递简介在使用RabbitMQ的时候，作为消息的发送方希望杜绝任何消息的丢失或者是消息的投递失败场景。RabbitMQ为我们提供了两种方式开控制消息的可靠性投递模式confrim确认模式return退回模式RabbitMQ真实消息投递的路径producer--&gt;borker(RabbitMQserver)--&gt;exchange--&gt;queue--&gt;consumer消息重producer到exchange则会返回一个confirmCallback（confrim确认模式）消息从exchange到queue投递失败则会返回一个returnCallback（return退回模式）我们将利用这两个callback控制消息的可靠性投递实战案例创建producer（生产者）添加依赖&lt;dependencies&gt;&lt;dependency&gt;&lt;groupId&gt;org.springframework&lt;/groupId&gt;&lt;artifactId&gt;spring-context&lt;/artifactId&gt;&lt;version&gt;5.1.7.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;!--添加rabbitmq和spring整合--&gt;&lt;dependency&gt;&lt;groupId&gt;org.springframework.amqp&lt;/groupId&gt;&lt;artifactId&gt;spring-rabbit&lt;/artifactId&gt;&lt;version&gt;2.1.8.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;&lt;groupId&gt;junit&lt;/groupId&gt;&lt;artifactId&gt;junit&lt;/artifactId&gt;&lt;version&gt;4.12&lt;/version&gt;&lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt;&lt;groupId&gt;org.springframework&lt;/groupId&gt;&lt;artifactId&gt;spring-test&lt;/artifactId&gt;&lt;version&gt;5.1.7.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;/dependencies&gt;添加配置文件rabbitmq.propertiesrabbitmq.host=192.168.25.134rabbitmq.port=5672rabbitmq.username=guestrabbitmq.password=guestrabbitmq.virtual-host=/spring-rabbitmq-producer.xml&lt;?xmlversion=&quot;1.0&quot;encoding=&quot;UTF-8&quot;?&gt;&lt;beansxmlns=&quot;http://www.springframework.org/schema/beans&quot;xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;xmlns:context=&quot;http://www.springframework.org/schema/context&quot;xmlns:rabbit=&quot;http://www.springframework.org/schema/rabbit&quot;xsi:schemaLocation=&quot;http://www.springframework.org/schema/beanshttp://www.springframework.org/schema/beans/spring-beans.xsdhttp://www.springframework.org/schema/contexthttps://www.springframework.org/schema/context/spring-context.xsdhttp://www.springframework.org/schema/rabbithttp://www.springframework.org/schema/rabbit/spring-rabbit.xsd&quot;&gt;&lt;!--加载配置文件--&gt;&lt;context:property-placeholderlocation=&quot;classpath:rabbitmq.properties&quot;/&gt;&lt;!--定义rabbitmqconnectionFactroy--&gt;&lt;rabbit:connection-factoryid=&quot;connectionFactory&quot;host=&quot;${rabbitmq.host}&quot;port=&quot;${rabbitmq.port}&quot;username=&quot;${rabbitmq.username}&quot;password=&quot;${rabbitmq.username}&quot;virtual-host=&quot;${rabbitmq.virtual-host}&quot;publisher-confirms=&quot;true&quot;publisher-returns=&quot;true&quot;/&gt;&lt;!--定义管理交换机、队列--&gt;&lt;rabbit:adminconnection-factory=&quot;connectionFactory&quot;/&gt;&lt;!--定义rabbitTemplate对象操作消息--&gt;&lt;rabbit:templateid=&quot;rabbitTemplate&quot;connection-factory=&quot;connectionFactory&quot;/&gt;&lt;!--消息可靠性投递--&gt;&lt;rabbit:queueid=&quot;test_queue_confirm&quot;name=&quot;test_queue_confirm&quot;/&gt;&lt;!--创建交换器，并且绑定queue--&gt;&lt;rabbit:direct-exchangename=&quot;test_exchange_confirm&quot;&gt;&lt;rabbit:bindings&gt;&lt;rabbit:bindingqueue=&quot;test_queue_confirm&quot;key=&quot;confirm&quot;/&gt;&lt;/rabbit:bindings&gt;&lt;/rabbit:direct-exchange&gt;&lt;/beans&gt;测试确认模式packagecom.cn.test;importorg.junit.Test;importorg.junit.runner.RunWith;importorg.springframework.amqp.rabbit.connection.CorrelationData;importorg.springframework.amqp.rabbit.core.RabbitTemplate;importorg.springframework.test.context.ContextConfiguration;importorg.springframework.test.context.junit4.SpringJUnit4ClassRunner;importjavax.annotation.Resource;@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations=&quot;classpath:spring-rabbitmq-producer.xml&quot;)publicclassProducerTest{@ResourceprivateRabbitTemplaterabbitTemplate;/***测试确认模式*思路：*1、开启确认模式*2、定义confirmCallback回调函数**/@TestpublicvoidtestConfirm(){//1、开启确认模式rabbitTemplate.setMandatory(true);//2、定义回调函数(confirmCallback：消息从producer到exchange的可靠性)rabbitTemplate.setConfirmCallback(newRabbitTemplate.ConfirmCallback(){/****@paramcorrelationData相关配置信息*@parambexchange交换机是否成功收到消息，如果为true则成功，false失败*@params表示失败的原因*/@Overridepublicvoidconfirm(CorrelationDatacorrelationData,booleanb,Strings){System.out.println(&quot;confirm方法被执行了...&quot;);if(b){//消息成功接收System.out.println(&quot;消息发送成功：&quot;+s);}else{//消息接收失败System.out.println(&quot;消息发送失败:&quot;+s);//做一些业务处理，如:让消息再次发送，在实际开发中消息发送失败后需要再次发送}}});//发送消息rabbitTemplate.convertAndSend(&quot;test_exchange_confirm&quot;,&quot;confirm&quot;,&quot;messageconfirm....&quot;);}}测试结果如果是正确的，那么会走消息发送成功的逻辑，如果失败了，会执行消息发送失败的逻辑测试回退模式/***测试回退模式：测试从exchange到queue的消息可靠性*会退模式:当消息噶给exchange之后，exchange路由到queue有可能会失败的，如果失败会执行returnCallback*步骤：*1、开启回退模式*2、设置returnCallBack*3、设置exchange消息处理模式*/@TestpublicvoidtestReturn(){//1、开启回退模式rabbitTemplate.setMandatory(true);//2、设置ReturnCallBackrabbitTemplate.setReturnCallback(newRabbitTemplate.ReturnCallback(){/****@parammessage消息对象*@parami错误代码*@params错误信息*@params1交换器*@params2路由键*/@OverridepublicvoidreturnedMessage(Messagemessage,inti,Strings,Strings1,Strings2){System.out.println(&quot;return被执行了&quot;);System.out.println(&quot;消息对象：&quot;+message);System.out.println(&quot;错误代码：&quot;+i);System.out.println(&quot;错误信息：&quot;+s);System.out.println(&quot;出错的交换器：&quot;+s1);System.out.println(&quot;出错的路由键：&quot;+s2);}});//3、发送消息rabbitTemplate.convertAndSend(&quot;test_exchange_confirm&quot;,&quot;confirm111&quot;,&quot;messageconfirm....&quot;);}正常情况下是不会执行returnCallBack方法的，只有在出错的情况下才会执行，测试时可以手动将路由键给修改为错误的再测试小结设置ConnectionFactroy的publisher-confrim=&quot;true&quot;开启确认模式使用rabbitTemplate.setConfirmCallback设置回调函数，当消息发送到exchange之后回调confirm方法。在方法中去判断ack，如果未true则表示发送成功，如果未false，表示发送失败需要去处理设置ConnectionFatroy的publisher-returns=&quot;true&quot;开启回退模式使用rabbitTemplate.setReturnCallback设置退回函数，当消息从exchange路由到queue失败后，如果设置了rabbitTemplate.setMandatory(true)参数，则会将消息回退给producer，并且执行returnedMessage方法在RabbitMQ中提供了事务的机制来解决消息投递可靠性的问题，但是性能较差，实际开发中并不适用ConsumerACK介绍ack：acknowledge确认表示消费段收到消息后的确认方式确认方式一共有三种acknowledge=&quot;none&quot;自动acknowledge=&quot;manual&quot;手动确认acknowledge=&quot;auto&quot;根据异常情况确认（这种方式使用起来很麻烦，开发中基本不用）其中自动确认是指：当消息一旦被Consumer接收到，则自动确认手动，并且将message从RabbitMQ的消息缓存中移除，但是实际业务处理中，很可能消息接收到了，但是业务处理出现了异常，那么该消息就丢失了。如果设置了手动确认方式，则需要在业务处理成功后调用channel.basicAck()手动签收，如果出现异常，则调用channel.basicNack()方法，让其自动重新发送消息创建consumer工程添加依赖&lt;dependencies&gt;&lt;dependency&gt;&lt;groupId&gt;org.springframework&lt;/groupId&gt;&lt;artifactId&gt;spring-context&lt;/artifactId&gt;&lt;version&gt;5.1.7.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;&lt;groupId&gt;org.springframework.amqp&lt;/groupId&gt;&lt;artifactId&gt;spring-rabbit&lt;/artifactId&gt;&lt;version&gt;2.1.8.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;&lt;groupId&gt;junit&lt;/groupId&gt;&lt;artifactId&gt;junit&lt;/artifactId&gt;&lt;version&gt;4.12&lt;/version&gt;&lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt;&lt;groupId&gt;org.springframework&lt;/groupId&gt;&lt;artifactId&gt;spring-test&lt;/artifactId&gt;&lt;version&gt;5.1.7.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;/dependencies&gt;编写配置文件spring-rabbitmq-consumer.xml&lt;?xmlversion=&quot;1.0&quot;encoding=&quot;UTF-8&quot;?&gt;&lt;beansxmlns=&quot;http://www.springframework.org/schema/beans&quot;xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;xmlns:context=&quot;http://www.springframework.org/schema/context&quot;xmlns:rabbit=&quot;http://www.springframework.org/schema/rabbit&quot;xsi:schemaLocation=&quot;http://www.springframework.org/schema/beanshttp://www.springframework.org/schema/beans/spring-beans.xsdhttp://www.springframework.org/schema/contexthttps://www.springframework.org/schema/context/spring-context.xsdhttp://www.springframework.org/schema/rabbithttp://www.springframework.org/schema/rabbit/spring-rabbit.xsd&quot;&gt;&lt;!--加载配置文件--&gt;&lt;context:property-placeholderlocation=&quot;classpath:rabbitmq.properties&quot;&gt;&lt;/context:property-placeholder&gt;&lt;!--定义rabbitmqconnectionFactroy--&gt;&lt;rabbit:connection-factoryid=&quot;connectionFactory&quot;host=&quot;${rabbitmq.host}&quot;port=&quot;${rabbitmq.port}&quot;username=&quot;${rabbitmq.username}&quot;password=&quot;${rabbitmq.username}&quot;virtual-host=&quot;${rabbitmq.virtual-host}&quot;publisher-confirms=&quot;true&quot;publisher-returns=&quot;true&quot;&gt;&lt;/rabbit:connection-factory&gt;&lt;!--添加包扫描，方便后期监听器交给spirng管理--&gt;&lt;context:component-scanbase-package=&quot;com.cn.listener&quot;&gt;&lt;/context:component-scan&gt;&lt;!--定义监听器容器--&gt;&lt;rabbit:listener-containerconnection-factory=&quot;connectionFactory&quot;&gt;&lt;rabbit:listenerref=&quot;ackListener&quot;queue-names=&quot;test_queue_confirm&quot;&gt;&lt;/rabbit:listener&gt;&lt;/rabbit:listener-container&gt;&lt;/beans&gt;rabbitmq.propertiesrabbitmq.host=192.168.25.134rabbitmq.port=5672rabbitmq.username=guestrabbitmq.password=guestrabbitmq.virtual-host=/编写监听类packagecom.cn.listener;importorg.springframework.amqp.core.AcknowledgeMode;importorg.springframework.amqp.core.Message;importorg.springframework.amqp.core.MessageListener;importorg.springframework.stereotype.Component;@ComponentpublicclassAckListenerimplementsMessageListener{publicvoidonMessage(Messagemessage){System.out.println(message.getBody());}publicvoidcontainerAckMode(AcknowledgeModemode){}}编写测试类importorg.junit.Test;importorg.junit.runner.RunWith;importorg.springframework.test.context.ContextConfiguration;importorg.springframework.test.context.junit4.SpringJUnit4ClassRunner;@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations=&quot;classpath:spring-rabbitmq-consumer.xml&quot;)publicclassConsumerTest{//为了实现监听的效果，写个死循环，一直读取配置文件@Testpublicvoidtest(){while(true){}}}从消息生产者工程中发送一个消息，然后在消费者工程里就可以接收到消息了手动签收上面默认就是自动签收修改配置文件为手动签收&lt;!--定义监听器容器acknowledge=&quot;manual&quot;:表示手动签收--&gt;&lt;rabbit:listener-containerconnection-factory=&quot;connectionFactory&quot;acknowledge=&quot;manual&quot;&gt;&lt;rabbit:listenerref=&quot;ackListener&quot;queue-names=&quot;test_queue_confirm&quot;&gt;&lt;/rabbit:listener&gt;&lt;/rabbit:listener-container&gt;在consumer中启动ack机制packagecom.cn.listener;importcom.rabbitmq.client.Channel;importorg.springframework.amqp.core.AcknowledgeMode;importorg.springframework.amqp.core.Message;importorg.springframework.amqp.core.MessageListener;importorg.springframework.amqp.rabbit.listener.api.ChannelAwareMessageListener;importorg.springframework.stereotype.Component;/***ConsumerACK机制:*1.设置手动签收：acknowledge=&quot;manual&quot;*2.让监听器实现ChannelAwareMessageListener接口*3.如果消息处理成功，则调用channel的basicAck()签收*4.如果消息处理失败，则调用channel的basicNack()拒绝签收，rabbitMQServer就会重新发消息给consumer*/@ComponentpublicclassAckListenerimplementsChannelAwareMessageListener{publicvoidonMessage(Messagemessage,Channelchannel)throwsException{//默认是自动签收longdeliveryTag=message.getMessageProperties().getDeliveryTag();try{//1.接收消息System.out.println(newString(message.getBody()));//2.处理业务inti=3/0;//模拟业务出现问题//3.如果业务处理成功，那么就签收channel.basicAck(deliveryTag,true);}catch(Exceptione){/***4.拒绝签收*第三个参数：为true表示该消息重新会到queue中，borker会重新发送该消息给消费端*/channel.basicNack(deliveryTag,true,true);}}publicvoidonMessage(Messagemessage){}publicvoidcontainerAckMode(AcknowledgeModemode){}}小结在rabbit:listener-container标签中设置acknowledge=&quot;manual&quot;，表示采用手动签收如果消费者没有出现异常，则调用channel.basicAck(deliveryTag,true);签收消息，那么消息才会从rabbitmq中删除如果在消费者出现了异常，则在catch中调用channel.basicNack(deliveryTag,true,true);拒绝消息，让MQ重新发送消息消息的可靠性如何保证？1.持久化​exchange要持久化​queue要持久化​message要持久化2.生产方确认Confirm3.消费方要Ack4.Broker高可用（rabbitMQ要搭建集群）消费端限流编写listenerpackagecom.cn.listener;importcom.rabbitmq.client.Channel;importorg.springframework.amqp.core.AcknowledgeMode;importorg.springframework.amqp.core.Message;importorg.springframework.amqp.rabbit.listener.api.ChannelAwareMessageListener;importorg.springframework.stereotype.Component;/***限流机制:*1.确保ack机制为手动确认*2.listener-container中配置prefetch=&quot;1&quot;，表示消费端每次从mq去拉去一条消息来消费，知道手动确认消息消费完毕后，才会继续去拉去洗一条消息*/@ComponentpublicclassQosListenerimplementsChannelAwareMessageListener{publicvoidonMessage(Messagemessage,Channelchannel)throwsException{Thread.sleep(1000);//1.获取消息System.out.println(newString(message.getBody()));//2.处理业务逻辑//3.签收channel.basicAck(message.getMessageProperties().getDeliveryTag(),true);}publicvoidonMessage(Messagemessage){}publicvoidcontainerAckMode(AcknowledgeModemode){}}编写配置文件&lt;!--定义监听器容器acknowledge=&quot;manual&quot;:表示手动签收--&gt;&lt;rabbit:listener-containerconnection-factory=&quot;connectionFactory&quot;acknowledge=&quot;manual&quot;prefetch=&quot;1&quot;&gt;&lt;!--&lt;rabbit:listenerref=&quot;ackListener&quot;queue-names=&quot;test_queue_confirm&quot;&gt;&lt;/rabbit:listener&gt;--&gt;&lt;rabbit:listenerref=&quot;qosListener&quot;queue-names=&quot;test_queue_confirm&quot;&gt;&lt;/rabbit:listener&gt;&lt;/rabbit:listener-container&gt;测试先通过producer发送10条消息到rabbitmq，然后启动consumer，发现是可以正常消费的，然后将prefetch=&quot;3&quot;，表示每次从rabbitmq拉取3条消息，再将签收注释掉，会发现一次性拉取了3条消息小结在listener-container中设置prefetch可以设置消费端一次性可以拉取多少条消息消费段一定要使用ack模式（手动签收）根据系统的承载量决定每次拉取多少消息TTL简介TTL：TimeToLive（存活时间/过期时间）当消息到达存活时间后，还没有被消费，会被自动清除RabbitMQ可以对消息设置过期时间，也可也对整个队列（Queue）设置过期时间应用场景问题1:如果用户下了订单后，并没有及时的支付，那么库存是一致归下了订单的用户，还是需要归还？需要问题2：如何归还库存？​一般的情况下，设置一个定时任务，每天凌晨1-3点之间执行，查看你的订单是否在24小时内支付了，如果没有支付，那么将库存返回​如果是秒杀情况下，用户的需求就是如果下了订单后，半小时没有支付，就返回库存（可以使用SpringTask每隔一段时间查询一次订单表和支付记录表，查询结果的是半个小时没有支付，那么返回库存）问题3：那么定时任务设置时间间隔多少合适？​如果是1分钟执行一次，（如：10点开始，10：10秒杀了一件商品），肯定是可以的，但毫无疑问存在时间的误差（误差1分钟可以接收），但查询数据库太频繁，肯定非常影响系统的性能producer中配置ttl&lt;!--ttl--&gt;&lt;rabbit:queuename=&quot;test_queue_ttl&quot;id=&quot;test_queue_ttl&quot;&gt;&lt;!--设置queue的参数注意一定要加value-type,因为类型默认是string，如果不设置就会出现类型错误--&gt;&lt;rabbit:queue-arguments&gt;&lt;entrykey=&quot;x-message-ttl&quot;value=&quot;10000&quot;value-type=&quot;java.lang.Integer&quot;&gt;&lt;/entry&gt;&lt;/rabbit:queue-arguments&gt;&lt;/rabbit:queue&gt;&lt;!--声明一个topic交换机--&gt;&lt;rabbit:topic-exchangename=&quot;test_exchange_ttl&quot;&gt;&lt;rabbit:bindings&gt;&lt;rabbit:bindingpattern=&quot;ttl.#&quot;queue=&quot;test_queue_ttl&quot;&gt;&lt;/rabbit:binding&gt;&lt;/rabbit:bindings&gt;&lt;/rabbit:topic-exchange&gt;在producer的测试类中编码/***TTL：过期时间*步骤：*1.队列统一过期*/@TestpublicvoidtestTtl(){for(inti=0;i&lt;10;i++){rabbitTemplate.convertAndSend(&quot;test_exchange_ttl&quot;,&quot;ttl.hello&quot;,&quot;messagettl....&quot;);}}在执行后，可以看到10秒钟后，queue中的消息就消失了可以单独设置过期时间/***TTL：过期时间*步骤：*1.队列统一过期**2.单独设置过期*/@TestpublicvoidtestTtl(){//一：统一过期//for(inti=0;i&lt;10;i++){//rabbitTemplate.convertAndSend(&quot;test_exchange_ttl&quot;,&quot;ttl.hello&quot;,&quot;messagettl....&quot;);//}MessagePostProcessormessagePostProcessor=newMessagePostProcessor(){publicMessagepostProcessMessage(Messagemessage)throwsAmqpException{//1.设置message的消息message.getMessageProperties().setExpiration(&quot;5000&quot;);//消息的过期时间，单位字符串//2.返回该消息returnmessage;}};//消息单独过期for(inti=0;i&lt;10;i++){if(i==5){//这条消息就单独过期(过期时间是5秒)rabbitTemplate.convertAndSend(&quot;test_exchange_ttl&quot;,&quot;ttl.hehe&quot;,&quot;messagettl....&quot;,messagePostProcessor);}else{//其他的过期时间默认的rabbitTemplate.convertAndSend(&quot;test_exchange_ttl&quot;,&quot;ttl.hello&quot;,&quot;messagettl....&quot;);}}}死信队列什么是死信队列死信队列（英文缩写：DLX），在RabbitMQ中叫DeadLetterExchange（死信交换机），当消息成为DeadMessage之后，可以被重新发送到另一个交换机中，这个交换机就叫DLX消息在什么情况下会成功死信消息成为死信有三种情况队列消息长度达到限制消费者拒绝消费消息，并且不把消息重新放入到原目标队列中（requeue=false）原队列存在消息过期设置，消息到达时间没有被消费队列如何绑定死信交换器BVCXVBNM,MNBGVCX队列绑定死信交换机：consumer中的配置死信&lt;!--死信队列:1.声明一个正常的队列（test_queue_dlx）和官换机(test_exchange_dlx)2.声明死信队列(queue_dlx)和死信交换机(exchange_dlx)--&gt;&lt;!--1.声明一个正常的队列（test_queue_dlx）和官换机(test_exchange_dlx)--&gt;&lt;rabbit:queuename=&quot;test_queue_dlx&quot;id=&quot;test_queue_dlx&quot;&gt;&lt;!--将正常的队列绑定死信交换机--&gt;&lt;rabbit:queue-arguments&gt;&lt;!--x-dead-letter-exchange:死信交换机名--&gt;&lt;entrykey=&quot;x-dead-letter-exchange&quot;value=&quot;exchange_dlx&quot;/&gt;&lt;!--发送给死信交换机的routingkey--&gt;&lt;entrykey=&quot;x-dead-letter-routing-key&quot;value=&quot;dlx.hehe&quot;/&gt;&lt;!--设置队列的过期时间ttl--&gt;&lt;entrykey=&quot;x-message-ttl&quot;value=&quot;10000&quot;value-type=&quot;java.lang.Integer&quot;/&gt;&lt;!--设置队列的长度限制--&gt;&lt;entrykey=&quot;x-max-length&quot;value=&quot;10&quot;value-type=&quot;java.lang.Integer&quot;/&gt;&lt;/rabbit:queue-arguments&gt;&lt;/rabbit:queue&gt;&lt;rabbit:topic-exchangename=&quot;test_exchange_dlx&quot;&gt;&lt;rabbit:bindings&gt;&lt;rabbit:bindingpattern=&quot;test.dlx.#&quot;queue=&quot;test_queue_dlx&quot;&gt;&lt;/rabbit:binding&gt;&lt;/rabbit:bindings&gt;&lt;/rabbit:topic-exchange&gt;&lt;!--声明死信队列(queue_dlx)和死信交换机(exchange_dlx)--&gt;&lt;rabbit:queuename=&quot;queue_dlx&quot;id=&quot;queue_dlx&quot;&gt;&lt;/rabbit:queue&gt;&lt;rabbit:topic-exchangename=&quot;exchange_dlx&quot;&gt;&lt;rabbit:bindings&gt;&lt;rabbit:bindingpattern=&quot;dlx.#&quot;queue=&quot;queue_dlx&quot;&gt;&lt;/rabbit:binding&gt;&lt;/rabbit:bindings&gt;&lt;/rabbit:topic-exchange&gt;在consumer中测试@TestpublicvoidtestDlx(){//1.测试过期时间，到了过期就会到死信中（不启动消费者）//rabbitTemplate.convertAndSend(&quot;test_exchange_dlx&quot;,&quot;test.dlx.haha&quot;,&quot;我是一条消息，我会死吗？&quot;);//2.测试长度超过上限后，多余的进入到死信中//for(inti=0;i&lt;20;i++){//rabbitTemplate.convertAndSend(&quot;test_exchange_dlx&quot;,&quot;test.dlx.haha&quot;,&quot;我是一条消息，我会死吗？&quot;);//}//3.测试消息拒收rabbitTemplate.convertAndSend(&quot;test_exchange_dlx&quot;,&quot;test.dlx.haha&quot;,&quot;我是一条消息，我会死吗？&quot;);}在consumer中拒收消息packagecom.cn.listener;importcom.rabbitmq.client.Channel;importorg.springframework.amqp.core.AcknowledgeMode;importorg.springframework.amqp.core.Message;importorg.springframework.amqp.rabbit.listener.api.ChannelAwareMessageListener;importorg.springframework.stereotype.Component;@ComponentpublicclassDlxListenerimplementsChannelAwareMessageListener{publicvoidonMessage(Messagemessage,Channelchannel)throwsException{//默认是自动签收longdeliveryTag=message.getMessageProperties().getDeliveryTag();try{//1.接收消息System.out.println(newString(message.getBody()));//2.处理业务inti=3/0;//模拟业务出现问题//3.如果业务处理成功，那么就签收channel.basicAck(deliveryTag,true);}catch(Exceptione){/***4.拒绝签收*第三个参数：为true表示该消息重新会到queue中，borker会重新发送该消息给消费端*为false表示不重回队列，将会进入到死信队列*/channel.basicNack(deliveryTag,true,false);}}publicvoidonMessage(Messagemessage){}publicvoidcontainerAckMode(AcknowledgeModemode){}}consumer的配置文件&lt;!--定义监听器容器acknowledge=&quot;manual&quot;:表示手动签收--&gt;&lt;rabbit:listener-containerconnection-factory=&quot;connectionFactory&quot;acknowledge=&quot;manual&quot;prefetch=&quot;3&quot;&gt;&lt;!--&lt;rabbit:listenerref=&quot;ackListener&quot;queue-names=&quot;test_queue_confirm&quot;&gt;&lt;/rabbit:listener&gt;--&gt;&lt;!--&lt;rabbit:listenerref=&quot;qosListener&quot;queue-names=&quot;test_queue_confirm&quot;&gt;&lt;/rabbit:listener&gt;--&gt;&lt;rabbit:listenerref=&quot;dlxListener&quot;queue-names=&quot;test_queue_dlx&quot;&gt;&lt;/rabbit:listener&gt;&lt;/rabbit:listener-container&gt;小结死信交换机和死信队列和普通的没有区别当消息成为死信后，如果该绑定了死信交换机，则消息会被死信交换机重新路由到死信队列消息成为死信的三种情况：（消息的长度达到上线、消费者拒绝消息、元队列的消息过期到了时间未被消费）队列延迟什么是队列延迟队列延迟：消息进入队列后不会立即被消费，只有达到指定的时间后才会被消费需求：下单后，三十分钟未支付，取消订单，回滚库存新用户注册7天后，发短信问候实现方式：定时器延迟队列（RabbitMQ没有）很可惜，在RabbitMQ中并未提供延迟队列功能但是我们可以使用:TTL+死信队列组合来实现延迟队列的效果生成者编码在producer中添加配置&lt;!--延迟队列:1.定义正常的交换器(order_exchange)和队列(order_queue)2.定义死信交换机(order_exchange_dlx)和队列(order_queue_dlx)3.绑定，设置正常的队列过期时间是30分钟(为了方便测试，设置为10秒)--&gt;&lt;rabbit:queueid=&quot;order_queue&quot;name=&quot;order_queue&quot;&gt;&lt;!--绑定--&gt;&lt;rabbit:queue-arguments&gt;&lt;entrykey=&quot;x-dead-letter-exchange&quot;value=&quot;order_exchange_dlx&quot;/&gt;&lt;entrykey=&quot;x-dead-letter-routing-key&quot;value=&quot;dlx.order.cancel&quot;/&gt;&lt;entrykey=&quot;x-message-ttl&quot;value=&quot;10000&quot;value-type=&quot;java.lang.Integer&quot;/&gt;&lt;/rabbit:queue-arguments&gt;&lt;/rabbit:queue&gt;&lt;rabbit:topic-exchangename=&quot;order_exchange&quot;&gt;&lt;rabbit:bindings&gt;&lt;rabbit:bindingpattern=&quot;order.#&quot;queue=&quot;order_queue&quot;&gt;&lt;/rabbit:binding&gt;&lt;/rabbit:bindings&gt;&lt;/rabbit:topic-exchange&gt;&lt;!--定义死信交换机--&gt;&lt;rabbit:queueid=&quot;order_queue_dlx&quot;name=&quot;order_queue_dlx&quot;&gt;&lt;/rabbit:queue&gt;&lt;rabbit:topic-exchangename=&quot;order_exchange_dlx&quot;&gt;&lt;rabbit:bindings&gt;&lt;rabbit:bindingpattern=&quot;dlx.order.#&quot;queue=&quot;order_queue_dlx&quot;&gt;&lt;/rabbit:binding&gt;&lt;/rabbit:bindings&gt;&lt;/rabbit:topic-exchange&gt;@TestpublicvoidtestDelay(){rabbitTemplate.convertAndSend(&quot;order_exchange&quot;,&quot;order.msg&quot;,&quot;订单信息：id=1,time=2020-6-14-17:31&quot;);}消费者编码packagecom.cn.listener;importcom.rabbitmq.client.Channel;importorg.springframework.amqp.core.AcknowledgeMode;importorg.springframework.amqp.core.Message;importorg.springframework.amqp.rabbit.listener.api.ChannelAwareMessageListener;importorg.springframework.stereotype.Component;/****/@ComponentpublicclassOrderListenerimplementsChannelAwareMessageListener{publicvoidonMessage(Messagemessage,Channelchannel)throwsException{//默认是自动签收longdeliveryTag=message.getMessageProperties().getDeliveryTag();try{//1.接收消息System.out.println(newString(message.getBody()));//2.处理业务System.out.println(&quot;处理业务逻辑....&quot;);System.out.println(&quot;根据id查询订单状态&quot;);System.out.println(&quot;判断其支付是否成功&quot;);System.out.println(&quot;如果未支付，那么业务做库存数量回滚&quot;);//3.如果业务处理成功，那么就签收channel.basicAck(deliveryTag,true);}catch(Exceptione){System.out.println(&quot;出现了异常&quot;);/***4.拒绝签收*第三个参数：为true表示该消息重新会到queue中，borker会重新发送该消息给消费端*为false表示不重回队列，将会进入到死信队列*/channel.basicNack(deliveryTag,true,false);}}publicvoidonMessage(Messagemessage){}publicvoidcontainerAckMode(AcknowledgeModemode){}}&lt;!--定义监听器容器acknowledge=&quot;manual&quot;:表示手动签收--&gt;&lt;rabbit:listener-containerconnection-factory=&quot;connectionFactory&quot;acknowledge=&quot;manual&quot;prefetch=&quot;3&quot;&gt;&lt;!--&lt;rabbit:listenerref=&quot;ackListener&quot;queue-names=&quot;test_queue_confirm&quot;&gt;&lt;/rabbit:listener&gt;--&gt;&lt;!--&lt;rabbit:listenerref=&quot;qosListener&quot;queue-names=&quot;test_queue_confirm&quot;&gt;&lt;/rabbit:listener&gt;--&gt;&lt;!--&lt;rabbit:listenerref=&quot;dlxListener&quot;queue-names=&quot;test_queue_dlx&quot;&gt;&lt;/rabbit:listener&gt;--&gt;&lt;rabbit:listenerref=&quot;orderListener&quot;queue-names=&quot;order_queue_dlx&quot;&gt;&lt;/rabbit:listener&gt;&lt;/rabbit:listener-container&gt;","link":"https://haohanya.github.io/post/rabbitmqer/"},{"title":"RabbitMQ（一）","content":"springcloudbus简介它是用轻量的消息代替将分布式节点连接起来，可以用于广播配置文件的更改或者是服务的监控管理。也就是消息总线可以为微服务做监控，也可以实现应用程序之间的相互通讯。SpringCloudBus可选的消息代理有RabbitMQ和KafakaMQ的基本概念MQ的概述MQ全称：MessageQueue（消息队列），是在消息的传输过程中保持消息的容器，多用于分布式系统之间进行通信MQ的优点和缺点优点应用解耦异步提速削峰填谷缺点系统可用性降低系统复杂度提高一致性问题优点一：应用解耦系统的耦合性越高，容错性就越低可维护性就越低使用MQ使得应用解耦，提高了容错性和可维护性优点二：异步提速一个订单操作耗时：20+300+300+300=920ms用户点击完成下单按钮后需要等待920ms才能得到下单成功的响应，太慢了！而使用了MQ用户点击下单按钮后只需要等待25ms就能得到下单的响应，提升用户体验和系统吞吐量（吞吐量:单位时间内处理请求的数目）优点三：削峰填谷削峰为了提高营业额，在A系统中做了一个活动，叫：一元秒杀外星人，在活动开始后，用户反复刷新页面，并且新用户增多，请求瞬间增多每秒5000个请求而应用A系统能每秒能处理的请求数只能是1000个，现在请求数达到5000那么A系统将会直接宕机用户的请求先发送给MQ，5000个请求同时发给MQ（在MQ看来是小意思）A系统每秒从MQ中拉取1000个请求，处理完了之后再从MQ继续拉取，直到消息全部拉取完毕填谷使用了MQ之后，限制效非消息的速度为1000，这样依赖，高峰期产生的数据势必会被挤压在MQ中，高峰就被消掉了，但是因为消息积压，在高峰期过后的一段时间内，消费消息的速度还是会维持在1000，直到消息消费完积压的消息，这就叫做“填谷”使用了MQ后可以提高系统稳定性小结优点小结应用解耦：提高系统容错性和可维护性异步提速：提升用户体验和系统吞吐量削峰填谷：提高了系统的稳定性MQ的缺点系统可用性降低系统引入的外部依赖越多，系统稳定性越差，一旦MQ宕机，就会对业务造成影响，如何保证MQ的高可用？系统复杂度提高MQ的加入大大增加了系统的复杂度，以前系统之间同步的远程调用，现在是通过MQ进行异步调用，如何保证消息没有被重复消费？怎么处理消息丢失的情况，那么保证消息传递的顺序性？一致性问题A系统处理完业务，通过MQ给B、C、D系统三个系统发送消息数据，如果B系统、C系统处理成功，但是D系统处理失败，如何保证消息数据处理的一致性呢？常见的MQ产品目前业界有很多的MQ产品，如：RabbitMQ、RocaketMQ、ActiveMQ、Kafaka、ZeroMQ、MetaMQ等等，也有公司直接使用Redis充当消息队列的案例，而这些消息队列产品各有偏重，在实际选型中，需要结合自身需求以及MQ产品的特性，综合考虑RabbitMQActiveMQRocketMQKafaka公司/社区RabbitApacheAlibabaApache开发语言Erlang（二郎神）JavaJavaJava&amp;Scala协议支持AMQP、SMTP...REST、AMQP、STOMP...自定义自定义协议、社区封装了http协议支持客户端支持语言官方支持Erlang、java、Ruby等Java、C、C++、Python、PHP...Java、C++(不成熟)官方支持JAVA、社区产出了多种API，如PHP和Python等单机吞吐量万级（其次）万级（最差）十万级（最好）十万级（次之）消息延迟微秒级毫秒级毫秒级毫秒级以内功能特性并发能力强、性能极其好、延迟低、社区活跃、管理界面丰富老牌产品、成熟度高、文档较多MQ功能比较完备、扩展性佳支支持主要的MQ功能，毕竟是为大数据领域准备的RabbitMQAMQP简介AMQP：AdvancedMessageQueuingProtocol(高级消息队列协议)，它是一个网路协议，是应用层协议的一个开发标准，为面向消息的中间件设计。基于此协议的客户端与消息中间件可传递消息，并不受客户端/中间件不同产品，不同的开发语言等条件限制AMQP是2006年SUN公司发布的一个规范RabbitMQ简介Rabbit技术公司（美国）基于AMQP标准开发的RabbitMQ于2007年发布V1.0版，RabbitMQ采用Erlang语言开发。Erlang语言专门为高并发和分布式统设计的一种语言，在电信领域使用广泛Broker:就是RabbitMQServer，用来接收和分发消息的应用VirtualHost:出于多租户和安全因素设计的，把AMQP的基本组件划分到一个虚拟的分组中，雷速与网络中的namesapce概念。当多个不同的用户使用一个RabbitMQserver提供服务的时候，可以划分出多个VirtualHost，每个用户都在自己的vhost创建exchange和queue等Connection：生产者/消费者和broker之间的TCP连接Channel：（信道）如果每一次访问RabbitMQ都建立一个Connection，在消息量大的时候建立TcpConnection的开销将是巨大的、效率也较低。Channel是在Connection内部建立的逻辑连接，如果应用程序支持多线程，通常每个thread创建单独的channel进行通信，AMQPmethod包含了channelid帮助客户端和messageborker识别channel，所以channel之间是完全隔离的。Channel作为轻量级的Connection极大减少了操作系统建立TCPconnection的开销Exchange：消息达到RabbitMQ的第一站，根据分发规则，匹配查询表中的routingkey(路由键)，分发消息到queue中去，常有的类型有：direct(点对点和activeMQ中的queue是一样的)、topic、fanout（这个和activeMQ中的topic模式是一样的）Queue：消息最终被送到这里等待消费者取走Binding：Exchange和Queue之间的虚拟连接，binding中可以包含路由键routingkey、Binding信息被保存到exchange中的查询表中，用于消息的分发依据使用Docker安装RabbitMQ拉取镜像dockerpullrabbitmq:3.8.4-management通过容器启动RabbitMQdockerrun-i-d--name=myrabbitmq-p5672:5672-p15672:15672imageid访问RabbitMQIP:15672用户名和密码默认都是guest通过SpringBoot整合RabbitMQ创建工程配置文件#端口号server:port:8080#配置rabbitMQspring:rabbitmq:host:192.168.25.134username:guestpassword:guest#port:5672创建Exchange@AutowiredprivateAmqpAdminamqpAdmin;/***通过代码创建exchange*/@TestpublicvoidcreateExchange(){amqpAdmin.declareExchange(newDirectExchange(&quot;amqp.exchange&quot;));}创建不同的消息new不同的对象即可常见Queue@AutowiredprivateAmqpAdminamqpAdmin;@TestpublicvoidcreateQueue(){amqpAdmin.declareQueue(newQueue(&quot;amqp.queue&quot;));}绑定exchange和queue@AutowiredprivateAmqpAdminamqpAdmin;@TestpublicvoidbindingQueueAndExchange(){//参数一：queue//参数二：是queue的类型//参数三：交换器//参数四：routingkey（路由键）//参数五：绑定的时候给一个初始化的消息amqpAdmin.declareBinding(newBinding(&quot;amqp.queue&quot;,Binding.DestinationType.QUEUE,&quot;amqp.exchange&quot;,&quot;amqp.test&quot;,null));}测试direct@ResourceprivateRabbitTemplaterabbitTemplate;/***测试direct发送消息*/@TestvoidtestPublishDirect(){Map&lt;String,Object&gt;map=newHashMap&lt;&gt;();map.put(&quot;id&quot;,1);map.put(&quot;list&quot;,Arrays.asList(&quot;张三&quot;,&quot;李四&quot;));/***参数1、exchange（交换器）通过交换器的类型，可以决定消息发送的方式，如：direct就是点对点，一个生产者对应一个消费者*参数2、routingKey（路由键）表示消息到queues中哪个地方存储*参数3、路由试题*/rabbitTemplate.convertAndSend(&quot;amqp.exchange&quot;,&quot;amqp.test&quot;,map);}/***测试direct接收消息*/@TestpublicvoidtestReceiveDirect(){//参数：queue的nameObjectconvert=rabbitTemplate.receiveAndConvert(&quot;amqp.queue&quot;);System.out.println(convert);System.out.println(convert.getClass());}测试fanout/***测试fanout发送消息(和activeMQ中的topic一样的)*/@TestpublicvoidtestPublishFanout(){Map&lt;String,Object&gt;map=newHashMap&lt;&gt;();map.put(&quot;id&quot;,1);map.put(&quot;list&quot;,Arrays.asList(&quot;张三&quot;,&quot;李四&quot;));rabbitTemplate.convertAndSend(&quot;amqp.exchange.fanout&quot;,&quot;amqp.exchange.fanout.test&quot;,map);}创建监听器@ServicepublicclassMyListener{@RabbitListener(queues=&quot;amqp.queue&quot;)publicvoidreceive(Map&lt;String,Object&gt;map){System.out.println(&quot;从监听器中取出消息：&quot;+map);}}测试topic在RabbitMQ中direct==activeMQ中的queue​fanout==activeMQ中的topic​topic匹配模式.#(表示一个单词或多个单词)*.(表示匹配一个或多个单词)","link":"https://haohanya.github.io/post/rabbitmqyi/"},{"title":" 熔断器Hystrix","content":"熔断器Hystrix简介hystrix在英文里的意思是豪猪，它的logo就是一头豪猪，刺让我想到的是自我保护，hystrix它就是一款提供保护机制额组件，它和eureka一样也是Netflix公司开发的雪崩问题微服务中，服务之间调用关系是错综复杂的，一个请求，可能需要调用多个微服务绝口才能实现，会形成非常复杂的调用链路如图：一次业务请求，需要调用A、P、H、I四个服务，这四个服务又有可能调用了其他的服务。如果此时，某个服务出现了异常：例如：微服务I出现了异常，请求就会阻塞，用球请求就会得不到响应，则tomcat的这个线程就不会释放，于是越来越多的用户请求到来，越来越多额线程会阻塞服务器支持的线程和并发数是有限的，请求一直阻塞，会导致服务器的资源耗尽，从而导致所有额其他服务都不可用，形成雪崩效应。这就好比：村里都用一个变压器，有一家用热得快烧水导致电路短路最终烧了电路，结果却导致村里所有家庭都无法用电（解决方案：每家每户都装一个保险丝，一家烧毁，不想赢其他家庭用电）这也好比：一个汽车生产线，生成不同的汽车，需要的是不同的零件，若果某个零件因为种种原因无法使用，那么就会早成整台车无法装配，陷入了等待零件的状态，知道零件到位，才能继续组装件，此时如果有很多的车型都需要这个零件，那么整个工厂就将陷入等待状态，导致所有的生成都瘫痪，一个零件的剥茧范围不断的扩大.这就是雪崩Hystrix解决的雪崩问题的手段主要是服务降级，包括：线程隔离服务熔断线程隔离&amp;服务降级原理解读该图：Hystrix为每个依赖服务调用分配一个小的线程池，如果线程池已满调用就会被立即拒绝，默认不采用排队，加速失败判定时间。用户的请求将不再直接访问服务，而是通过线程池中的空闲线程来访问服务，如果线程池已经满了，或者是请求超时，则会进行降级处理（服务降级：有限保证核心服务，而非核心服务不可用或弱可用）用户的请求故障的时候，不会被阻塞，更不会无休止的等待或者是看到系统崩溃，至少可以看到一个执行的结果（一个友好的界面）服务降级虽然会导致请求失败，但是不会导致阻塞，而且最多会影响这个依赖服务对应的线程池中的资源，对其它服务完全没有影响。hysrix服务降级的情况线程池已满请求超时案例在user-web工程中依赖hystrix&lt;dependency&gt;&lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt;&lt;/dependency&gt;开启熔断在启动类上添加注解@EnableCircuitBreaker@SpringBootApplication@EnableDiscoveryClient//开启发现服务@EnableCircuitBreakerpublicclassUserWebApplication{...}可以看到，类上面的注解越来越多了，在微服务中，经常引入上面的三个注解，学习一个组合注解@SpringCloudApplication它的源码如下：@SpringBootApplication@EnableDiscoveryClient@EnableCircuitBreakerpublic@interfaceSpringCloudApplication{}所以我们就可以直接使用该注解@SpringCloudApplicationpublicclassUserWebApplication{....}编写降级逻辑当目标服务的调用出现故障，我们希望快速失败，给用户一个友好的提示，因此需要提前编写好失败的时候的降级逻辑，使用HystrixCommand来完成对User-web中的controller进行改造@RestController@RequestMapping(&quot;/consumer&quot;)publicclassConsumerController{@AutowiredprivateRestTemplaterestTemplate;@AutowiredprivateDiscoveryClientdiscoveryClient;@RequestMapping(&quot;/{id}&quot;)@HystrixCommand(fallbackMethod=&quot;queryByIdFallback&quot;)publicUsergetByyid(@PathVariable(&quot;id&quot;)Longid){//使用负载均衡（Ribbon）Stringurl=&quot;http://user-service/user/&quot;+id;returnrestTemplate.getForObject(url,User.class);}//熔断的方法：方法名和正常的方法名一致，参数一致publicUserqueryByIdFallback(Longid){Useruser=newUser();user.setId(id);user.setNote(&quot;对不起网络太用拥挤了！&quot;);returnuser;}}可以停掉user-service服务，在进行use-web的访问测试说明：@HystrixCommand(fallbackMethod=&quot;queryByIdFallback&quot;)；用来声明一个降级逻辑的方法默认的fallback刚才是吧fallback写在了某个业务的方法上，如果这样的方法多了，就会导致每个方法都写一个fallback，实际上可能意义不大，我们就可以写默认的fallback对controller改造@RestController@RequestMapping(&quot;/consumer&quot;)@DefaultProperties(defaultFallback=&quot;defaultFallback&quot;)publicclassConsumerController{@AutowiredprivateRestTemplaterestTemplate;@AutowiredprivateDiscoveryClientdiscoveryClient;@RequestMapping(&quot;/{id}&quot;)//@HystrixCommand(fallbackMethod=&quot;queryByIdFallback&quot;)@HystrixCommandpublicUsergetByyid(@PathVariable(&quot;id&quot;)Longid){//使用负载均衡（Ribbon）Stringurl=&quot;http://user-service/user/&quot;+id;returnrestTemplate.getForObject(url,User.class);}//熔断的方法：方法名和正常的方法名一致，参数一致publicUserqueryByIdFallback(Longid){Useruser=newUser();user.setId(id);user.setNote(&quot;对不起网络太用拥挤了！&quot;);returnuser;}//默认服务熔断publicUserdefaultFallback(){Useruser=newUser();user.setNote(&quot;默认提示：对不起,网络太用拥挤了！&quot;);returnuser;}}超时设置在案例中，请求在超过1秒后都会返回错误信息，这是因为Hystirx的默认超时时间是1秒hystrix:command:default:execution:isolation:thread:timeoutInMilliseconds:2000这个配置会作用于全局所有的方法为了演示这个效果，我先将上面的2000恢复到默认值是1000，然后修改了user-service中的service方法，给2秒的访问延迟@ServicepublicclassUserServiceImplimplementsUserService{@AutowiredprivateUserRepositoryuserRepository;@OverridepublicUsergetUserById(Longid){try{Thread.sleep(2000);}catch(InterruptedExceptione){e.printStackTrace();}returnuserRepository.findUserById(id);}}接着我们再访问user-web，发现即使user-service服务是能正常提供服务，但是他们的通讯时间超过了1秒还是会出现问题。接下来，将上面的配置改为3000毫秒，接下来就能正常访问了服务熔断原理在服务熔断中，使用的是熔断器，也叫断路器，英文叫：CircuitBreaker熔断器跟家用的保险丝原理类似：当如果电路发生了短路的时候能够立即熔断电路，避免灾难的发生。在分布式系统的应用中应用服务熔断后，服务调用方可以自己进行判断哪些服务反应慢或者是存在大量的超时，可以针对这些服务进行主动熔断，防止整个系统被拖垮Hystrix的服务熔断机制，可以实现弹性容错，当服务请求情况好转之后，可以自动重连。通过短路的方式，将后续请求直接拒绝，一段时间（默认时间是5秒）之后允许部分请求通过，如果调用成功则回到断路器关闭状态，否则将继续打开，拒绝请求的服务。Hystirx的熔断状态模型：","link":"https://haohanya.github.io/post/rong-duan-qi-hystrix/"},{"title":" Ribbon负载均衡器","content":"Ribbon什么是RibbonRibbon是Netflix发布的一个负载均衡器，它有助于控制Http和TCP客户端的行为。为Ribbon配置服务提供者列表后，Ribbon就可以基于某种负载均衡的算法，自动地帮助我们选择其中的一个服务给消费者。Ribbon默认负载均衡算法是轮询，除此之外还有随机等，当然实际开发中也可以自定义负载均衡的算法服务之间的通讯问题永远是从eureka中拉取到了服务提供者的列表，但是永远只用第一个服务，其他的服务就都闲置着了@RequestMapping(&quot;/{id}&quot;)publicUsergetByyid(@PathVariable(&quot;id&quot;)Longid){//地址从eureka中获取List&lt;ServiceInstance&gt;instancesList=discoveryClient.getInstances(&quot;user-service&quot;);//有可能有多个服务，我只需要拿一个ServiceInstanceserviceInstance=instancesList.get(0);//组装Stringurl=&quot;http://&quot;+serviceInstance.getHost()+&quot;:&quot;+serviceInstance.getPort()+&quot;/user/&quot;+id;//采用http的方式系统之间通讯returnrestTemplate.getForObject(url,User.class);}解决方案：通过一种算法，合理的选择其中的一个服务。可以通过编写负载均衡的算法，在多个实例列表中选择一个服务不过Eurkea中已经集成了负载均衡组件：Ribbon（简单的修改代码即可使用）实战1、先启动2个user-service实例2、在user-web工程中开启负载均衡在eureka-client的包中已经集成了Ribbon，所以不需要导入新的依赖直接修改启动类，添加开启的注解（在RestTemplate上面添加@LoadBalanced）@SpringBootApplication@EnableDiscoveryClient//开启发现服务publicclassUserWebApplication{publicstaticvoidmain(String[]args){SpringApplication.run(UserWebApplication.class,args);}@Bean@LoadBalancedpublicRestTemplaterestTemplate(){returnnewRestTemplate();}}3、修改controller中获取服务的方法@RequestMapping(&quot;/{id}&quot;)publicUsergetByyid(@PathVariable(&quot;id&quot;)Longid){//使用负载均衡（Ribbon）Stringurl=&quot;http://user-service/user/&quot;+id;returnrestTemplate.getForObject(url,User.class);}接下来测试就可以通了关掉一个user-service后测试是否可以正常获取到服务再启动关掉的那个user-service后关掉第二个user-service服务再测试。","link":"https://haohanya.github.io/post/ribbon-fu-zai-jun-heng-qi/"},{"title":"Eureka","content":"什么是Eureka百度百科：什么是Eureka问题分析刚才的案例，user-service对外提供服务，需要对外暴漏自己的地址。user-web需要记录服务提供者的地址。将来地址出现变更，还需要及时的去更新。这在服务较少的时候不会觉得有什么，但是在大型的互联网项目中，一个项目可能差分处几十个微服务，此时如果还是人为的管理，不仅开发困难，奖励啊测试、发布上线都会有大麻烦与DevOps思想违背：就是系统可以通过一组过程、方法或者是系统，提高应用发布和运维的效率，降低管理成本Eureka做什么好比是房产中介，负责管理、记录服务提供者的信息。服务调用者就无需自己去找服务，而是把自己的需求告诉Eureka，然后Eureka把符合你要求的服务告诉你同时，服务的提供方与Eureka之间通过“心跳”机制进行监控，当某个服务提供方出现问题，Eureka自然会把它从服务列表中剔除这就实现了服务的自动注册、发现和状态监控Eureka注册中心说明Eureka的主要功能是进行服务管理，定期检查服务状态，返回服务地址列表。入门案例1、创建springboot项目并添加依赖2、在启动类中添加注解@SpringBootApplication@EnableEurekaServer//声明当前应用是eureka服务publicclassEurekaServiceApplication{publicstaticvoidmain(String[]args){SpringApplication.run(EurekaServiceApplication.class,args);}}3、配置eureka#端口号server:port:10086spring:application:name:eureka-server#应用名称，会在eureka中作为服务的id标识#配置eurkeaeureka:client:service-url:defaultZone:http://127.0.0.1:10086/eurekaregister-with-eureka:false#不注册自己，默认值是true（如果搭建eureka集群，需要相互之间注册）fetch-registry:false#不拉取自己的服务列表4、启动服务访问：http://localhost:10086/服务注册注册服务，就是在服务上添加Eureka的客户端依赖，客户端代码会自动把服务注册到EurekaService中添加依赖&lt;!--添加mapper的启动器--&gt;&lt;dependency&gt;&lt;groupId&gt;tk.mybatis&lt;/groupId&gt;&lt;artifactId&gt;mapper-spring-boot-starter&lt;/artifactId&gt;&lt;version&gt;2.0.3&lt;/version&gt;&lt;/dependency&gt;&lt;!--lombok--&gt;&lt;dependency&gt;&lt;groupId&gt;org.projectlombok&lt;/groupId&gt;&lt;artifactId&gt;lombok&lt;/artifactId&gt;&lt;/dependency&gt;1、修改启动类@SpringBootApplication@MapperScan(basePackages=&quot;com.kgc.mapper&quot;)//扫描mapper包，如果使用的是tb.mybatis@EnableEurekaClient//开启Eureka客户端发现功能publicclassUserServiceApplication{publicstaticvoidmain(String[]args){SpringApplication.run(UserServiceApplication.class,args);}}2、修改配置文件#端口号server:port:9091#数据源spring:datasource:driver-class-name:com.mysql.jdbc.Driverurl:jdbc:mysql://localhost:3306/springcloud?useUnicode=true&amp;characterEncoding=utf-8&amp;serverTimezone=Asia/Shanghaiusername:rootpassword:rootapplication:name:user-service#应用名#添加Eureka注册的配置eureka:client:service-url:defaultZone:http://127.0.0.1:10086/eureka3、测试启动user-service工程服务发现1、修改启动类@SpringBootApplication@EnableDiscoveryClient//开启Eureak客户端publicclassUserWebApplication{@BeanpublicRestTemplaterestTemplate(){returnnewRestTemplate();}publicstaticvoidmain(String[]args){SpringApplication.run(UserWebApplication.class,args);}}2、修改配置文件server:port:8080spring:application:name:user-web#应用名称eureka:client:service-url:defaultZone:http://127.0.0.1:10086/eureka#eurekaSerer地址3、修改处理器packagecom.cn.controller;importcom.cn.pojo.User;importcom.netflix.appinfo.InstanceInfo;importorg.springframework.beans.factory.annotation.Autowired;importorg.springframework.cloud.client.ServiceInstance;importorg.springframework.cloud.client.discovery.DiscoveryClient;importorg.springframework.web.bind.annotation.PathVariable;importorg.springframework.web.bind.annotation.RequestMapping;importorg.springframework.web.bind.annotation.RestController;importorg.springframework.web.client.RestTemplate;importjava.util.List;@RestController@RequestMapping(&quot;/consumer&quot;)publicclassConsumerController{@AutowiredprivateRestTemplaterestTemplate;//DiscoveryClient的用springCloud包中的@Autowired(required=false)privateDiscoveryClientdiscoveryClient;@RequestMapping(&quot;/{id}&quot;)publicUsergetByid(@PathVariable(&quot;id&quot;)Longid){/*//通过http的方式实现系统之间的通讯Stringurl=&quot;http://localhost:9091/user/&quot;+id;//这个是user-service提供的restapi风格的接口Useruser=restTemplate.getForObject(url,User.class);returnuser;*///从eurekaServer注册中心去获取user-service的实例列表List&lt;ServiceInstance&gt;instancesList=discoveryClient.getInstances(&quot;user-service&quot;);//因为我就一个服务，所以我就拿集合中的第一个就成ServiceInstanceserviceInstance=instancesList.get(0);//服务的resutApi接口Stringurl=&quot;http://&quot;+serviceInstance.getHost()+&quot;:&quot;+serviceInstance.getPort()+&quot;/user/&quot;+id;returnrestTemplate.getForObject(url,User.class);}}4、测试Eureak总结三个角色服务注册中心Eureka的服务端应用，提供服务注册和发现功能，就是我们建立的eureka-server服务提供者提供服务的应用，可以是springBoot应用，也可以是其他任意技术实现，只要对外提供的是Rest风格服务就可。就是我们建立的user-service服务消费者消费者应用就是从注册中心获取服务列表，从而得知每个服务放的信息，知道去哪里调用服务，就是我们建立的user-web高可用的EurekaServer我们只有一个Eureak，事实上可以搭建一个集群，形成一个高可用的Eureka注册中心服务同步多个EurekaServer之间会相互注册为服务，当服务提供者注册到EurekaServer结群中的某个节点的时候，该节点会把服务的信息同步到集群中的每个节点，从而实现数据的同步，一旦有一个节点挂掉了，那么其他的节点依然能提供服务注册和发现的功能1、修改EurekaServer配置#端口号server:port:${port:10086}spring:application:name:eureka-server#应用名称，会在eureka中作为服务的id标识#配置eurkeaeureka:client:service-url:defaultZone:${defualtZone:http://127.0.0.1:10086/eureka}#register-with-eureka:false#不注册自己，默认值是true（如果搭建eureka集群，需要相互之间注册）#fetch-registry:false#不拉取自己的服务列表2、修改启动配置文件3、复制一份并修改VMoptions4、启动eureka集群服务注册Eureka集群因为Eureka不止一个，修改user-service关于注册中心的配置服务提供者在启动的时候，会检测配置属性中eureka.client.register-with-eureka=true参数是否正确，事实上默认是true，所以我们没有配置，如果值确实是true，则会向EurekaServer发起一个Rest请求，并且携带自己的元数据信息，EurekaServer会把这些信息保存到一个双层的Map结构中第一层Map的key就是服务的id，一般就是配置spring.applicaton.name属性第二层Map的key就是服务的实例id，一般host+serviceId+port，例如：localhost:user-service:9091值则是服务的实例对象，也就是说一个服务，可以同时启动多个不同的实例，形成集群默认注册的时候是主机名或者是localhost，如果想用ip进行注册，可以在user-server中添加配置#端口号server:port:9091#数据源spring:datasource:driver-class-name:com.mysql.jdbc.Driverurl:jdbc:mysql://localhost:3306/springcloud?useUnicode=true&amp;characterEncoding=utf-8&amp;serverTimezone=Asia/Shanghaiusername:rootpassword:rootapplication:name:user-service#应用名#添加Eureka注册的配置eureka:client:service-url:#EurekaServer地址，多个地址之间用逗号分隔defaultZone:http://127.0.0.1:10086/eureka,http://127.0.0.1:10087/eurekainstance:ip-address:127.0.0.1#ip地址prefer-ip-address:true#更倾向于使用ip，而不是host名修改完成后重启user-server工程和user-web工程可以测试一下，先关掉10086，然后在测试是否能正常通讯失效的剔除和自我保护服务续约在注册服务完成以后，服务提供者会持续一个心跳（定时向EurekaServer发起Rest请求），告诉EurekaServer：“我还活着”，这个我们就称之为服务的续约(renew)；向user-server工程配置文件中添加如下配置#添加Eureka注册的配置eureka:client:service-url:#EurekaServer地址，多个地址之间用逗号分隔defaultZone:http://127.0.0.1:10086/eureka,http://127.0.0.1:10087/eurekainstance:ip-address:127.0.0.1#ip地址prefer-ip-address:true#更倾向于使用ip，而不是host名lease-expiration-duration-in-seconds:5#服务续约的时间间隔，默认是30秒，现在我这里设置为5秒lease-renewal-interval-in-seconds:5#服务失效时间，默认是90秒，我这里设置为5秒也就是说，默认情况下每个30秒服务会向注册中心发送一次心跳，证明自己还活着，如果超过90秒还没有发送心跳，EurekaServer就会认为该服务已经宕机，会定时从服务列表中移除，这两个值在生产环境中不要修改（我这里修改是为了方便测试）服务下线当服务进行正常关闭操作的时候，它会触发一个服务下线的REST请求给EurekaSever，告诉服务注册中心：“我要下线了”。服务中心接收到请求之后，会讲该服务置为下线状态失效剔除自我保护我们关停一个服务，很可能会在eureka面板出现一条警告：这个就是eureka的自我保护机制。当服务未按时进行心跳续约，Eureka会统计服务实例最近15分钟心跳续约的比例是否低于85%，在生产环境下，因为网络延迟等原因，心跳失败实例的比例很有可能会超标，但是此时就把服务剔除列表并不妥当，因为服务并没有宕机。Erueka在这段时间内不会剔除任何服务实例，直到网络恢复正常。生产环境下这很有效,因此服务调用者必须做好服务的失败容错可以关闭自我保护（生产环境下，千万别干这事！）#配置eurkeaeureka:client:service-url:defaultZone:${defualtZone:http://127.0.0.1:10086/eureka}#register-with-eureka:false#不注册自己，默认值是true（如果搭建eureka集群，需要相互之间注册）#fetch-registry:false#不拉取自己的服务列表server:enable-self-preservation:false#关闭自我保护模式(缺省为打开)","link":"https://haohanya.github.io/post/eureka/"},{"title":"初识SpringCloud","content":"系统架构的演变随着互联网的发展，网站的应用规模不断扩大，需求的激增，带来的是技术上的压力。系统架构也因此在不断的演变、升级、迭代。集中式架构当网站流量很小的时候，只需要一个应用，将所有的功能都部署到一起，以减少部署节点和成本。优点：系统开发速度快，维护成本低，适合开发并发要求较低的系统缺点：单点容错率低，并发能力差垂直应用架构当访问量逐渐增大，单一应用无法满足需求，此时为了应对更高的并发和业务需求，我们根据业务功能对系统进行拆分：优点：系统拆分实现了流量分担，解决了并发问题可以针对不同的模块进行优化方便水平扩展，负载均衡，容错率高缺点：系统之间相互独立，开发中会有很多重复代码，影响开发效率分布式服务当垂直应用越来越多的时候，应用之间交互不可避免，作为独立的服务，逐渐形成稳定的服务中心，是前段应用能更快速的影响多变的市场需求优点：将基础服务进行了抽取，系统之间互相通用，提高了代码的重用性和开发效率缺点：系统之间耦合较高，调用关系复杂，难以维护面向服务架构SOA(ServiceOrientedArchitecure)面向服务的架构：它是一种设计方法，其中包含了多个服务，服务与服务之间通过互相依赖最终提供一系列的功能。一个服务通常以独立的形式存在与操作系统进行中，各个服务之间通过网络调用。ESB(企业服务总线)：简单的说ESB就是一根管道，用来连接各个服务节点，为了继承不同系统，不同协议的服务，ESB做了消息的转换解释和路由工作，让不同的服务互联互通SOA缺点每个供应商的ESB产品有偏差，自身实现较为复杂；应用服务粒度较大，ESB继承整合所有的服务和协议，数据转换使得运维、测试和部署比较困难，所有的服务都通过一个通路通讯，直接降低了通信速度(dubbo要比这个优化，系统之间通讯采用RPC这种方式，这种方式是直接使用二进制，效率比较高)微服务架构微服务架构是使用一套小服务开发单个应用的方式或途径，每个服务基于单一业务能力构建（职能单一），运行在自己的进程中，并使用轻量级机制通信，通常是HttpAPI，并能够通过自动化部署机制来独立部署，这些服务可以使用不同的编程语言，以及不同的数据存储技术，并保持最低的集中式管理(dubbo：使用RPC协议通讯，采用的就是二进制通讯，如果要使用dubbo实现系统之间的通讯，必须保证项目是java语言开发的。dubbo是不能实现跨语言平台通讯dubbox：后来是当当网对它进行升级，让dubbo在支持RPC的同时，也支持HttpAPI（RestAPI）通讯)APIGateway:网关是一个服务器，是系统的唯一入口，为每个客户端提供了一个定制的API。API网关核心是，所有的客户端和消费端都通过统一的网关介入微服务，在网管层处理所有的非业务功能。如它还可以具有其他职责：身份验证、监控、负载均衡、缓存、请求分片与管理。通常网关提供RESTFUL/http的方式访问服务，而服务端通过服务注册中心进行服务注册和管理微服务特点单一职责：微服务中每个服务都对应唯一的业务能力,做到单一职责微：微服务的服务拆分粒度很小，例如一个用户管理就可以作为一个服务，每个服务虽然小，但是“五脏俱全”面向服务：每个服务都要对外暴漏Rest风格服务接口API。并不关心服务的技术实现，做到与平台和语言无关，也不限定用什么技术实现，只要提供Rest的接口即可自治：服务之间相互独立，互不干扰团队独立：每个服务都可以一个独立的团队开发，人数不能过多技术独立：面向的是服务，提供Rest接口，使用什么技术没有人干涉前后端分离：采用前后端分离开发，提供统一Rest接口，后端不用再为PC、移动端开发不同的接口部署独立：服务之间虽然有调用，但是要做到服务器重启不影响其他的服务器。有利于持续集成和持续交付。每个服务都是独立的组件，可以复用、可以替换、降低了耦合度，易于维护互联网精神：先上线，后迭代微服务架构与SOA都是对系统进行了拆分；微服务架构师基于SOA思想，可以把微服务当作去除了ESB总线的SOA。ESB是SOA架构中的中心总线服务调用方式常见的远程调用方式1、RPCRemoteProduceCall。基于Socket的通讯（是用最底层的方式来实现通讯，采用二进制的形式，通讯的效率最高的）。工作在会话层。自定义数据格式，速度快，效率高。早期的webservice，现在热门的dubbox，都是RPC的典型代表（只能是java语言编写的服务之间通讯）2、Httphttp其实是一种网络传输协议，基于TCP，工作在应用层，规定了数据传输的格式。现在客户端浏览器与服务器通讯基本上都是采用的http协议，也可以用来进行远程服务调用。缺点是消息封装臃肿，优势是对服务的提供和调用方没有任何技术限定（可以跨语言），自由灵活，更符合微服务的理念如果你们的公司全部采用的java技术栈，那么使用dubbo作为微服务架构师一个不错的选择。相反如果公司的技术栈多样化，而且你更加青睐于Spring家族，那么SpringCloud搭建微服务就是不二选择，在我们的项目中，会所选择SpringCloud套件，因此会使用http方式来实现微服务之间的调用Http客户端工具既然微服务选择了http，那么我们就需要考虑自己来实现对请求和响应的处理，不过开源世界已经有很多的http客户端工具，能够帮助我们做这些事情，例如：HttpClientOkHttpURLConnection他们之间的API各不相同，而spring也有对http的客户端工具进行了封装（这三种都有），提供了工具类：RestTemplateSpring的RestTemplate使用spring提供的一个RestTemplate来实现http的交互创建springboot项目1、创建业务逻辑层(user-service)依赖&lt;!--mapper启动器(准备使用mybatis作为持久层)--&gt;&lt;dependency&gt;&lt;groupId&gt;tk.mybatis&lt;/groupId&gt;&lt;artifactId&gt;mapper-spring-boot-starter&lt;/artifactId&gt;&lt;version&gt;2.0.3&lt;/version&gt;&lt;/dependency&gt;&lt;!--mysql驱动--&gt;&lt;dependency&gt;&lt;groupId&gt;mysql&lt;/groupId&gt;&lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!--为了开发方便，我这里引入lombok--&gt;&lt;dependency&gt;&lt;groupId&gt;org.projectlombok&lt;/groupId&gt;&lt;artifactId&gt;lombok&lt;/artifactId&gt;&lt;/dependency&gt;pojo@Data@Table(name=&quot;tb_user&quot;)publicclassUser{@Id@KeySql(useGeneratedKeys=true)privateLongid;privateStringuserName;/*用户名*/privateStringpassword;/*密码*/privateStringname;/*姓名*/privateIntegerage;/*年龄*/privateIntegersex;/*性别，1男性，2女性*/privateDatebirthday;/*生日*/privateStringnote;/*备注*/privateDatecreated;/*创建时间*/privateDateupdated;/*修改时间*/}mapper接口importtk.mybatis.mapper.common.Mapper;publicinterfaceUserMapperextendsMapper&lt;User&gt;{}在启动类中扫描mapper@SpringBootApplication@MapperScan(basePackages=&quot;com.cn.mapper&quot;)publicclassUserServiceApplication{publicstaticvoidmain(String[]args){SpringApplication.run(UserServiceApplication.class,args);}}servicepublicinterfaceUserService{/***根据主键查询对象*@paramid主键*@return对象*/UsergetUserById(Longid);}-------------@ServicepublicclassUserServiceImplimplementsUserService{@Autowired(required=false)privateUserMapperuserMapper;@OverridepublicUsergetUserById(Longid){returnuserMapper.selectByPrimaryKey(id);}}编写控制层提供Rstful接口@RestController@RequestMapping(&quot;/user&quot;)publicclassUserContorller{@AutowiredprivateUserServiceuserService;@RequestMapping(&quot;/{id}&quot;)publicUsergetById(@PathVariable(&quot;id&quot;)Longid){returnuserService.getUserById(id);}}2、创建表现层（user-web）pojo：同上启动类配置RestTemplate@SpringBootApplicationpublicclassUserWebApplication{@BeanpublicRestTemplaterestTemplate(){returnnewRestTemplate();}publicstaticvoidmain(String[]args){SpringApplication.run(UserWebApplication.class,args);}}importcom.cn.pojo.User;importorg.springframework.beans.factory.annotation.Autowired;importorg.springframework.web.bind.annotation.PathVariable;importorg.springframework.web.bind.annotation.RequestMapping;importorg.springframework.web.bind.annotation.RestController;importorg.springframework.web.client.RestTemplate;@RestController@RequestMapping(&quot;/consumer&quot;)publicclassConsumerController{@AutowiredprivateRestTemplaterestTemplate;@RequestMapping(&quot;/{id}&quot;)publicUsergetByid(@PathVariable(&quot;id&quot;)Longid){//通过http的方式实现系统之间的通讯Stringurl=&quot;http://localhost:9091/user/&quot;+id;//这个是user-service提供的restapi风格的接口Useruser=restTemplate.getForObject(url,User.class);returnuser;}}上面的操作我们是使用user-service对外提供了根据主键查询用户的接口，然后在user-web通过RestTemplate调用service的接口这样写会存在硬编码的问题，不方便后期维护，并且我们需要记住url的地址，如果发生改变，收不到通知，地址将会失效web层并不知道service层的状态，例如服务器宕机service层也只有一台，不具备高可用即便是service搭建成了集群，web还需要去实现负载均衡其实上面说的问题，概括一下就是分布式服务必然要面临的问题：服务管理如何自动注册和发现如何实现状态监控如何实现动态路由服务如何实现负载均衡服务如何解决容灾问题服务如何实现统一配置","link":"https://haohanya.github.io/post/chu-shi-springcloud/"},{"title":"Spring-Data-Jpa","content":"什么是JAPJPA是JavaPersistenceAPI的简称，中文名Java持久层API，是JDK5.0注解或XML描述对象－关系表的映射关系，并将运行期的实体对象持久化到数据库中Sun引入新的JPAORM规范出于两个原因：其一，简化现有JavaEE和JavaSE应用开发工作；其二，Sun希望整合ORM技术，实现天下归一。mybatis和hibernate的区别mybatis和hibernate一样是个orm数据库框架1).hibernate是全自动，而mybatis是半自动。mybatis开发是需要去写sql语句，而使用hibernate不需要写任何的sql语句就能实现各种操作2).hibernate数据库移植性远大于mybatis。如果使用mybatis，一旦数据库发生变化，需要重写编码（比如mysql数据库的sql语句和oracle以及sqlServer数据库他们用的sql语句会有一些差别）。但是使用hibernate一旦数据库发生变化，我们不需要重写编码，只需要改少许的配置就能实现3).hibernate拥有完整的日志系统，mybatis则欠缺一些。4).mybatis相比hibernate需要关心很多细节hibernate配置要比mybatis复杂的多，学习成本也比mybatis高。但也正因为mybatis使用简单，才导致它要比hibernate关心很多技术细节。mybatis由于不用考虑很多细节，开发模式上与传统jdbc区别很小，因此很容易上手并开发项目，但忽略细节会导致项目前期bug较多，因而开发出相对稳定的软件很慢，而开发出软件却很快。hibernate则正好与之相反。但是如果使用hibernate很熟练的话，实际上开发效率丝毫不差于甚至超越mybatis。5).sql直接优化上，mybatis要比hibernate方便很多这也是hibernate没落的原因之一。因为sql语句自动生成的，效率上不好控制为什么现在mybatis要比hiernate流行？很重要的原因：hibernate的学习难度是目前大家接触的框架中最大的，学习成本远远高于mybatis，所以mybatis更流行入门1、引入依赖.....2、配置数据源spring.datasource.url=jdbc:mysql://localhost:3306/springboot?serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=utf8&amp;useSSL=truespring.datasource.username=rootspring.datasource.password=root3、编写实体类在mybatis的开发中，实体类所在包名都用的是pojo，但是在spring-data-jpa中，因为spring中实体类的包名一般都是叫做domain，所以我们开发的时候实体类的包名也叫domainimportjavax.persistence.*;/**@Entity：该注解表示这个类是一个实体类，（准备用来建立数据库表的映射关系）@Table：用来建立实体类和数据库表的真实映射关系，属性name为表名，表名和类名一致可以省略@id：表示主键@GeneratedValue(strategy=GenerationType.IDENTITY)：该字段是自增的@Column：建立数据库列名的映射*/@Entity@Table(name=&quot;grade&quot;)publicclassGrade{@Id@GeneratedValue(strategy=GenerationType.IDENTITY)@Column(name=&quot;id&quot;,nullable=false)privateIntegerid;@Column(name=&quot;name&quot;,nullable=false,length=50)privateStringname;....}4、编写接口在spring-data-jpa中，接口所在的包名，官方用的是repository，所以我们也这么用，它等同于我们之前的dao或者是mapper/***编写spring-data-jpa接口要点：*1.继承JpaRepository&lt;参数一要操作的类,参数二改类的主键类型&gt;*2.在接口上添加注解@Repository，如果该接口在启动类的同一个包或者是在启动类的子包中，那么该类将交给spring管理*spring-data-jpa接口编写的规则（因为增删改是就用封装好的就可以，该接口主要是用于查询）*精确查询的规则：find+表名+By+domain中的属性名*模糊查询的规则：find+表名+By+domain中的属性名+Like*/@RepositorypublicinterfaceGradeAreaRepositoryextendsJpaRepository&lt;Grade,Integer&gt;{/***根据年级名称查询年级*@paramname*@return*/GradefindGradeByName(Stringname);/***根据年级名称做模糊查询*@paramname*@return*/List&lt;Grade&gt;findGradeByNameLike(Stringname);/***根据主键查询*/GradefindGradeById(Integerid);/***根据id和年级名称做联合查询*/GradefindGradeByIdAndNameLike(Integerid,Stringname);/***单独的分页操作*如果希望做分页操作，返回的数据类型必须是spring-data-jpa跟我们封装好的Page，参数放Pageable接口*/Page&lt;Grade&gt;findAll(Pageablepage);}5、测试&lt;!--spring-data-jpa测试需要添加的依赖,如果直接在tomcat中运行不需要该包--&gt;&lt;dependency&gt;&lt;groupId&gt;net.minidev&lt;/groupId&gt;&lt;artifactId&gt;asm&lt;/artifactId&gt;&lt;version&gt;1.0.2&lt;/version&gt;&lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt;//测试增加@TestpublicvoidtestSave(){Gradegrade=newGrade();grade.setName(&quot;五年级&quot;);Gradeg=gradeRepository.save(grade);//增加后很容易拿到主键System.out.println(g);}//测试修改(如果不给主键是增加，给主键就是修改)@TestpublicvoidtestUpdate(){Gradegrade=newGrade();grade.setId(4);grade.setName(&quot;原子弹设置与制造&quot;);Gradeg=gradeRepository.save(grade);System.out.println(g);}//测试删除--根据主键删除@TestpublicvoidtestDeleteById(){//执行删除gradeRepository.deleteById(5);}//测试删除--根据对象删除@TestpublicvoidtestDeleteByObject(){//执行删除Gradegrade=newGrade();grade.setId(4);gradeRepository.delete(grade);}//测试删除--删除全部@TestpublicvoidtestDeleteAll(){gradeRepository.deleteAll();}@TestpublicvoidtestSave100(){for(inti=1;i&lt;=100;i++){Gradegrade=newGrade();grade.setName(i+&quot;年级&quot;);gradeRepository.save(grade);}}//测试查询--查询全部@TestpublicvoidtestGetAll(){List&lt;Grade&gt;list=gradeRepository.findAll();for(Gradegrade:list){System.out.println(grade);}}//测试查询--根据id查询@TestpublicvoidtestGetById(){//根据主键查询Gradegrade=gradeRepository.findById(1).get();System.out.println(grade);}//测试查询--根据id查询(在tomcat容器中不会有问题，但是在测试的时候会出现懒加载导致session关闭的问题)@TestpublicvoidtestGetById2(){//根据主键查询//使用getOne方法需要在配置文件中添加spring.jpa.properties.hibernate.enable_lazy_load_no_trans=trueGradegrade=gradeRepository.getOne(1);System.out.println(grade);}//测试查询--非主键的精确查询--根据年级名称做精确查询@TestpublicvoidtestGetGradeByName(){Gradegrade=gradeRepository.findGradeByName(&quot;1年级&quot;);System.out.println(grade);}//测试查询--模糊查询--根据年级名称做模糊查询@TestpublicvoidtestGetGradeByNameLike(){Stringname=&quot;火&quot;;List&lt;Grade&gt;list=gradeRepository.findGradeByNameLike(&quot;%&quot;+name+&quot;%&quot;);for(Gradegrade:list){System.out.println(grade);}}@TestpublicvoidtestGetById3(){Gradegrade=gradeRepository.findGradeById(2);System.out.println(grade);}//测试查询--多条件联合查询@TestpublicvoidtestGetGradeByIdAndNameLike(){Gradegrade=gradeRepository.findGradeByIdAndNameLike(1,&quot;%1年级%&quot;);System.out.println(grade);}//测试查询--分页查询@TestpublicvoidtestFindAllPages(){//构造Pageable使用PageRequest.of(参数一当前要展示的页码，参数二每页显示的信息条数)//注意：在mybatis的pagehelper中，当前源码是从1开始的，但是在spring-data-jpa中分页页码是从0开始//PageRequest中的其他参数//Pageablepageable=PageRequest.of(0,10,Sort.by(Sort.Direction.DESC,&quot;id&quot;));//Pageablepageable=PageRequest.of(0,10,Sort.Direction.DESC,&quot;id&quot;);Pageablepageable=PageRequest.of(1,10);Page&lt;Grade&gt;all=gradeRepository.findAll(pageable);System.out.println(&quot;总条数&quot;+all.getTotalElements());System.out.println(&quot;总页数&quot;+all.getTotalPages());System.out.println(&quot;是否有下一页&quot;+all.hasNext());System.out.println(&quot;是否有上一页&quot;+all.hasPrevious());System.out.println(&quot;是否有内容&quot;+all.hasContent());System.out.println(&quot;是否首页&quot;+all.isFirst());System.out.println(&quot;是否最后一页&quot;+all.isLast());System.out.println(&quot;元素数量&quot;+all.getNumberOfElements());//获取到一页数据List&lt;Grade&gt;list=all.getContent();for(Gradegrade:list){System.out.println(grade);}}","link":"https://haohanya.github.io/post/spring-data-jpa/"},{"title":"MongoDB","content":"Mongo什么是MongoDBMongoDB是一个基于分布式文件存储的数据库。由C++语言编写。旨在为WEB应用提供可扩展的高性能数据存储解决方案。MongoDB是一个介于关系数据库和非关系数据库之间的产品，是非关系数据库当中功能最丰富，最像关系数据库的。它支持的数据结构非常松散，是类似json的bson格式，因此可以存储比较复杂的数据类型。Mongo最大的特点是它支持的查询语言非常强大，其语法有点类似于面向对象的查询语言，几乎可以实现类似关系数据库单表查询的绝大部分功能，而且还支持对数据建立索引。MongoDB特点它的特点是高性能、易部署、易使用，存储数据非常方便。主要功能特性有：*面向集合存储的，易于存储对象类型的数据*模式自由。*支持动态[查询]*支持完全索引，包含内部对象。*支持查询。*支持复制和故障恢复。*使用高效的二进制数据存储，包括大型对象（如视频等）。*自动处理碎片，以支持云计算层次的扩展性。*支持Golang，RUBY，PYTHON，JAVA，C++，PHP，C#等多种语言。*文件存储格式为BSON（一种JSON的扩展）。*可通过网络访问。MongoDB体系结构mongo的逻辑结果是一种层次结构主要由如下几个东西组成：文档(document)、集合(collection)、数据库(database)这三部分组成，逻辑结构是面向用户的。用户就可以通过MongoDB开发应用程序使用的就是逻辑结构(1)MongoDB的document，相当于是MySQL（关系型数据库）中的一行记录(2)多个文档组成一个集合，在MySQL中多条记录组成的是表(3)多个集合，逻辑上组织在一起，就是一个数据库(4)一个MongoDB实例支持多个数据库MongoDBMysql数据库(database)数据库(database)集合(collection)表(table)文档(document)行(row)安装Mongo1、拉取镜像dockerpullmongo:latest2、创建容器dockerrun-di--name=mymongo-p27017:27017mongo--auth27017：mongo默认的端口--auth：启用验证，默认关闭3、创建用户#进入容器dockerexec-itmymongo/bin/bash#进入Mongomongo#选择数据库useadmin#创建用户db.createUser({user:&quot;root&quot;,pwd:&quot;root&quot;,roles:[{role:&quot;root&quot;,db:&quot;admin&quot;}]})CRUD如果涉及到认证问题，必须在操作之前登陆db.auth(&quot;账号&quot;,&quot;密码&quot;)添加语法：db.collection.save(json)db.student.save({name:&quot;张三&quot;,sex:&quot;男&quot;,address:&quot;湖北&quot;})查询查询全部语法：db.collection.find()db.student.find()#结果#{&quot;_id&quot;:ObjectId(&quot;5ece87413b6767c1aa235b37&quot;),&quot;name&quot;:&quot;张三&quot;,&quot;sex&quot;:&quot;女&quot;,&quot;address&quot;:&quot;湖北&quot;}这里大家会发现每条文档都有一个叫&quot;_id&quot;字段，这个相当于mysql数据库中表的主键，当你在插入记录的时候，没有指定该字段，mongo会自动创建，类型是ObjectId类型如果我们在插入文档记录的时候指定了该字段，其类型可以是ObjectId，也可以是mongo支持的任意数据类型如：db.student.save({_id:1,name:&quot;张三&quot;,sex:15,address:&quot;湖北&quot;})如果_id的值是一样的会覆盖原有的数据条件查询语法：db.collection.find({key:&quot;value&quot;})db.student.find({name:&quot;李四&quot;})查询单个语法：db.collection.findOne({key:value})修改完全修改语法：db.collection.update(条件json,修改后的json)部分修改语法：db.collection.update(条件json,{$set:{key:value,key:value}})删除语法：db.collection.remove(json条件)高级查询模糊查询语法：db.collection.find({key:/value/})查询key中带有value的文档查询NULL语法：db.collection.find({key:null})查询没有key的文档比较查询#大于db.collection.find({key:{$gt:value}})#小于db.collection.find({key:{$lt:value}})#大于或等于db.collection.find({key:{$gte:value}})#小于等于db.collection.find({key:{$lte:value}})#不等于db.collection.find({key:{$ne:value}})判断域/字段是否存在#语法db.collection.find({key:{$exists:true}})#例子：查询带有address的文档db.student.find({address:{$exists:true}})#例子：查询没有address的文档db.student.find({address:{$exists:false}})包含类似于mysql的in语法：db.collection.find({key:{$in:[v1,v2,v3,.....]}})统计数量语法：db.collection.count()添加条件语法：db.collection.count(json条件)逻辑运算符并且#语法db.collection.find($and:[{k1:v1},{k2:{表达式:v2}}])#例子：查询年龄大于10并且小于20db.student.find($and:[{age:{$gt:10}},{age:{$lt:20}}])或者#语法db.collection.find($or:[{k1:v1},{v2:{表达式:v2}}])#例子：查询年龄大于18或者性别为女db.student.find($or:[{age:{$gt:18}},{sex:&quot;女&quot;}])非db.collection.find({key:{$ne:value}})JAVA操作Mongo1、添加依赖&lt;!--mongodb客户端--&gt;&lt;dependency&gt;&lt;groupId&gt;org.mongodb&lt;/groupId&gt;&lt;artifactId&gt;mongo-java-driver&lt;/artifactId&gt;&lt;version&gt;3.9.1&lt;/version&gt;&lt;/dependency&gt;2、连接测试@TestpublicvoidtestConnection(){//创建认证对象，参数1：用户名、参数2：数据库、参数3：密码MongoCredentialcredential=MongoCredential.createCredential(&quot;root&quot;,&quot;admin&quot;,&quot;root&quot;.toCharArray());//创建mongo客户端对象，参数1：服务器地址，参数2：mongodb的端口号ServerAddressserverAddress=newServerAddress(&quot;192.168.25.146&quot;,27017);MongoClientclient=newMongoClient(serverAddress,Arrays.asList(credential));//获取到集合（数据库）MongoDatabasedatabase=client.getDatabase(&quot;admin&quot;);//获取collectionMongoCollection&lt;Document&gt;student=database.getCollection(&quot;student&quot;);//获取到document集合（一行记录）FindIterable&lt;Document&gt;documents=student.find();for(Documentdocument:documents){System.out.println(document.getString(&quot;name&quot;));System.out.println(document.getDouble(&quot;age&quot;));System.out.println(document.getString(&quot;sex&quot;));}}3、条件查询-匹配@TestpublicvoidtestFindBasi(){//创建认证对象，参数1：用户名、参数2：数据库、参数3：密码MongoCredentialcredential=MongoCredential.createCredential(&quot;root&quot;,&quot;admin&quot;,&quot;root&quot;.toCharArray());//创建mongo客户端对象，参数1：服务器地址，参数2：mongodb的端口号ServerAddressserverAddress=newServerAddress(&quot;192.168.25.146&quot;,27017);MongoClientclient=newMongoClient(serverAddress,Arrays.asList(credential));//获取到集合（数据库）MongoDatabasedatabase=client.getDatabase(&quot;admin&quot;);//获取collectionMongoCollection&lt;Document&gt;student=database.getCollection(&quot;student&quot;);/*------------------------------------创建查询条件----------------------------------------------*/Map&lt;String,Object&gt;map=newHashMap&lt;&gt;();map.put(&quot;name&quot;,&quot;张三&quot;);BasicDBObjectbasicDBObject=newBasicDBObject(map);/*------------------------------------创建查询条件----------------------------------------------*///获取到document集合（一行记录）FindIterable&lt;Document&gt;documents=student.find(basicDBObject);for(Documentdocument:documents){System.out.println(document.getString(&quot;name&quot;));System.out.println(document.getDouble(&quot;age&quot;));System.out.println(document.getString(&quot;sex&quot;));}}4、条件查询-模糊完全匹配/*------------------------------------创建查询条件----------------------------------------------*/Patternpattern=Pattern.compile(&quot;^张三$&quot;);Map&lt;String,Object&gt;map=newHashMap&lt;&gt;();map.put(&quot;name&quot;,pattern);BasicDBObjectbasicDBObject=newBasicDBObject(map);/*------------------------------------创建查询条件----------------------------------------------*/右匹配Patternpattern=Pattern.compile(&quot;^张.*$&quot;);左匹配Patternpattern=Pattern.compile(&quot;^.*张$&quot;);模糊匹配Patternpattern=Pattern.compile(&quot;^.*张.*$&quot;);5、数字比较//查询年龄大于10/*------------------------------------创建查询条件----------------------------------------------*/BasicDBObjectbasicDBObject=newBasicDBObject(&quot;age&quot;,newBasicDBObject(&quot;$gt&quot;,10));/*------------------------------------创建查询条件----------------------------------------------*/6、条件连接-并且//查询性别为男并且年龄大于10岁/*------------------------------------创建查询条件----------------------------------------------*/BasicDBObjectbasicDBObject1=newBasicDBObject(&quot;sex&quot;,&quot;男&quot;);BasicDBObjectbasicDBObject2=newBasicDBObject(&quot;age&quot;,newBasicDBObject(&quot;$gt&quot;,10));BasicDBObjectbasicDBObject=newBasicDBObject(&quot;$and&quot;,Arrays.asList(basicDBObject1,basicDBObject2));/*------------------------------------创建查询条件----------------------------------------------*/7、条件连接-或者//查询性别为男或者年龄大于20/*------------------------------------创建查询条件----------------------------------------------*/BasicDBObjectbasicDBObject1=newBasicDBObject(&quot;sex&quot;,&quot;男&quot;);BasicDBObjectbasicDBObject2=newBasicDBObject(&quot;age&quot;,newBasicDBObject(&quot;$gt&quot;,20));BasicDBObjectbasicDBObject=newBasicDBObject(&quot;$or&quot;,Arrays.asList(basicDBObject1,basicDBObject2));/*------------------------------------创建查询条件----------------------------------------------*/8、添加//创建认证对象，参数1：用户名、参数2：数据库、参数3：密码MongoCredentialcredential=MongoCredential.createCredential(&quot;root&quot;,&quot;admin&quot;,&quot;root&quot;.toCharArray());//创建mongo客户端对象，参数1：服务器地址，参数2：mongodb的端口号ServerAddressserverAddress=newServerAddress(&quot;192.168.25.146&quot;,27017);MongoClientclient=newMongoClient(serverAddress,Arrays.asList(credential));//获取到集合（数据库）MongoDatabasedatabase=client.getDatabase(&quot;admin&quot;);//获取collectionMongoCollection&lt;Document&gt;student=database.getCollection(&quot;student&quot;);Map&lt;String,Object&gt;map=newHashMap&lt;&gt;();map.put(&quot;name&quot;,&quot;王五&quot;);map.put(&quot;sex&quot;,&quot;男&quot;);map.put(&quot;age&quot;,15);map.put(&quot;address&quot;,&quot;湖南&quot;);Documentdocument=newDocument(map);student.insertOne(document);9、修改//把_id为1的文档中age修改为55publicvoidupdate(){//创建认证对象，参数1：用户名、参数2：数据库、参数3：密码MongoCredentialcredential=MongoCredential.createCredential(&quot;root&quot;,&quot;admin&quot;,&quot;root&quot;.toCharArray());//创建mongo客户端对象，参数1：服务器地址，参数2：mongodb的端口号ServerAddressserverAddress=newServerAddress(&quot;192.168.25.146&quot;,27017);MongoClientclient=newMongoClient(serverAddress,Arrays.asList(credential));//获取到集合（数据库）MongoDatabasedatabase=client.getDatabase(&quot;admin&quot;);//获取collectionMongoCollection&lt;Document&gt;student=database.getCollection(&quot;student&quot;);//修改的条件BasicDBObjectfilter=newBasicDBObject(&quot;_id&quot;,1);//修改后的域和值BasicDBObjectupdate=newBasicDBObject(&quot;$set&quot;,newBasicDBObject(&quot;age&quot;,55));student.updateOne(filter,update);}10、删除文档publicvoiddelete(){//创建认证对象，参数1：用户名、参数2：数据库、参数3：密码MongoCredentialcredential=MongoCredential.createCredential(&quot;root&quot;,&quot;admin&quot;,&quot;root&quot;.toCharArray());//创建mongo客户端对象，参数1：服务器地址，参数2：mongodb的端口号ServerAddressserverAddress=newServerAddress(&quot;192.168.25.146&quot;,27017);MongoClientclient=newMongoClient(serverAddress,Arrays.asList(credential));//获取到集合（数据库）MongoDatabasedatabase=client.getDatabase(&quot;admin&quot;);//获取collectionMongoCollection&lt;Document&gt;student=database.getCollection(&quot;student&quot;);//删除条件BasicDBObjectbasicDBObject=newBasicDBObject(&quot;_id&quot;,1);student.deleteOne(basicDBObject);//删除一个student.deleteMany(basicDBObject);//删除所有满足条件的}MongoDB工具类MongoClient被设计成线程安全的类（单线程），也就是我们在使用该类的时候不用考虑并发的情况，这样我们就可以考虑将mongoClient做成一个静态变量，为所有的线程共用，不必每次都销毁，这样就可以极大的提高执行的效率，实际上mongodb提供了内置的连接池来实现packagecom.mongo.util;importcom.mongodb.*;importcom.mongodb.client.MongoDatabase;importjava.util.Arrays;/***@program:mongodb*@author:潘*@create:2020-05-2812:57**/publicclassMongoManager{privatestaticMongoClientclient=null;privatestaticvoidinit(){MongoCredentialcredential=MongoCredential.createCredential(&quot;root&quot;,&quot;admin&quot;,&quot;root&quot;.toCharArray());ServerAddressserverAddress=newServerAddress(&quot;192.168.25.146&quot;,27017);//选项构造者MongoClientOptions.Builderbuilder=newMongoClientOptions.Builder();//读取数据的超时时间builder.socketTimeout(5000);//每个地址最大请求数builder.connectionsPerHost(30);//写入的策略,仅仅抛出网络异常builder.writeConcern(WriteConcern.NORMAL);MongoClientOptionsoptions=builder.build();client=newMongoClient(serverAddress,Arrays.asList(credential),options);}publicstaticMongoDatabasegetDatabase(Stringdb){if(client==null){init();}returnclient.getDatabase(db);}}daopublicclassStudentDao{publicvoidsave(Stringname,Stringsex,doubleage,Stringaddress){//2.获取数据库(数据库)MongoDatabasedatabase=MongoManager.getDatabase(&quot;admin&quot;);//3.获取到collection(表)MongoCollection&lt;Document&gt;collection=database.getCollection(&quot;student&quot;);//4.准备要添加的数据Map&lt;String,Object&gt;map=newHashMap&lt;String,Object&gt;();map.put(&quot;name&quot;,name);map.put(&quot;sex&quot;,sex);map.put(&quot;age&quot;,age);map.put(&quot;address&quot;,address);Documentdocument=newDocument(map);//5.添加数据collection.insertOne(document);}}","link":"https://haohanya.github.io/post/mongodb/"},{"title":"Docker","content":"Docker安装Docker1、使用yum命令在线安装yuminstalldocker#遇事不决就选y2、查看docker版本docker-v3、启动与停止systemctl命令是系统服务管理器指令，它是service和chkconfig两个命令组合#启动dockersystemctlstartdocker#停止dockersystemctlstopdocker#重启dockersystemctlrestartdocker#查看docker状态systemctlstatusdocker#开机自启systemctlenabledocker#查看docker概要信息dockerinfo#查看docker帮助文档docker--infoDocker镜像操作1、列出镜像dockerimages#REPOSITORY镜像所在的仓库名称#TAG镜像标签（版本号）#IMAGEID镜像ID#CREATE镜像创建的时间（仓库中创建的时间）#SIZE镜像大小2、搜索镜像dockersearch镜像名称#INDEX#NAME仓库名称#DESCRIPTION镜像描述#STARS用户评价，反应一个镜像的受欢迎程度#OFFICIAL是否是官方#AUTOMATED自动构建，表示该镜像由DockerHub自动构建流程创建的3、拉取镜像从DockerHub上拉取dockerpullcentos:7ustc的镜像https://lug.ustc.edu.cn/wiki/mirrors/help/docker阿里云镜像1、进入阿里云https://cr.console.aliyun.com/cn-hangzhou/instances/mirrors2、得到镜像URL并修改daemon.json3、重启daemonsystemctldaemon-reload4、重启docker服务systemctlrestartdocker修改daemon.json1、编辑文件vi/etc/docker/daemon.json2、修改文件内容{&quot;registry-mirrors&quot;:[&quot;https://docker.mirrors.ustc.edu.cn&quot;]}3、重启4、删除镜像#删除指定镜像dockerrmi$IMAGE_ID#删除所有镜像dockerrmi`dockerimages-q`Docker容器操作1、查看容器#查看正在运行的容器dockerps#查看运行过的容器dockerps-a#查看最后一次运行的容器dockerps-i#查看停止的容器dockerps-fstatus=exited2、创建与启动容器创建容器常用的参数说明dockerrun创建容器命令-i运行该容器-t表示容器启动后会进入其命令行。加入这两个参数后，容器创建就能登录进去。即分配一个伪终端。--name为创建的容器命名-v表示目录映射关系（前者是宿主机目录，后者是映射到宿主机上的目录），可以使用多个－v做多个目录或文件映射。注意：最好做目录映射，在宿主机上做修改，然后共享到容器上。-d在run后面加上-d参数则会创建一个守护式容器在后台运行（这样创建容器后不会自动登陆容器，如果只加-i-t两个参数，创建后就会自动进入容器）-p端口映射，前者是宿主机端口，后者是容器内的映射端口，可以使用多个-p做多个端口映射交互式容器创建一个交互式容器并命名为：mycentosdockerrun-it--name=mycentoscentos:7/bin/bash使用exit命令退出当前容器创建守护式容器创建一个守护式容器：如果对于一个需要长期运行的容器来说，我们可以创建一个守护式容器。命令如下（容器名称不能重复）dockerrun-id--name=mycentos2centos:7登陆守护式容器dockerexec-itcontainer_name(或者container_id)/bin/bash(exit退出时容器不会停止)3、停止与启动容器#停止正在运行的容器dockerstop$CONTAINER_NAME/ID#运行已停止的容器dockerstart$CONTAINER_NAME/ID4、文件拷贝#将文件拷贝到容器内dockercp宿主机内要拷贝的文件或目录容器名称:拷贝到容器目录#将容器内的文件拷贝出来dockercp容器名称:容器要拷贝出开的文件或目录拷贝到宿主机那个目录5、目录挂载我们可以在创建容器的时候，将宿主机的目录与容器内的目录进行映射，这样我们就可以通过修改宿主机某个目录的文件从而去影响容器。创建容器添加-v参数后边为宿主机目录:容器目录如果共享多级目录可能会出现权限不足的情况这是因为CentOS7中的安全模块selinux把权限禁掉了，我们需要添加参数--privileged=true来解决挂载的目录没有权限的问题dockerrun-di-v/usr/test:/usr/test--name=mycentoscentos:76、查看容器IP地址#可以通过以下命令查看容器运行的各种数据dockerinspectcontainer_name#也可以直接执行下面的命令直接输出IP地址dockerinspect--format='{{.NetworkSettings.IPAddress}}'container_name7、删除容器#删除指定容器dockerrmcontainer_id/name#删除所有容器（以停止运行的）dockerrm`dockerps-a-q`部署应用MySQL部署1、拉取MySQL镜像dockerpullmysql2、创建MySQL容器#-p宿主机映射端口:容器运行端口#-e表示添加环境变量，MYSQL_ROOT_PASSWORD为root用户的登陆密码dockerrun-di--name=jd_mysql-p33306:3306-eMYSQL_ROOT_PASSWORD=rootmysql3、进入MySQL容器dockerexec-itjd_mysql/bin/bash4、登陆MySQL#-u用户名，-u后面需要打空格#-p密码，-p后面没有空格,加了空格会再输入一遍密码mysql-uroot-proot5、退出MySQL#退出mysqlquit#退出容器exitTomcat部署1、拉取Tomcat镜像dockerpulltomcat:7-jre72、创建tomcat容器创建容器用于部署单点登录系统（CAS）-p表示地址映射dockerrun-di--name=jd_tomcat-p9100:8080-v/usr/local/webapps:/usr/local/tomcat/webapps--privileged=truetomcat:7-jre73、访问ip:9100/cas登陆测试，如果出现Invalidcredentials重启.dockerrestartjd_tomcatnginx部署1、拉取镜像dockerpullnginx2、创建容器dockerrun-di--name=mynginx-p80:80nginx/bin/bash3、测试无法访问需要手动启动nginxdockerexec-itjd_nginx/bin/bash/etc/init.d/nginxstart4、编辑配置文件#将nginx配置文件复制出来dockercpjd_nginx:/etc/nginx/nginx.confnginx.conf#修改nginx.conf.......#将文件拷贝到容器dockercpnginx.confjd_nginx:/etc/nginx/nginx.conf#重启容器dockerrestartjd_nginxRedis部署1、拉取镜像dockerpullredis2、创建容器dockerrun-di--name=jd_redis-p6379:6379redis3、测试连接redisDesktop备份与迁移1、将容器保存为镜像dockercommitjd_nginxmynginxjd_nginx：容器名称mynginx：新镜像名称2、镜像备份dockersave-omynginx.tarmynginx-o：输出到的文件3、镜像恢复与迁移dockerload-imynginx.tar-i：输入的文件","link":"https://haohanya.github.io/post/docker/"},{"title":"Redis-Cluster","content":"搭建Redis-Cluster搭建要求需要6台redis服务器。搭建伪集群。需要6个redis实例。需要运行在不同的端口7001-7006准备工作1、安装gccyuminstallgcc-c++2、使用yum命令安装ruby（我们需要使用ruby脚本来实现集群搭建）yuminstallrubyyuminstallrubygems以上两步遇到选择y/N直接填y即可3、将redis源码包上传到linux系统，解压redis源码包tar-zxvfredis-3.0.0.tar.gz4、编译redis源码，进入redis源码文件夹cdredis-3.0.0make5、创建目录/usr/local/redis-cluster目录，安装6个redis实例，分别安装在以下目录mkdir/usr/local/redis-clustercdredis-3.0.0makeinstallPREFIX=/usr/local/redis-cluster/redis-1......makeinstallPREFIX=/usr/local/redis-cluster/redis-66、复制配置文件将/redis-3.0.0/redis.conf复制到redis下的bin目录下cpredis.conf/usr/local/redis-cluster/redis-1/bin......cpredis.conf/usr/local/redis-cluster/redis-6/bin配置集群1、修改每个redis节点的配置文件redis.conf修改运行端口为7001（70027003.....）(45行)将cluster-enabledyes前的注释去掉(632行)daemonizeno改为yes（43行）cd/usr/local/redis-cluster/viredis-1/bin/redis.conf......viredis-6/bin/redis.conf2、启动每个redis实例cdredis-1/bin/./redis-serverredis.conf.......3、上传redis-3.0.0.gem，安装ruby用于搭建redis集群的脚本。cd~cpredis-3.0.0.gem/usr/local/redis-cluster/cdredis-3.0.0/src/cpredis-trib.rb/usr/local/redis-cluster/cd/usr/local/redis-cluster/geminstallredis-3.0.0.gem4、使用ruby脚本搭建集群。进入redis源码目录中的src目录执行下面的命令./redis-trib.rbcreate--replicas1192.168.25.144:7001192.168.25.144:7002192.168.25.144:7003192.168.25.144:7004192.168.25.144:7005192.168.25.144:70065、查看是否启动成功ps-ef|grepredisSpringDataRedis连接Redis集群&lt;?xmlversion=&quot;1.0&quot;encoding=&quot;UTF-8&quot;?&gt;&lt;beansxmlns=&quot;http://www.springframework.org/schema/beans&quot;xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;xmlns:p=&quot;http://www.springframework.org/schema/p&quot;xmlns:context=&quot;http://www.springframework.org/schema/context&quot;xsi:schemaLocation=&quot;http://www.springframework.org/schema/beanshttp://www.springframework.org/schema/beans/spring-beans.xsdhttp://www.springframework.org/schema/contexthttp://www.springframework.org/schema/context/spring-context.xsd&quot;&gt;&lt;!--加载配置属性文件--&gt;&lt;context:property-placeholderignore-unresolvable=&quot;true&quot;location=&quot;classpath:properties/redis-cluster-config.properties&quot;/&gt;&lt;beanid=&quot;redis-clusterConfiguration&quot;class=&quot;org.springframework.data.redis.connection.redis-clusterConfiguration&quot;&gt;&lt;propertyname=&quot;maxRedirects&quot;value=&quot;${redis.maxRedirects}&quot;&gt;&lt;/property&gt;&lt;propertyname=&quot;clusterNodes&quot;&gt;&lt;set&gt;&lt;beanclass=&quot;org.springframework.data.redis.connection.redis-clusterNode&quot;&gt;&lt;constructor-argname=&quot;host&quot;value=&quot;${redis.host1}&quot;&gt;&lt;/constructor-arg&gt;&lt;constructor-argname=&quot;port&quot;value=&quot;${redis.port1}&quot;&gt;&lt;/constructor-arg&gt;&lt;/bean&gt;&lt;beanclass=&quot;org.springframework.data.redis.connection.redis-clusterNode&quot;&gt;&lt;constructor-argname=&quot;host&quot;value=&quot;${redis.host2}&quot;&gt;&lt;/constructor-arg&gt;&lt;constructor-argname=&quot;port&quot;value=&quot;${redis.port2}&quot;&gt;&lt;/constructor-arg&gt;&lt;/bean&gt;&lt;beanclass=&quot;org.springframework.data.redis.connection.redis-clusterNode&quot;&gt;&lt;constructor-argname=&quot;host&quot;value=&quot;${redis.host3}&quot;&gt;&lt;/constructor-arg&gt;&lt;constructor-argname=&quot;port&quot;value=&quot;${redis.port3}&quot;&gt;&lt;/constructor-arg&gt;&lt;/bean&gt;&lt;beanclass=&quot;org.springframework.data.redis.connection.redis-clusterNode&quot;&gt;&lt;constructor-argname=&quot;host&quot;value=&quot;${redis.host4}&quot;&gt;&lt;/constructor-arg&gt;&lt;constructor-argname=&quot;port&quot;value=&quot;${redis.port4}&quot;&gt;&lt;/constructor-arg&gt;&lt;/bean&gt;&lt;beanclass=&quot;org.springframework.data.redis.connection.redis-clusterNode&quot;&gt;&lt;constructor-argname=&quot;host&quot;value=&quot;${redis.host5}&quot;&gt;&lt;/constructor-arg&gt;&lt;constructor-argname=&quot;port&quot;value=&quot;${redis.port5}&quot;&gt;&lt;/constructor-arg&gt;&lt;/bean&gt;&lt;beanclass=&quot;org.springframework.data.redis.connection.redis-clusterNode&quot;&gt;&lt;constructor-argname=&quot;host&quot;value=&quot;${redis.host6}&quot;&gt;&lt;/constructor-arg&gt;&lt;constructor-argname=&quot;port&quot;value=&quot;${redis.port6}&quot;&gt;&lt;/constructor-arg&gt;&lt;/bean&gt;&lt;/set&gt;&lt;/property&gt;&lt;/bean&gt;&lt;beanid=&quot;jedisPoolConfig&quot;class=&quot;redis.clients.jedis.JedisPoolConfig&quot;&gt;&lt;propertyname=&quot;maxIdle&quot;value=&quot;${redis.maxIdle}&quot;/&gt;&lt;propertyname=&quot;maxTotal&quot;value=&quot;${redis.maxTotal}&quot;/&gt;&lt;/bean&gt;&lt;beanid=&quot;jeidsConnectionFactory&quot;class=&quot;org.springframework.data.redis.connection.jedis.JedisConnectionFactory&quot;&gt;&lt;constructor-argref=&quot;redis-clusterConfiguration&quot;/&gt;&lt;constructor-argref=&quot;jedisPoolConfig&quot;/&gt;&lt;/bean&gt;&lt;beanid=&quot;redisTemplate&quot;class=&quot;org.springframework.data.redis.core.RedisTemplate&quot;&gt;&lt;propertyname=&quot;connectionFactory&quot;ref=&quot;jeidsConnectionFactory&quot;/&gt;&lt;/bean&gt;&lt;/beans&gt;redis-cluster-config.propertiesredis.host1=192.168.25.140redis.port1=7001redis.host2=192.168.25.140redis.port2=7002redis.host3=192.168.25.140redis.port3=7003redis.host4=192.168.25.140redis.port4=7004redis.host5=192.168.25.140redis.port5=7005redis.host6=192.168.25.140redis.port6=7006redis.maxRedirects=3redis.maxIdle=100redis.maxTotal=600模拟集群异常测试关闭节点命令./redis-cli-p端口shutdown测试关闭7001和7004,看看会发生什么。测试关闭7001、7002、7003会发生什么。","link":"https://haohanya.github.io/post/redis-cluster/"},{"title":" Zookeeper-Cluster","content":"查看tomcat运行日志：tail-flogs/catalina.outZooKeeper安装官网下载：http://zookeeper.apache.org/releases.html第一次启动会出现错误解决方案：把conf目录下的zoo_sample.cfg复制一份，并改名为zoo.cfg在zookeeper根目录新建一个data目录修改zoo.cfg里面的dataDir=/tmp/zookeeper修改为：../data服务提供者&lt;!--使用dubbo暴漏服务--&gt;&lt;dubbo:protocolname=&quot;dubbo&quot;port=&quot;20881&quot;/&gt;&lt;!--将工程注册到dubbo中--&gt;&lt;dubbo:applicationname=&quot;jd-sellergoods-service&quot;/&gt;&lt;!--注册中心地址--&gt;&lt;dubbo:registryaddress=&quot;zookeeper://192.168.25.128:2181&quot;/&gt;&lt;!--开启注解开发--&gt;&lt;dubbo:annotationpackage=&quot;com.jd.service.impl&quot;/&gt;服务消费者&lt;!--引用dubbo服务--&gt;&lt;dubbo:applicationname=&quot;jd-sellergoods-web&quot;/&gt;&lt;dubbo:registryaddress=&quot;zookeeper://192.168.25.128:2181&quot;timeout=&quot;30000&quot;/&gt;&lt;dubbo:annotationpackage=&quot;com.jd.controller&quot;/&gt;Zookeeper集群简介为什么搭建Zookeeper集群大部分分布式应用需要一个主控、协调器或者控制器来管理物理分布的子进程。目前，大多数都要开发私有的协调程序，缺乏一个通用机制，协调程序的反复编写浪费，且难以形成通用、伸缩性好的协调器，zookeeper提供通用的分布式锁服务，用以协调分布式应用。所以说zookeeper是分布式应用的协作服务。zookeeper作为注册中心，服务器和客户端都要访问，如果有大量的并发，肯定会有等待。所以可以通过zookeeper集群解决。下面是zookeeper集群部署结构图：了解Leader选举Zookeeper的启动过程中leader选举是非常重要而且最复杂的一个环节。那么什么是leader选举呢？zookeeper为什么需要leader选举呢？zookeeper的leader选举的过程又是什么样子的？首先我们来看看什么是leader选举。其实这个很好理解，leader选举就像总统选举一样，每人一票，获得多数票的人就当选为总统了。在zookeeper集群中也是一样，每个节点都会投票，如果某个节点获得超过半数以上的节点的投票，则该节点就是leader节点了。以一个简单的例子来说明整个选举的过程.假设有五台服务器组成的zookeeper集群,它们的id从1-5,同时它们都是最新启动的,也就是没有历史数据,在存放数据量这一点上,都是一样的.假设这些服务器依序启动,来看看会发生什么。1)服务器1启动,此时只有它一台服务器启动了,它发出去的报没有任何响应,所以它的选举状态一直是LOOKING状态2)服务器2启动,它与最开始启动的服务器1进行通信,互相交换自己的选举结果,由于两者都没有历史数据,所以id值较大的服务器2胜出,但是由于没有达到超过半数以上的服务器都同意选举它(这个例子中的半数以上是3),所以服务器1,2还是继续保持LOOKING状态.3)服务器3启动,根据前面的理论分析,服务器3成为服务器1,2,3中的老大,而与上面不同的是,此时有三台服务器选举了它,所以它成为了这次选举的leader.4)服务器4启动,根据前面的分析,理论上服务器4应该是服务器1,2,3,4中最大的,但是由于前面已经有半数以上的服务器选举了服务器3,所以它只能接收当小弟的命了.5)服务器5启动,同4一样,当小弟ZooKeeper集群搭建真实的集群是需要部署在不同的服务器上的，但是在我们测试时同时启动十几个虚拟机内存会吃不消，所以我们通常会搭建伪集群，也就是把所有的服务都搭建在一台虚拟机上，用端口进行区分。我们这里要求搭建一个三个节点的Zookeeper集群（伪集群）。测试环境​jdk：1.7​zookeeper：3.4.6​centos：6.x1、创建一个目录mkdir/usr/local/zookeeper-cluster2、上传zookeeper文件并解压tar-zxvfzookeeper-3.4.6.tar.gz#新建文件夹mkdirzookeeper-3.4.6/data#修改coo.cfg名cdzookeeper-3.4.6/conf/mvzoo_sample.cfgzoo.cfg3、复制zookeepercp-rzookeeper-3.4.6/usr/local/zookeeper-cluster/zookeeper-1cp-rzookeeper-3.4.6/usr/local/zookeeper-cluster/zookeeper-2cp-rzookeeper-3.4.6/usr/local/zookeeper-cluster/zookeeper-34、配置每一个Zookeeper配置每一个Zookeeper的dataDir（zoo.cfg）clientPort分别为218121822183vi/usr/local/zookeeper-cluster/zookeeper-1/conf/zoo.cfgclientPort=2181dataDir=/usr/local/zookeeper-cluster/zookeeper-1/datavi/usr/local/zookeeper-cluster/zookeeper-2/conf/zoo.cfgclientPort=2182dataDir=/usr/local/zookeeper-cluster/zookeeper-2/datavi/usr/local/zookeeper-cluster/zookeeper-3/conf/zoo.cfgclientPort=2183dataDir=/usr/local/zookeeper-cluster/zookeeper-3/data5、配置集群在每个zookeeper的data目录下创建一个myid文件，内容分别是1、2、3。这个文件就是记录每个服务器的ID（内容为自定义，后面会用到，只要不重复即可）cd/usr/local/zookeeper-cluster/echo1&gt;zookeeper-1/data/myidecho2&gt;zookeeper-2/data/myidecho3&gt;zookeeper-3/data/myid在每一个zookeeper的zoo.cfg配置客户端访问端口（clientPort）和集群服务器IP列表。解释：server.服务器ID=服务器IP地址:服务器之间通信端口:服务器之间投票选举端口服务器ID为上面自定义的内容server.1=192.168.25.143:2881:3881server.2=192.168.25.143:2882:3882server.3=192.168.25.143:2883:3883vizookeeper-1/conf/zoo.cfgvizookeeper-2/conf/zoo.cfgvizookeeper-3/conf/zoo.cfg6、启动集群启动集群就是分别启动每个实例。./zookeeper-1/bin/zkServer.shstart./zookeeper-2/bin/zkServer.shstart./zookeeper-3/bin/zkServer.shstart#查看启动状态./zookeeper-1/bin/zkServer.shstatus./zookeeper-2/bin/zkServer.shstatus./zookeeper-3/bin/zkServer.shstatus#如果出现错误，则需要查看日志vizookeeper.outMode为follower表示是跟随者（从）Mod为leader表示是领导者（主）7、模拟集群异常首先我们先测试如果是从服务器挂掉，会怎么样把3号服务器停掉，观察1号和2号，发现状态并没有变化由此得出结论，3个节点的集群，从服务器挂掉，集群正常我们再把1号服务器（从服务器）也停掉，查看2号（主服务器）的状态，发现已经停止运行了。由此得出结论，3个节点的集群，2个从服务器都挂掉，主服务器也无法运行。因为可运行的机器没有超过集群总数量的半数。我们再次把1号服务器启动起来，发现2号服务器又开始正常工作了。而且依然是领导者。我们把3号服务器也启动起来，把2号服务器停掉（汗~~干嘛？领导挂了？）停掉后观察1号和3号的状态。发现新的leader产生了~由此我们得出结论，当集群中的主服务器挂了，集群中的其他服务器会自动进行选举状态，然后产生新得leader我们再次测试，当我们把2号服务器重新启动起来（汗~~这是诈尸啊!）启动后，会发生什么？2号服务器会再次成为新的领导吗？我们看结果我们会发现，2号服务器启动后依然是跟随者（从服务器），3号服务器依然是领导者（主服务器），没有撼动3号服务器的领导地位。哎~退休了就是退休了，说了不算了，哈哈。由此我们得出结论，当领导者产生后，再次有新服务器加入集群，不会影响到现任领导者。Dubbox连接zookeeper集群修改服务提供者和服务调用者的spring配置文件,多个节点使用“,”分割&lt;!--指定注册中心地址--&gt;&lt;dubbo:registryprotocol=&quot;zookeeper&quot;address=&quot;192.168.25.129:2181,192.168.25.129:2182,192.168.25.129:2183&quot;/&gt;","link":"https://haohanya.github.io/post/zookeeper-cluster/"},{"title":"单点登陆-CAS","content":"什么是单点登录单点登录（SingleSignOn），简称为SSO，是目前比较流行的企业业务整合的解决方案之一。SSO的定义是在多个应用系统中，用户只需要登录一次就可以访问所有相互信任的应用系统。我们目前的系统存在诸多子系统，而这些子系统是分别部署在不同的服务器中，那么使用传统方式的session是无法解决的，我们需要使用相关的单点登录技术来解决。什么是CASCAS是Yale大学发起的一个开源项目，旨在为Web应用系统提供一种可靠的单点登录方法，CAS在2004年12月正式成为JA-SIG的一个项目。CAS具有以下特点：【1】开源的企业级单点登录解决方案。【2】CASServer为需要独立部署的Web应用。【3】CASClient支持非常多的客户端(这里指单点登录系统中的各个Web应用)，包括Java,.Net,PHP,Perl,Apache,uPortal,Ruby等。从结构上看，CAS包含两个部分：CASServer和CASClient。CASServer需要独立部署，主要负责对用户的认证工作；CASClient负责处理对客户端受保护资源的访问请求，需要登录时，重定向到CASServer。下图是CAS最基本的协议过程：SSO单点登录访问流程主要有以下步骤：访问服务：SSO客户端发送请求访问应用系统提供的服务资源。定向认证：SSO客户端会重定向用户请求到SSO服务器。用户认证：用户身份认证。发放票据：SSO服务器会产生一个随机的ServiceTicket。验证票据：SSO服务器验证票据ServiceTicket的合法性，验证通过后，允许客户端访问服务。传输用户信息：SSO服务器验证票据通过后，传输用户认证结果信息给客户端。CAS服务端部署1、cas安装在资源\\cas\\source\\cas-server-4.0.0-release\\cas-server-4.0.0\\modules目录下cas-server-webapp-4.0.0.war将其改名为cas.war放入tomcat目录下的webapps下。启动tomcat自动解压war包。浏览器输入http://localhost:8080/cas/login，可看到登录页面这里有个固定的用户名和密码casuser/Mellon登录成功后会跳到登录成功的提示页面2、修改端口修改tomcat端口打开tomcat目录conf\\server.xml找到下面的配置&lt;Connectorport=&quot;8080&quot;protocol=&quot;HTTP/1.1&quot;connectionTimeout=&quot;20000&quot;redirectPort=&quot;8443&quot;/&gt;&lt;!--修改port为9100--&gt;修改CAS配置文件WEB-INF/cas.propertiesserver.name=http://localhost:91003、去除https认证CAS默认使用的是HTTPS协议，如果使用HTTPS协议需要SSL安全证书（需向特定的机构申请和购买）。如果对安全要求不高或是在开发测试阶段，可使用HTTP协议。我们这里讲解通过修改配置，让CAS使用HTTP协议。修改cas的WEB-INF/deployerConfigContext.xml&lt;beanclass=&quot;org.jasig.cas.authentication.handler.support.HttpBasedServiceCredentialsAuthenticationHandler&quot;p:httpClient-ref=&quot;httpClient&quot;/&gt;&lt;!--这里需要增加参数p:requireSecure=&quot;false&quot;requireSecure属性意思为是否需要安全验证即HTTPS，false为不采用--&gt;修改cas的/WEB-INF/spring-configuration/ticketGrantingTicketCookieGenerator.xml&lt;beanid=&quot;ticketGrantingTicketCookieGenerator&quot;class=&quot;org.jasig.cas.web.support.CookieRetrievingCookieGenerator&quot;p:cookieSecure=&quot;true&quot;p:cookieMaxAge=&quot;-1&quot;p:cookieName=&quot;CASTGC&quot;p:cookiePath=&quot;/cas&quot;/&gt;&lt;!--参数p:cookieSecure=&quot;true&quot;，同理为HTTPS验证相关，TRUE为采用HTTPS验证，FALSE为不采用https验证。参数p:cookieMaxAge=&quot;-1&quot;，是COOKIE的最大生命周期，-1为无生命周期，即只在当前打开的窗口有效，关闭或重新打开其它窗口，仍会要求验证。可以根据需要修改为大于0的数字，比如3600等，意思是在3600秒内，打开任意窗口，都不需要验证。我们这里将cookieSecure改为false,cookieMaxAge改为3600--&gt;修改cas的WEB-INF/spring-configuration/warnCookieGenerator.xml&lt;beanid=&quot;warnCookieGenerator&quot;class=&quot;org.jasig.cas.web.support.CookieRetrievingCookieGenerator&quot;p:cookieSecure=&quot;true&quot;p:cookieMaxAge=&quot;-1&quot;p:cookieName=&quot;CASPRIVACY&quot;p:cookiePath=&quot;/cas&quot;/&gt;&lt;!--将cookieSecure改为false,cookieMaxAge改为3600--&gt;CAS客户端入门小Demo客户端工程1搭建1、搭建工程引入依赖创建Maven工程（war）casclient_demo1引入cas客户端依赖并制定tomcat运行端口为9001&lt;dependencies&gt;&lt;!--cas--&gt;&lt;dependency&gt;&lt;groupId&gt;org.jasig.cas.client&lt;/groupId&gt;&lt;artifactId&gt;cas-client-core&lt;/artifactId&gt;&lt;version&gt;3.3.3&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;&lt;groupId&gt;javax.servlet&lt;/groupId&gt;&lt;artifactId&gt;servlet-api&lt;/artifactId&gt;&lt;version&gt;2.5&lt;/version&gt;&lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt;&lt;/dependencies&gt;&lt;build&gt;&lt;plugins&gt;&lt;!--配置Tomcat插件--&gt;&lt;plugin&gt;&lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt;&lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt;&lt;configuration&gt;&lt;port&gt;9001&lt;/port&gt;&lt;path&gt;/&lt;/path&gt;&lt;uriEncoding&gt;utf-8&lt;/uriEncoding&gt;&lt;/configuration&gt;&lt;/plugin&gt;&lt;/plugins&gt;&lt;/build&gt;2、修改web.xml&lt;?xmlversion=&quot;1.0&quot;encoding=&quot;UTF-8&quot;?&gt;&lt;web-appxmlns=&quot;http://xmlns.jcp.org/xml/ns/javaee&quot;xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;xsi:schemaLocation=&quot;http://xmlns.jcp.org/xml/ns/javaeehttp://xmlns.jcp.org/xml/ns/javaee/web-app_4_0.xsd&quot;version=&quot;4.0&quot;&gt;&lt;!--用于单点退出，该过滤器用于实现单点登出功能，可选配置--&gt;&lt;listener&gt;&lt;listener-class&gt;org.jasig.cas.client.session.SingleSignOutHttpSessionListener&lt;/listener-class&gt;&lt;/listener&gt;&lt;!--该过滤器用于实现单点登出功能，可选配置。--&gt;&lt;filter&gt;&lt;filter-name&gt;CASSingleSignOutFilter&lt;/filter-name&gt;&lt;filter-class&gt;org.jasig.cas.client.session.SingleSignOutFilter&lt;/filter-class&gt;&lt;/filter&gt;&lt;filter-mapping&gt;&lt;filter-name&gt;CASSingleSignOutFilter&lt;/filter-name&gt;&lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt;&lt;!--该过滤器负责用户的认证工作，必须启用它--&gt;&lt;filter&gt;&lt;filter-name&gt;CASFilter&lt;/filter-name&gt;&lt;filter-class&gt;org.jasig.cas.client.authentication.AuthenticationFilter&lt;/filter-class&gt;&lt;init-param&gt;&lt;param-name&gt;casServerLoginUrl&lt;/param-name&gt;&lt;param-value&gt;http://localhost:9100/cas/login&lt;/param-value&gt;&lt;!--这里的server是服务端的IP--&gt;&lt;/init-param&gt;&lt;init-param&gt;&lt;param-name&gt;serverName&lt;/param-name&gt;&lt;param-value&gt;http://localhost:9001&lt;/param-value&gt;&lt;/init-param&gt;&lt;/filter&gt;&lt;filter-mapping&gt;&lt;filter-name&gt;CASFilter&lt;/filter-name&gt;&lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt;&lt;!--该过滤器负责对Ticket的校验工作，必须启用它--&gt;&lt;filter&gt;&lt;filter-name&gt;CASValidationFilter&lt;/filter-name&gt;&lt;filter-class&gt;org.jasig.cas.client.validation.Cas20ProxyReceivingTicketValidationFilter&lt;/filter-class&gt;&lt;init-param&gt;&lt;param-name&gt;casServerUrlPrefix&lt;/param-name&gt;&lt;param-value&gt;http://localhost:9100/cas&lt;/param-value&gt;&lt;/init-param&gt;&lt;init-param&gt;&lt;param-name&gt;serverName&lt;/param-name&gt;&lt;param-value&gt;http://localhost:9001&lt;/param-value&gt;&lt;/init-param&gt;&lt;/filter&gt;&lt;filter-mapping&gt;&lt;filter-name&gt;CASValidationFilter&lt;/filter-name&gt;&lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt;&lt;!--该过滤器负责实现HttpServletRequest请求的包裹，比如允许开发者通过HttpServletRequest的getRemoteUser()方法获得SSO登录用户的登录名，可选配置。--&gt;&lt;filter&gt;&lt;filter-name&gt;CASHttpServletRequestWrapperFilter&lt;/filter-name&gt;&lt;filter-class&gt;org.jasig.cas.client.util.HttpServletRequestWrapperFilter&lt;/filter-class&gt;&lt;/filter&gt;&lt;filter-mapping&gt;&lt;filter-name&gt;CASHttpServletRequestWrapperFilter&lt;/filter-name&gt;&lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt;&lt;!--该过滤器使得开发者可以通过org.jasig.cas.client.util.AssertionHolder来获取用户的登录名。比如AssertionHolder.getAssertion().getPrincipal().getName()。--&gt;&lt;filter&gt;&lt;filter-name&gt;CASAssertionThreadLocalFilter&lt;/filter-name&gt;&lt;filter-class&gt;org.jasig.cas.client.util.AssertionThreadLocalFilter&lt;/filter-class&gt;&lt;/filter&gt;&lt;filter-mapping&gt;&lt;filter-name&gt;CASAssertionThreadLocalFilter&lt;/filter-name&gt;&lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt;&lt;/web-app&gt;3、编写index.jsp&lt;%@pagelanguage=&quot;java&quot;contentType=&quot;text/html;charset=utf-8&quot;pageEncoding=&quot;utf-8&quot;%&gt;&lt;!DOCTYPEhtmlPUBLIC&quot;-//W3C//DTDHTML4.01Transitional//EN&quot;&quot;http://www.w3.org/TR/html4/loose.dtd&quot;&gt;&lt;html&gt;&lt;head&gt;&lt;metahttp-equiv=&quot;Content-Type&quot;content=&quot;text/html;charset=utf-8&quot;&gt;&lt;title&gt;Hello&lt;/title&gt;&lt;/head&gt;&lt;body&gt;欢迎登陆一：&lt;%--为获取远程登录名--%&gt;&lt;%=request.getRemoteUser()%&gt;&lt;/body&gt;&lt;/html&gt;客户端工程2搭建1、搭建工程创建Maven工程（war）casclient_demo2引入cas客户端依赖并制定tomcat运行端口为90022、修改web.xml创建web.xml，参照casclient_demo1,将serverName的值改为http://localhost:9002，一共两处3、编写index.jsp创建index.jsp,内容显示“欢迎登陆二：”单点退出登录地址栏输入http://localhost:9100/cas/logout即可看到退出后的提示页面指定退出后跳转地址1、修改cas系统的配置文件cas-servlet.xml（217行）&lt;beanid=&quot;logoutAction&quot;class=&quot;org.jasig.cas.web.flow.LogoutAction&quot;p:servicesManager-ref=&quot;servicesManager&quot;p:followServiceRedirects=&quot;${cas.logout.followServiceRedirects:false}&quot;/&gt;&lt;!--把p:followServiceRedirects的false修改为true--&gt;2、填入跳转地址&lt;!--service参数为退出后跳转的地址--&gt;&lt;ahref=&quot;http://localhost:9100/cas/logout?service=http://www.baidu.com&quot;&gt;退出登录&lt;/a&gt;CAS服务端数据源设置1、配置数据源修改cas服务端中web-inf下deployerConfigContext.xml，添加如下配置&lt;!--配置数据源c3p0连接池--&gt;&lt;beanid=&quot;dataSource&quot;class=&quot;com.mchange.v2.c3p0.ComboPooledDataSource&quot;p:driverClass=&quot;com.mysql.jdbc.Driver&quot;p:jdbcUrl=&quot;jdbc:mysql://127.0.0.1:3306/jd?characterEncoding=utf8&quot;p:user=&quot;root&quot;p:password=&quot;root&quot;/&gt;&lt;!--密码加密的方式为md5,在登陆时先加密密码然后再去数据库比对--&gt;&lt;beanid=&quot;passwordEncoder&quot;class=&quot;org.jasig.cas.authentication.handler.DefaultPasswordEncoder&quot;c:encodingAlgorithm=&quot;MD5&quot;p:characterEncoding=&quot;UTF-8&quot;/&gt;&lt;!--数据校验--&gt;&lt;beanid=&quot;dbAuthHandler&quot;class=&quot;org.jasig.cas.adaptors.jdbc.QueryDatabaseAuthenticationHandler&quot;p:dataSource-ref=&quot;dataSource&quot;p:sql=&quot;selectpasswordfromtb_userwhereusername=?&quot;p:passwordEncoder-ref=&quot;passwordEncoder&quot;/&gt;然后在配置文件开始部分找到如下配置&lt;beanid=&quot;authenticationManager&quot;class=&quot;org.jasig.cas.authentication.PolicyBasedAuthenticationManager&quot;&gt;&lt;constructor-arg&gt;&lt;map&gt;&lt;entrykey-ref=&quot;proxyAuthenticationHandler&quot;value-ref=&quot;proxyPrincipalResolver&quot;/&gt;&lt;entrykey-ref=&quot;primaryAuthenticationHandler&quot;value-ref=&quot;primaryPrincipalResolver&quot;/&gt;&lt;/map&gt;&lt;/constructor-arg&gt;&lt;propertyname=&quot;authenticationPolicy&quot;&gt;&lt;beanclass=&quot;org.jasig.cas.authentication.AnyAuthenticationPolicy&quot;/&gt;&lt;/property&gt;&lt;/bean&gt;&lt;!--其中&lt;entrykey-ref=&quot;primaryAuthenticationHandler&quot;value-ref=&quot;primaryPrincipalResolver&quot;/&gt;一句是使用固定的用户名和密码，我们在下面可以看到这两个bean,如果我们使用数据库认证用户名和密码，需要将这句注释掉。添加下面这一句配置(54行)&lt;entrykey-ref=&quot;dbAuthHandler&quot;value-ref=&quot;primaryPrincipalResolver&quot;/&gt;--&gt;2、添加jar包将以下三个jar包放入webapps\\cas\\WEB-INF\\lib下c3p0-0.9.1.2.jarcas-server-support-jdbc-4.0.0.jarmysql-connector-java-5.1.32.jar3、测试用数据库中的用户名和密码进行测试修改默认登陆页面1、上传文件上传自己的登陆页面到WEB-INF\\view\\jsp\\default\\ui\\casLoginView.jsp2、编辑casLoginView.jsp内容1、添加指令&lt;%@pagepageEncoding=&quot;UTF-8&quot;%&gt;&lt;%@pagecontentType=&quot;text/html;charset=UTF-8&quot;%&gt;&lt;%@taglibprefix=&quot;c&quot;uri=&quot;http://java.sun.com/jsp/jstl/core&quot;%&gt;&lt;%@taglibprefix=&quot;spring&quot;uri=&quot;http://www.springframework.org/tags&quot;%&gt;&lt;%@taglibprefix=&quot;form&quot;uri=&quot;http://www.springframework.org/tags/form&quot;%&gt;&lt;%@taglibprefix=&quot;fn&quot;uri=&quot;http://java.sun.com/jsp/jstl/functions&quot;%&gt;2、修改form标签&lt;form:formmethod=&quot;post&quot;id=&quot;fm1&quot;commandName=&quot;${commandName}&quot;htmlEscape=&quot;true&quot;class=&quot;sui-form&quot;&gt;......&lt;/form:form&gt;3、修改用户名框&lt;form:inputid=&quot;username&quot;tabindex=&quot;1&quot;accesskey=&quot;${userNameAccessKey}&quot;path=&quot;username&quot;autocomplete=&quot;off&quot;htmlEscape=&quot;true&quot;placeholder=&quot;邮箱/用户名/手机号&quot;class=&quot;span2input-xfat&quot;/&gt;4、修改密码框&lt;form:passwordid=&quot;password&quot;tabindex=&quot;2&quot;path=&quot;password&quot;accesskey=&quot;${passwordAccessKey}&quot;htmlEscape=&quot;true&quot;autocomplete=&quot;off&quot;placeholder=&quot;请输入密码&quot;class=&quot;span2input-xfat&quot;/&gt;5、修改登陆按钮&lt;inputtype=&quot;hidden&quot;name=&quot;lt&quot;value=&quot;${loginTicket}&quot;/&gt;&lt;inputtype=&quot;hidden&quot;name=&quot;execution&quot;value=&quot;${flowExecutionKey}&quot;/&gt;&lt;inputtype=&quot;hidden&quot;name=&quot;_eventId&quot;value=&quot;submit&quot;/&gt;&lt;inputclass=&quot;sui-btnbtn-blockbtn-xlargebtn-danger&quot;accesskey=&quot;l&quot;value=&quot;登陆&quot;type=&quot;submit&quot;/&gt;3、错误提示在表单内加入错误提示框&lt;form:errorspath=&quot;*&quot;id=&quot;msg&quot;cssClass=&quot;errors&quot;element=&quot;div&quot;htmlEscape=&quot;false&quot;/&gt;设置登陆失败中文提示修改cas-servlet.xml中的en（61行）&lt;beanid=&quot;localeResolver&quot;class=&quot;org.springframework.web.servlet.i18n.CookieLocaleResolver&quot;p:defaultLocale=&quot;zh_CN&quot;/&gt;将此信息拷贝到WEB-INF\\classes\\messages_zh_CN.properties下，并改为中文提示（转码）authenticationFailure.AccountNotFoundException=\\u7528\\u6237\\u4E0D\\u5B58\\u5728.authenticationFailure.FailedLoginException=\\u5BC6\\u7801\\u9519\\u8BEF.第一个是用户名不存在时的错误提示第二个是密码错误的提示CAS客户端与SpringSecurity集成1、创建工程建立Maven项目casclient_demo3，引入spring依赖和springsecrity相关依赖，tomcat端口设置为90032、引入依赖&lt;dependencies&gt;&lt;dependency&gt;&lt;groupId&gt;org.springframework&lt;/groupId&gt;&lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt;&lt;version&gt;4.2.4.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;&lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt;&lt;artifactId&gt;jackson-databind&lt;/artifactId&gt;&lt;version&gt;2.4.2&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;&lt;groupId&gt;javax.servlet&lt;/groupId&gt;&lt;artifactId&gt;servlet-api&lt;/artifactId&gt;&lt;version&gt;2.5&lt;/version&gt;&lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt;&lt;!--身份验证--&gt;&lt;dependency&gt;&lt;groupId&gt;org.springframework.security&lt;/groupId&gt;&lt;artifactId&gt;spring-security-web&lt;/artifactId&gt;&lt;version&gt;4.1.0.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;&lt;groupId&gt;org.springframework.security&lt;/groupId&gt;&lt;artifactId&gt;spring-security-config&lt;/artifactId&gt;&lt;version&gt;4.1.0.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;&lt;groupId&gt;com.github.penggle&lt;/groupId&gt;&lt;artifactId&gt;kaptcha&lt;/artifactId&gt;&lt;version&gt;2.3.2&lt;/version&gt;&lt;exclusions&gt;&lt;exclusion&gt;&lt;groupId&gt;javax.servlet&lt;/groupId&gt;&lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt;&lt;/exclusion&gt;&lt;/exclusions&gt;&lt;/dependency&gt;&lt;dependency&gt;&lt;groupId&gt;org.springframework.security&lt;/groupId&gt;&lt;artifactId&gt;spring-security-cas&lt;/artifactId&gt;&lt;version&gt;4.1.0.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;&lt;groupId&gt;org.jasig.cas.client&lt;/groupId&gt;&lt;artifactId&gt;cas-client-core&lt;/artifactId&gt;&lt;version&gt;3.3.3&lt;/version&gt;&lt;!--排除log4j包冲突--&gt;&lt;exclusions&gt;&lt;exclusion&gt;&lt;groupId&gt;org.slf4j&lt;/groupId&gt;&lt;artifactId&gt;log4j-over-slf4j&lt;/artifactId&gt;&lt;/exclusion&gt;&lt;/exclusions&gt;&lt;/dependency&gt;&lt;/dependencies&gt;&lt;build&gt;&lt;plugins&gt;&lt;!--配置Tomcat插件--&gt;&lt;plugin&gt;&lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt;&lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt;&lt;configuration&gt;&lt;port&gt;9003&lt;/port&gt;&lt;path&gt;/&lt;/path&gt;&lt;uriEncoding&gt;utf-8&lt;/uriEncoding&gt;&lt;/configuration&gt;&lt;/plugin&gt;&lt;/plugins&gt;&lt;resources&gt;&lt;resource&gt;&lt;directory&gt;src/main/java&lt;/directory&gt;&lt;includes&gt;&lt;include&gt;**/*.*&lt;/include&gt;&lt;/includes&gt;&lt;/resource&gt;&lt;resource&gt;&lt;directory&gt;src/main/resources&lt;/directory&gt;&lt;includes&gt;&lt;include&gt;**/*.*&lt;/include&gt;&lt;/includes&gt;&lt;/resource&gt;&lt;/resources&gt;&lt;/build&gt;3、创建spring-mvc.xml&lt;?xmlversion=&quot;1.0&quot;encoding=&quot;UTF-8&quot;?&gt;&lt;beansxmlns=&quot;http://www.springframework.org/schema/beans&quot;xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;xmlns:context=&quot;http://www.springframework.org/schema/context&quot;xmlns:mvc=&quot;http://www.springframework.org/schema/mvc&quot;xsi:schemaLocation=&quot;http://www.springframework.org/schema/beanshttp://www.springframework.org/schema/beans/spring-beans.xsdhttp://www.springframework.org/schema/mvchttp://www.springframework.org/schema/mvc/spring-mvc.xsdhttp://www.springframework.org/schema/contexthttp://www.springframework.org/schema/context/spring-context.xsd&quot;&gt;&lt;!--扫描用@Controller注解的类，并且加载到spring中进行管理--&gt;&lt;context:component-scanbase-package=&quot;com.cn.controller&quot;/&gt;&lt;!--配置注解驱动--&gt;&lt;mvc:annotation-driven&gt;&lt;!--添加转换器，添加对于对象的支持--&gt;&lt;mvc:message-converters&gt;&lt;refbean=&quot;stringHttpMessageConverter&quot;/&gt;&lt;refbean=&quot;mappingJackson2HttpMessageConverter&quot;/&gt;&lt;/mvc:message-converters&gt;&lt;/mvc:annotation-driven&gt;&lt;beanid=&quot;stringHttpMessageConverter&quot;class=&quot;org.springframework.http.converter.StringHttpMessageConverter&quot;/&gt;&lt;!--解决IE浏览器json文件下载和json数据中午乱码的问题--&gt;&lt;beanid=&quot;mappingJackson2HttpMessageConverter&quot;class=&quot;org.springframework.http.converter.json.MappingJackson2HttpMessageConverter&quot;&gt;&lt;propertyname=&quot;supportedMediaTypes&quot;&gt;&lt;list&gt;&lt;value&gt;text/html;charset=UTF-8&lt;/value&gt;&lt;/list&gt;&lt;/property&gt;&lt;/bean&gt;&lt;mvc:default-servlet-handler/&gt;&lt;!--jackson--&gt;&lt;mvc:annotation-driven&gt;&lt;mvc:message-converters&gt;&lt;beanclass=&quot;org.springframework.http.converter.StringHttpMessageConverter&quot;/&gt;&lt;beanclass=&quot;org.springframework.http.converter.json.MappingJackson2HttpMessageConverter&quot;/&gt;&lt;/mvc:message-converters&gt;&lt;/mvc:annotation-driven&gt;&lt;/beans&gt;4、创建spring-security.xml&lt;?xmlversion=&quot;1.0&quot;encoding=&quot;UTF-8&quot;?&gt;&lt;beans:beansxmlns=&quot;http://www.springframework.org/schema/security&quot;xmlns:beans=&quot;http://www.springframework.org/schema/beans&quot;xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;xsi:schemaLocation=&quot;http://www.springframework.org/schema/beanshttp://www.springframework.org/schema/beans/spring-beans.xsdhttp://www.springframework.org/schema/securityhttp://www.springframework.org/schema/security/spring-security.xsd&quot;&gt;&lt;!--entry-point-ref入口点引用--&gt;&lt;httpuse-expressions=&quot;false&quot;entry-point-ref=&quot;casProcessingFilterEntryPoint&quot;&gt;&lt;intercept-urlpattern=&quot;/**&quot;access=&quot;ROLE_USER&quot;/&gt;&lt;csrfdisabled=&quot;true&quot;/&gt;&lt;!--custom-filter为过滤器，position表示将过滤器放在指定的位置上(参照位置表)，before表示放在指定位置之前，after表示放在指定的位置之后--&gt;&lt;custom-filterref=&quot;casAuthenticationFilter&quot;position=&quot;CAS_FILTER&quot;/&gt;&lt;custom-filterref=&quot;requestSingleLogoutFilter&quot;before=&quot;LOGOUT_FILTER&quot;/&gt;&lt;custom-filterref=&quot;singleLogoutFilter&quot;before=&quot;CAS_FILTER&quot;/&gt;&lt;/http&gt;&lt;!--CAS入口点开始--&gt;&lt;beans:beanid=&quot;casProcessingFilterEntryPoint&quot;class=&quot;org.springframework.security.cas.web.CasAuthenticationEntryPoint&quot;&gt;&lt;!--单点登录服务器登录URL--&gt;&lt;beans:propertyname=&quot;loginUrl&quot;value=&quot;http://localhost:9100/cas/login&quot;/&gt;&lt;beans:propertyname=&quot;serviceProperties&quot;ref=&quot;serviceProperties&quot;/&gt;&lt;/beans:bean&gt;&lt;beans:beanid=&quot;serviceProperties&quot;class=&quot;org.springframework.security.cas.ServiceProperties&quot;&gt;&lt;!--service配置自身工程的根地址+/login/cas--&gt;&lt;beans:propertyname=&quot;service&quot;value=&quot;http://localhost:9003/login/cas&quot;/&gt;&lt;/beans:bean&gt;&lt;!--CAS入口点结束--&gt;&lt;!--认证过滤器开始--&gt;&lt;beans:beanid=&quot;casAuthenticationFilter&quot;class=&quot;org.springframework.security.cas.web.CasAuthenticationFilter&quot;&gt;&lt;beans:propertyname=&quot;authenticationManager&quot;ref=&quot;authenticationManager&quot;/&gt;&lt;/beans:bean&gt;&lt;!--认证管理器--&gt;&lt;authentication-manageralias=&quot;authenticationManager&quot;&gt;&lt;authentication-providerref=&quot;casAuthenticationProvider&quot;&gt;&lt;/authentication-provider&gt;&lt;/authentication-manager&gt;&lt;!--认证提供者--&gt;&lt;beans:beanid=&quot;casAuthenticationProvider&quot;class=&quot;org.springframework.security.cas.authentication.CasAuthenticationProvider&quot;&gt;&lt;beans:propertyname=&quot;authenticationUserDetailsService&quot;&gt;&lt;beans:beanclass=&quot;org.springframework.security.core.userdetails.UserDetailsByNameServiceWrapper&quot;&gt;&lt;beans:constructor-argref=&quot;userDetailsService&quot;/&gt;&lt;/beans:bean&gt;&lt;/beans:property&gt;&lt;beans:propertyname=&quot;serviceProperties&quot;ref=&quot;serviceProperties&quot;/&gt;&lt;!--ticketValidator为票据验证器--&gt;&lt;beans:propertyname=&quot;ticketValidator&quot;&gt;&lt;beans:beanclass=&quot;org.jasig.cas.client.validation.Cas20ServiceTicketValidator&quot;&gt;&lt;beans:constructor-argindex=&quot;0&quot;value=&quot;http://localhost:9100/cas&quot;/&gt;&lt;/beans:bean&gt;&lt;/beans:property&gt;&lt;beans:propertyname=&quot;key&quot;value=&quot;an_id_for_this_auth_provider_only&quot;/&gt;&lt;/beans:bean&gt;&lt;!--认证类--&gt;&lt;beans:beanid=&quot;userDetailsService&quot;class=&quot;com.cn.service.impl.UserDetailServiceImpl&quot;/&gt;&lt;!--认证过滤器结束--&gt;&lt;!--单点登出开始--&gt;&lt;beans:beanid=&quot;singleLogoutFilter&quot;class=&quot;org.jasig.cas.client.session.SingleSignOutFilter&quot;/&gt;&lt;beans:beanid=&quot;requestSingleLogoutFilter&quot;class=&quot;org.springframework.security.web.authentication.logout.LogoutFilter&quot;&gt;&lt;beans:constructor-argvalue=&quot;http://localhost:9100/cas/logout?service=http://www.baidu.com&quot;/&gt;&lt;beans:constructor-arg&gt;&lt;beans:beanclass=&quot;org.springframework.security.web.authentication.logout.SecurityContextLogoutHandler&quot;/&gt;&lt;/beans:constructor-arg&gt;&lt;beans:propertyname=&quot;filterProcessesUrl&quot;value=&quot;/logout/cas&quot;/&gt;&lt;/beans:bean&gt;&lt;!--单点登出结束--&gt;&lt;/beans:beans&gt;5、创建认证类publicclassUserDetailServiceImplimplementsUserDetailsService{@OverridepublicUserDetailsloadUserByUsername(Stringusername)throwsUsernameNotFoundException{//构建角色集合List&lt;GrantedAuthority&gt;authorities=newArrayList();authorities.add(newSimpleGrantedAuthority(&quot;ROLE_USER&quot;));returnnewUser(username,&quot;&quot;,authorities);}}6、修改web.xml,添加过滤器等配置&lt;?xmlversion=&quot;1.0&quot;encoding=&quot;UTF-8&quot;?&gt;&lt;web-appxmlns=&quot;http://xmlns.jcp.org/xml/ns/javaee&quot;xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;xsi:schemaLocation=&quot;http://xmlns.jcp.org/xml/ns/javaeehttp://xmlns.jcp.org/xml/ns/javaee/web-app_4_0.xsd&quot;version=&quot;4.0&quot;&gt;&lt;context-param&gt;&lt;param-name&gt;contextConfigLocation&lt;/param-name&gt;&lt;param-value&gt;classpath:spring-security.xml&lt;/param-value&gt;&lt;/context-param&gt;&lt;listener&gt;&lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt;&lt;/listener&gt;&lt;filter&gt;&lt;filter-name&gt;springSecurityFilterChain&lt;/filter-name&gt;&lt;filter-class&gt;org.springframework.web.filter.DelegatingFilterProxy&lt;/filter-class&gt;&lt;/filter&gt;&lt;filter-mapping&gt;&lt;filter-name&gt;springSecurityFilterChain&lt;/filter-name&gt;&lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt;&lt;!--------------------------------------------------------------------------------&gt;&lt;!--解决post乱码--&gt;&lt;filter&gt;&lt;filter-name&gt;CharacterEncodingFilter&lt;/filter-name&gt;&lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt;&lt;init-param&gt;&lt;param-name&gt;encoding&lt;/param-name&gt;&lt;param-value&gt;utf-8&lt;/param-value&gt;&lt;/init-param&gt;&lt;init-param&gt;&lt;param-name&gt;forceEncoding&lt;/param-name&gt;&lt;param-value&gt;true&lt;/param-value&gt;&lt;/init-param&gt;&lt;/filter&gt;&lt;filter-mapping&gt;&lt;filter-name&gt;CharacterEncodingFilter&lt;/filter-name&gt;&lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt;&lt;servlet&gt;&lt;servlet-name&gt;springmvc&lt;/servlet-name&gt;&lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt;&lt;!--指定加载的配置文件，通过参数contextConfigLocation加载--&gt;&lt;init-param&gt;&lt;param-name&gt;contextConfigLocation&lt;/param-name&gt;&lt;param-value&gt;classpath:spring-mvc.xml&lt;/param-value&gt;&lt;/init-param&gt;&lt;load-on-startup&gt;1&lt;/load-on-startup&gt;&lt;/servlet&gt;&lt;servlet-mapping&gt;&lt;servlet-name&gt;springmvc&lt;/servlet-name&gt;&lt;url-pattern&gt;/&lt;/url-pattern&gt;&lt;/servlet-mapping&gt;&lt;/web-app&gt;7、创建UserController@RestControllerpublicclassUserController{@RequestMapping(&quot;/findLoginUser&quot;)publicvoidfindLoginUser(){Stringname=SecurityContextHolder.getContext().getAuthentication().getName();System.out.println(name);}}8、退出登陆修改spring-security.xmlhttp://localhost:9100/cas/logout?service=http://www.baidu.comservice等于登出后跳转的地址&lt;!--单点登出开始--&gt;&lt;beans:beanid=&quot;singleLogoutFilter&quot;class=&quot;org.jasig.cas.client.session.SingleSignOutFilter&quot;/&gt;&lt;beans:beanid=&quot;requestSingleLogoutFilter&quot;class=&quot;org.springframework.security.web.authentication.logout.LogoutFilter&quot;&gt;&lt;beans:constructor-argvalue=&quot;http://localhost:9100/cas/logout?service=http://www.baidu.com&quot;/&gt;&lt;beans:constructor-arg&gt;&lt;beans:beanclass=&quot;org.springframework.security.web.authentication.logout.SecurityContextLogoutHandler&quot;/&gt;&lt;/beans:constructor-arg&gt;&lt;beans:propertyname=&quot;filterProcessesUrl&quot;value=&quot;/logout/cas&quot;/&gt;&lt;/beans:bean&gt;&lt;!--单点登出结束--&gt;在页面上添加&lt;ahref=&quot;/logout/cas&quot;&gt;退出登录&lt;/a&gt;","link":"https://haohanya.github.io/post/dan-dian-deng-lu-cas/"},{"title":"Redis","content":"redis安装安装gccyuminstallgcc-c++解压源码tar-zxvfredis-3.0.0.tar.gz进入解压后的目录进行编译cd/usr/local/redis-3.0.0makePREFIX=/usr/local/redisinstall拷贝配置文件到安装目录下cd/usr/local/redismkdirconfcp/usr/local/redis-3.0.0/redis.conf/usr/local/redis/bin运行bin/redis-server后端模式运行修改redis.conf文件:daemonizeyes./bin/redis-serverredis.confSpringDataRedis简介Redisredis是一款开源的Key-Value数据库，运行在内存中，由ANSIC编写。企业开发通常采用Redis来实现缓存。同类的产品还有memcache、MongoDB等。JedisJedis是Redis官方推出的一款面向Java的客户端，提供了很多接口供Java语言调用。可以在Redis官网下载，当然还有一些开源爱好者提供的客户端，如Jredis、SRP等等，推荐使用Jedis。SpringDataRedisSpring-data-redis是spring大家族的一部分，提供了在srping应用中通过简单的配置访问redis服务，对reids底层开发包(Jedis,JRedis,andRJC)进行了高度封装，RedisTemplate提供了redis各种操作、异常处理及序列化，支持发布订阅，并对spring3.1cache进行了实现。spring-data-redis针对jedis提供了如下功能：1、连接池自动管理，提供了一个高度封装的“RedisTemplate”类​2、针对jedis客户端中大量api进行了归类封装,将同一类型操作封装为operation接口​ValueOperations：简单K-V操作​SetOperations：set类型数据操作​ZSetOperations：zset类型数据操作​HashOperations：针对map类型的数据操作​ListOperations：针对list类型的数据操作SpringDataRedis入门小Demo1、引入依赖&lt;!--缓存--&gt;&lt;dependency&gt;&lt;groupId&gt;redis.clients&lt;/groupId&gt;&lt;artifactId&gt;jedis&lt;/artifactId&gt;&lt;version&gt;2.8.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;&lt;groupId&gt;org.springframework.data&lt;/groupId&gt;&lt;artifactId&gt;spring-data-redis&lt;/artifactId&gt;&lt;version&gt;1.7.2.RELEASE&lt;/version&gt;&lt;/dependency&gt;2、创建redis-config.propertiesredis.host=127.0.0.1redis.port=6379redis.pass=redis.database=0redis.maxIdle=300redis.maxWait=3000redis.testOnBorrow=true3、编写redis配置文件applicationContext-redis.xml&lt;context:property-placeholderlocation=&quot;classpath*:properties/*.properties&quot;/&gt;&lt;!--redis相关配置--&gt;&lt;beanid=&quot;poolConfig&quot;class=&quot;redis.clients.jedis.JedisPoolConfig&quot;&gt;&lt;propertyname=&quot;maxIdle&quot;value=&quot;${redis.maxIdle}&quot;/&gt;&lt;propertyname=&quot;maxWaitMillis&quot;value=&quot;${redis.maxWait}&quot;/&gt;&lt;propertyname=&quot;testOnBorrow&quot;value=&quot;${redis.testOnBorrow}&quot;/&gt;&lt;/bean&gt;&lt;beanid=&quot;JedisConnectionFactory&quot;class=&quot;org.springframework.data.redis.connection.jedis.JedisConnectionFactory&quot;p:host-name=&quot;${redis.host}&quot;p:port=&quot;${redis.port}&quot;p:password=&quot;${redis.pass}&quot;p:pool-config-ref=&quot;poolConfig&quot;/&gt;&lt;beanid=&quot;redisTemplate&quot;class=&quot;org.springframework.data.redis.core.RedisTemplate&quot;&gt;&lt;propertyname=&quot;connectionFactory&quot;ref=&quot;JedisConnectionFactory&quot;/&gt;&lt;/bean&gt;maxIdle：最大空闲数maxWaitMillis:连接时的最大等待毫秒数testOnBorrow：在提取一个jedis实例时，是否提前进行验证操作；如果为true，则得到的jedis实例均是可用的；4、值类型操作@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations=&quot;classpath:spring/applicationContext-redis.xml&quot;)publicclassTestValue{@AutowiredprivateRedisTemplateredisTemplate;@TestpublicvoidsetValue(){redisTemplate.boundValueOps(&quot;name&quot;).set(&quot;zhangsan&quot;);}@TestpublicvoidgetValue(){Stringstr=(String)redisTemplate.boundValueOps(&quot;name&quot;).get();System.out.println(str);}@TestpublicvoiddeleteValue(){redisTemplate.delete(&quot;name&quot;);;}}5、Set类型操作@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations=&quot;classpath:spring/applicationContext-redis.xml&quot;)publicclassTestSet{@AutowiredprivateRedisTemplateredisTemplate;/***存入值*/@TestpublicvoidsetValue(){redisTemplate.boundSetOps(&quot;nameset&quot;).add(&quot;罗志祥&quot;);redisTemplate.boundSetOps(&quot;nameset&quot;).add(&quot;周扬青&quot;);redisTemplate.boundSetOps(&quot;nameset&quot;).add(&quot;蝴蝶姐&quot;);}/***提取值*/@TestpublicvoidgetValue(){Setmembers=redisTemplate.boundSetOps(&quot;nameset&quot;).members();System.out.println(members);}/***删除集合中的某一个值*/@TestpublicvoiddeleteValue(){redisTemplate.boundSetOps(&quot;nameset&quot;).remove(&quot;蝴蝶姐&quot;);}/***删除整个集合*/@TestpublicvoiddeleteAllValue(){redisTemplate.delete(&quot;nameset&quot;);}}6、List类型操作6.1、右压栈/***右压栈：后添加的对象排在后边*/@TestpublicvoidtestSetValue1(){redisTemplate.boundListOps(&quot;namelist1&quot;).rightPush(&quot;刘备&quot;);redisTemplate.boundListOps(&quot;namelist1&quot;).rightPush(&quot;关羽&quot;);redisTemplate.boundListOps(&quot;namelist1&quot;).rightPush(&quot;张飞&quot;);}/***显示右压栈集合*/@TestpublicvoidtestGetValue1(){Listlist=redisTemplate.boundListOps(&quot;namelist1&quot;).range(0,10);System.out.println(list);}//运行结果：[刘备,关羽,张飞]6.2、左压栈/***左压栈：后添加的对象排在前边*/@TestpublicvoidtestSetValue2(){redisTemplate.boundListOps(&quot;namelist2&quot;).leftPush(&quot;刘备&quot;);redisTemplate.boundListOps(&quot;namelist2&quot;).leftPush(&quot;关羽&quot;);redisTemplate.boundListOps(&quot;namelist2&quot;).leftPush(&quot;张飞&quot;);}/***显示左压栈集合*/@TestpublicvoidtestGetValue2(){Listlist=redisTemplate.boundListOps(&quot;namelist2&quot;).range(0,10);System.out.println(list);}//运行结果：[张飞,关羽,刘备]6.3、根据索引查询元素/***查询集合某个元素*/@TestpublicvoidtestSearchByIndex(){Strings=(String)redisTemplate.boundListOps(&quot;namelist1&quot;).index(1);System.out.println(s);}6.4、移除某个元素的值/***移除集合某个元素*/@TestpublicvoidtestRemoveByIndex(){redisTemplate.boundListOps(&quot;namelist1&quot;).remove(1,&quot;关羽&quot;);}7、Hash类型操作7.1、存入值@TestpublicvoidtestSetValue(){redisTemplate.boundHashOps(&quot;namehash&quot;).put(&quot;a&quot;,&quot;唐僧&quot;);redisTemplate.boundHashOps(&quot;namehash&quot;).put(&quot;b&quot;,&quot;悟空&quot;);redisTemplate.boundHashOps(&quot;namehash&quot;).put(&quot;c&quot;,&quot;八戒&quot;);redisTemplate.boundHashOps(&quot;namehash&quot;).put(&quot;d&quot;,&quot;沙僧&quot;);}7.2、提取所有的KEY@TestpublicvoidtestGetKeys(){Sets=redisTemplate.boundHashOps(&quot;namehash&quot;).keys();System.out.println(s);}//运行结果：[a,b,c,d]7.3、提取所有的值@TestpublicvoidtestGetValues(){Listvalues=redisTemplate.boundHashOps(&quot;namehash&quot;).values();System.out.println(values);}//运行结果：[唐僧,悟空,八戒,沙僧]7.4、根据KEY提取值@TestpublicvoidtestGetValueByKey(){Objectobject=redisTemplate.boundHashOps(&quot;namehash&quot;).get(&quot;b&quot;);System.out.println(object);}//运行结果：悟空7.5、根据KEY移除值@TestpublicvoidtestRemoveValueByKey(){redisTemplate.boundHashOps(&quot;namehash&quot;).delete(&quot;c&quot;);}//运行结果：[唐僧,悟空,沙僧]","link":"https://haohanya.github.io/post/redis/"},{"title":"ActiveMQ","content":"什么是jmsJMS（javaMessagingService）是Java平台上有关面向消息中间件的技术规范，它便于消息系统中的Java应用程序进行消息交换,并且通过提供标准的产生、发送、接收消息的接口简化企业应用的开发。​JMS本身只定义了一系列的接口规范，是一种与厂商无关的API，用来访问消息收发系统。它类似于JDBC(javaDatabaseConnectivity)：这里，JDBC是可以用来访问许多不同关系数据库的API，而JMS则提供同样与厂商无关的访问方法，以访问消息收发服务。许多厂商目前都支持JMS，包括IBM的MQSeries、BEA的WeblogicJMSservice和Progress的SonicMQ，这只是几个例子。JMS使您能够通过消息收发服务（有时称为消息中介程序或路由器）从一个JMS客户机向另一个JML客户机发送消息。消息是JMS中的一种类型对象，由两部分组成：报头和消息主体。报头由路由信息以及有关该消息的元数据组成。消息主体则携带着应用程序的数据或有效负载。JMS定义了五种不同的消息正文格式，以及调用的消息类型，允许你发送并接收以一些不同形式的数据，提供现有消息格式的一些级别的兼容性。TextMessage--一个字符串对象（应用最广泛的一种）MapMessage--一套名称-值对ObjectMessage--一个序列化的Java对象BytesMessage--一个字节的数据流StreamMessage--Java原始值的数据流JMS消息传递类型对于消息的传递有两种类型：一种是点对点的，即一个生产者和一个消费者一一对应；另一种是发布/订阅模式，即一个生产者产生消息并进行发送后，可以由多个消费者进行接收。安装1、上传activeMQ到服务器2、解压tar-zxvfapache-activemq-5.12.0-bin.tar.gz3、移动文件mvapache-activemq-5.12.0/usr/local/java/activemq-5.12.04、进入bincd/usr/local/java/activemq-5.12.0/bin5、启动activeMQ./activemqstart6、访问：ip:8161账号：admin密码：adminJMS测试点对点模式1、引入依赖&lt;dependencies&gt;&lt;dependency&gt;&lt;groupId&gt;org.apache.activemq&lt;/groupId&gt;&lt;artifactId&gt;activemq-client&lt;/artifactId&gt;&lt;version&gt;5.13.4&lt;/version&gt;&lt;/dependency&gt;&lt;/dependencies&gt;2、创建消息生产者QueueProducerpublicstaticvoidmain(String[]args)throwsJMSException{//1、创建工厂ConnectionFactoryconnectionFactory=newActiveMQConnectionFactory(&quot;tcp://192.168.25.135:61616&quot;);//2、获取连接Connectionconnection=connectionFactory.createConnection();//3、启动连接connection.start();/**4、获取session参数1：是否启用事务参数2：消息确认模式AUTO_ACKNOWLEDGE=1自动确认CLIENT_ACKNOWLEDGE=2客户端手动确认DUPS_OK_ACKNOWLEDGE=3自动批量确认SESSION_TRANSACTED=0事务提交并确认*/Sessionsession=connection.createSession(false,Session.AUTO_ACKNOWLEDGE);//5、创建队列对象Queuequeue=session.createQueue(&quot;test-queue&quot;);//6、创建消息生产着MessageProducermessageProducer=session.createProducer(queue);//7、创建消息TextMessagetextMessage=session.createTextMessage(&quot;测试文本内容&quot;);//8、发送消息messageProducer.send(textMessage);//9、关闭资源messageProducer.close();session.close();connection.close();}3、创建消息消费者QueueConsumerpublicstaticvoidmain(String[]args)throwsJMSException,IOException{//1、创建连接工厂ConnectionFactoryconnectionFactory=newActiveMQConnectionFactory(&quot;tcp://192.168.25.135:61616&quot;);//2、获取连接Connectionconnection=connectionFactory.createConnection();//3、启动连接connection.start();//4、获取sessionSessionsession=connection.createSession(false,Session.AUTO_ACKNOWLEDGE);//5、创建队列对象Queuequeue=session.createQueue(&quot;test-queue&quot;);//6、创建消息消费MessageConsumerconsumer=session.createConsumer(queue);//7、监听消息consumer.setMessageListener(newMessageListener(){@OverridepublicvoidonMessage(Messagemessage){TextMessagetextMessage=(TextMessage)message;try{System.out.println(&quot;接收消息为：&quot;+textMessage.getText());}catch(JMSExceptione){e.printStackTrace();}}});//8、等待键盘输入System.in.read();//9、关闭资源consumer.close();session.close();connection.close();}发布/订阅模式1、消息生产者TopicProducerpublicstaticvoidmain(String[]args)throwsJMSException,IOException{//1、创建连接工厂ConnectionFactoryconnectionFactory=newActiveMQConnectionFactory(&quot;tcp://192.168.25.135:61616&quot;);//2、获取连接Connectionconnection=connectionFactory.createConnection();//3、启动连接connection.start();//4、获取sessionSessionsession=connection.createSession(false,Session.AUTO_ACKNOWLEDGE);//5、创建主题对象Topictopic=session.createTopic(&quot;test-topic&quot;);//6、创建消息消费者MessageConsumerconsumer=session.createConsumer(topic);//7、监听消息consumer.setMessageListener(newMessageListener(){@OverridepublicvoidonMessage(Messagemessage){TextMessagetextMessage=(TextMessage)message;try{System.out.println(&quot;接收消息：&quot;+textMessage.getText());}catch(JMSExceptione){e.printStackTrace();}}});//8、等待键盘输入System.in.read();//9、关闭资源consumer.close();session.close();connection.close();}2、消息消费者TopicProducerpublicstaticvoidmain(String[]args)throwsJMSException{//1、创建连接工厂ConnectionFactoryconnectionFactory=newActiveMQConnectionFactory(&quot;tcp://192.168.25.135:61616&quot;);//2、获取连接Connectionconnection=connectionFactory.createConnection();//3、启动连接connection.start();//4、获取sessionSessionsession=connection.createSession(false,Session.AUTO_ACKNOWLEDGE);//5、创建主题对象Topictopic=session.createTopic(&quot;test-topic&quot;);//6、创建消息生产者MessageProducerproducer=session.createProducer(topic);//7、创建消息TextMessagetopicTest=session.createTextMessage(&quot;topicTest&quot;);//8、发送消息producer.send(topicTest);//9、关闭资源producer.close();session.close();connection.close();}spring整合jms点对点模式1、引入依赖&lt;!--spring-jms--&gt;&lt;dependency&gt;&lt;groupId&gt;org.springframework&lt;/groupId&gt;&lt;artifactId&gt;spring-jms&lt;/artifactId&gt;&lt;version&gt;4.2.4.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;!--activemq--&gt;&lt;dependency&gt;&lt;groupId&gt;org.apache.activemq&lt;/groupId&gt;&lt;artifactId&gt;activemq-all&lt;/artifactId&gt;&lt;version&gt;5.11.2&lt;/version&gt;&lt;/dependency&gt;&lt;!--单元测试--&gt;&lt;!--springJunit--&gt;&lt;dependency&gt;&lt;groupId&gt;org.springframework&lt;/groupId&gt;&lt;artifactId&gt;spring-test&lt;/artifactId&gt;&lt;version&gt;4.2.4.RELEASE&lt;/version&gt;&lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt;&lt;groupId&gt;junit&lt;/groupId&gt;&lt;artifactId&gt;junit&lt;/artifactId&gt;&lt;version&gt;4.12&lt;/version&gt;&lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt;2、创建生产者配置文件applicationContext-jms-producer-queue.xml&lt;?xmlversion=&quot;1.0&quot;encoding=&quot;UTF-8&quot;?&gt;&lt;beansxmlns=&quot;http://www.springframework.org/schema/beans&quot;xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;xmlns:context=&quot;http://www.springframework.org/schema/context&quot;xsi:schemaLocation=&quot;http://www.springframework.org/schema/beanshttp://www.springframework.org/schema/beans/spring-beans.xsdhttp://www.springframework.org/schema/contexthttp://www.springframework.org/schema/context/spring-context.xsd&quot;&gt;&lt;!--消息生产者:点对点--&gt;&lt;context:component-scanbase-package=&quot;com.springjms&quot;/&gt;&lt;!--jms服务厂商提供的连接工厂--&gt;&lt;beanid=&quot;targetConnectionFactory&quot;class=&quot;org.apache.activemq.ActiveMQConnectionFactory&quot;&gt;&lt;propertyname=&quot;brokerURL&quot;value=&quot;tcp://192.168.25.137:61616&quot;/&gt;&lt;/bean&gt;&lt;!--spring用于管理真正的ConnectionFactory--&gt;&lt;beanid=&quot;connectionFactory&quot;class=&quot;org.springframework.jms.connection.SingleConnectionFactory&quot;&gt;&lt;propertyname=&quot;targetConnectionFactory&quot;ref=&quot;targetConnectionFactory&quot;/&gt;&lt;/bean&gt;&lt;!--spring提供的工具类--&gt;&lt;beanid=&quot;jmsTemplate&quot;class=&quot;org.springframework.jms.core.JmsTemplate&quot;&gt;&lt;constructor-argname=&quot;connectionFactory&quot;ref=&quot;connectionFactory&quot;/&gt;&lt;/bean&gt;&lt;!--queue--&gt;&lt;beanid=&quot;queueTextDestination&quot;class=&quot;org.apache.activemq.command.ActiveMQQueue&quot;&gt;&lt;constructor-argname=&quot;name&quot;value=&quot;queue_text&quot;/&gt;&lt;/bean&gt;&lt;/beans&gt;3、发送消息@ComponentpublicclassQueueProducer{@ResourceprivateJmsTemplatejmsTemplate;@ResourceprivateDestinationqueueTextDestination;/***发送文本消息*@paramtext发送的文本内容*/publicvoidsendTextMessage(finalStringtext){jmsTemplate.send(queueTextDestination,newMessageCreator(){@OverridepublicMessagecreateMessage(Sessionsession)throwsJMSException{returnsession.createTextMessage(text);}});}}4、测试发送消息@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations=&quot;classpath:applicationContext-jms-producer-queue.xml&quot;)publicclassMyTest{@ResourceprivateQueueProducerqueueProducer;@Testpublicvoidtest(){queueProducer.sendTextMessage(&quot;Hello!queue&quot;);}}5、创建消费者配置文件applicationContext-jms-consumer-queue.xml&lt;?xmlversion=&quot;1.0&quot;encoding=&quot;UTF-8&quot;?&gt;&lt;beansxmlns=&quot;http://www.springframework.org/schema/beans&quot;xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;xsi:schemaLocation=&quot;http://www.springframework.org/schema/beanshttp://www.springframework.org/schema/beans/spring-beans.xsd&quot;&gt;&lt;!--服务消费者:点对点--&gt;&lt;!--jsm服务厂商提供的连接工厂--&gt;&lt;beanid=&quot;targetConnectionFactory&quot;class=&quot;org.apache.activemq.ActiveMQConnectionFactory&quot;&gt;&lt;propertyname=&quot;brokerURL&quot;value=&quot;tcp://192.168.25.137:61616&quot;/&gt;&lt;/bean&gt;&lt;!--spring用于管理真正的ConnectionFactory--&gt;&lt;beanid=&quot;connectionFactory&quot;class=&quot;org.springframework.jms.connection.SingleConnectionFactory&quot;&gt;&lt;propertyname=&quot;targetConnectionFactory&quot;ref=&quot;targetConnectionFactory&quot;/&gt;&lt;/bean&gt;&lt;!--spring提供的工具类--&gt;&lt;beanid=&quot;jmsTemplate&quot;class=&quot;org.springframework.jms.core.JmsTemplate&quot;&gt;&lt;constructor-argname=&quot;connectionFactory&quot;ref=&quot;connectionFactory&quot;/&gt;&lt;/bean&gt;&lt;!--queue--&gt;&lt;beanid=&quot;queueTextDestination&quot;class=&quot;org.apache.activemq.command.ActiveMQQueue&quot;&gt;&lt;constructor-argname=&quot;name&quot;value=&quot;queue_text&quot;/&gt;&lt;/bean&gt;&lt;!--监听类,用来监听mq中是否有消息--&gt;&lt;beanid=&quot;myMessageListener&quot;class=&quot;com.springjms.MyMessageListener&quot;/&gt;&lt;!--消息的监听器--&gt;&lt;beanclass=&quot;org.springframework.jms.listener.DefaultMessageListenerContainer&quot;&gt;&lt;propertyname=&quot;connectionFactory&quot;ref=&quot;connectionFactory&quot;/&gt;&lt;propertyname=&quot;destination&quot;ref=&quot;queueTextDestination&quot;/&gt;&lt;propertyname=&quot;messageListener&quot;ref=&quot;myMessageListener&quot;/&gt;&lt;/bean&gt;&lt;/beans&gt;6、编写监听类publicclassMyMessageListenerimplementsMessageListener{@OverridepublicvoidonMessage(Messagemessage){TextMessagetextMessage=(TextMessage)message;try{System.out.println(&quot;接收到消息：&quot;+textMessage.getText());}catch(JMSExceptione){e.printStackTrace();}}}7、测试@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations=&quot;classpath:applicationContext-jms-consumer-queue.xml&quot;)publicclassMyTest1{@TestpublicvoidtestQueue(){try{System.in.read();}catch(IOExceptione){e.printStackTrace();}}}发布/订阅模式1、创建生产者，在applicationContext-jms-producer-queue.xml新增内容&lt;!--这个是订阅模式文本信息--&gt;&lt;beanid=&quot;topicTextDestination&quot;class=&quot;org.apache.activemq.command.ActiveMQTopic&quot;&gt;&lt;constructor-argvalue=&quot;topic_text&quot;/&gt;&lt;/bean&gt;2、发送消息@ComponentpublicclassTopicProducer{@ResourceprivateJmsTemplatejmsTemplate;@ResourceprivateDestinationtopicTextDestination;/***发送消息*@paramtext*/publicvoidsendMessage(finalStringtext){jmsTemplate.send(topicTextDestination,newMessageCreator(){@OverridepublicMessagecreateMessage(Sessionsession)throwsJMSException{returnsession.createTextMessage(text);}});}}3、测试@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations=&quot;classpath:applicationContext-jms-producer-topic.xml&quot;)publicclassMyTest2{@ResourceprivateTopicProducertopicProducer;@Testpublicvoidtest(){topicProducer.sendMessage(&quot;Hello!topic&quot;);}}4、创建消费者，在applicationContext-jms-consumer-queue.xml新增内容&lt;!--topic--&gt;&lt;beanid=&quot;topicTextDestination&quot;class=&quot;org.apache.activemq.command.ActiveMQTopic&quot;&gt;&lt;constructor-argname=&quot;name&quot;value=&quot;topic_text&quot;/&gt;&lt;/bean&gt;&lt;!--监听类,用来监听mq中是否有消息--&gt;&lt;beanid=&quot;topicMessageListener&quot;class=&quot;com.springjms.TopicMessageListener&quot;/&gt;&lt;!--消息的监听器--&gt;&lt;beanclass=&quot;org.springframework.jms.listener.DefaultMessageListenerContainer&quot;&gt;&lt;propertyname=&quot;connectionFactory&quot;ref=&quot;connectionFactory&quot;/&gt;&lt;propertyname=&quot;destination&quot;ref=&quot;topicTextDestination&quot;/&gt;&lt;propertyname=&quot;messageListener&quot;ref=&quot;topicMessageListener&quot;/&gt;&lt;/bean&gt;5、编写监听类publicclassTopicMessageListenerimplementsMessageListener{@OverridepublicvoidonMessage(Messagemessage){TextMessagetextMessage=(TextMessage)message;try{System.out.println(&quot;接收到消息：&quot;+textMessage.getText());}catch(JMSExceptione){e.printStackTrace();}}}6、编写测试类@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations=&quot;classpath:applicationContext-jms-consumer-topic.xml&quot;)publicclassMyTest3{@TestpublicvoidtestQueue(){try{System.in.read();}catch(IOExceptione){e.printStackTrace();}}}","link":"https://haohanya.github.io/post/activemq/"},{"title":"solr安装使用","content":"什么是Solr大多数搜索引擎应用都必须具有某种搜索功能，问题是搜索功能往往是巨大的资源消耗并且它们由于沉重的数据库加载而拖垮你的应用的性能。这就是为什么转移负载到一个外部的搜索服务器是一个不错的主意，ApacheSolr是一个流行的开源搜索服务器，它通过使用类似REST的HTTPAPI，这就确保你能从几乎任何编程语言来使用solr。Solr是一个开源搜索平台，用于构建搜索应用程序。它建立在Lucene(全文搜索引擎)之上。Solr是企业级的，快速的和高度可扩展的。使用Solr构建的应用程序非常复杂，可提供高性能。为了在CNET网络的公司网站上添加搜索功能，YonikSeely于2004年创建了Solr。并在2006年1月，它成为Apache软件基金会下的一个开源项目。并于2016年发布最新版本Solr6.0，支持并行SQL查询的执行。Solr可以和Hadoop一起使用。由于Hadoop处理大量数据，Solr帮助我们从这么大的源中找到所需的信息。不仅限于搜索，Solr也可以用于存储目的。像其他NoSQL数据库一样，它是一种非关系数据存储和处理技术。总之，Solr是一个可扩展的，可部署，搜索/存储引擎，优化搜索大量以文本为中心的数据。solr安装1上传文件apache-tomcat-7.0.82.tar.gzsolr-4.10.3.tgz.tgzIKAnalyzer2012FF_hf12创建目录mkdir/usr/soft/solr3解压tomcat并移动到solr目录tar-zxvfapache-tomcat-7.0.82.tar.gzmvapache-tomcat-7.0.82/usr/soft/solr/tomcat7tar-zxvfsolr-4.10.3.tgz.tgz在solr-4.10.3/dist目录下有一个war包需要把war包移动到tomcat里运行cp~/solr-4.10.3/dist/solr-4.10.3.war/usr/soft/solr/tomcat7/webapps/solr.war4启动tomcatcd/usr/soft/solr/tomcat7./bin/startup.sh查看tomcat日志(可选)tail-flogs/catalina.out5引入依赖jar包cd~/solr-4.10.3/example/lib/extcp*/usr/soft/solr/tomcat7/webapps/solr/WEB-INF/lib6复制配置文件cd~/solr-4.10.3/examplecp-rsolr/usr/soft/solr/solrhome7solr和solrhome建立联系cd/usr/soft/solr/tomcat7/webapps/solr/WEB-INFviweb.xml/usr/soft/solr/solrhome&lt;env-entry&gt;&lt;env-entry-name&gt;solr/home&lt;/env-entry-name&gt;&lt;!--这里设置为自己的solrhome路径--&gt;&lt;env-entry-value&gt;/usr/soft/solr/solrhome&lt;/env-entry-value&gt;&lt;env-entry-type&gt;java.lang.String&lt;/env-entry-type&gt;&lt;/env-entry&gt;:wq8重启tomcatcd/usr/soft/solr/tomcat7/bin./shutdown.sh./startup.sh9访问solrhttp://192.168.25.132:8080/solr/配置IK分词器IKAnalyzer简介IKAnalyzer是一个开源的，基亍java语言开发的轻量级的中文分词工具包。从2006年12月推出1.0版开始，IKAnalyzer已经推出了4个大版本。最初，它是以开源项目Luence为应用主体的，结合词典分词和文法分析算法的中文分词组件。从3.0版本开始，IK发展为面向Java的公用分词组件，独立亍Lucene项目，同时提供了对Lucene的默认优化实现。在2012版本中，IK实现了简单的分词歧义排除算法，标志着IK分词器从单纯的词典分词向模拟语义分词衍化。1将ik分词器jar包移动到solr中cp~/IK\\Analyzer\\2012FF_hf1/IKAnalyzer2012FF_u1.jar/usr/soft/solr/tomcat7/webapps/solr/WEB-INF/lib2在solr项目的WEB-INF目录创建一个classes目录mkdir/usr/soft/solr/tomcat7/webapps/solr/WEB-INF/classes3移动配置文件到classes目录cpIKAnalyzer.cfg.xmlext_stopword.dicmydict.dic/usr/soft/solr/tomcat7/webapps/solr/WEB-INF/classes4启用---编辑配置文件使用npp编辑服务器上的文件1安装npp(略)2安装NppFTP(略)3连接服务器(虐)4编辑xml文件:/usr/soft/solr/solrhome/collection1/conf/schema.xml&lt;!--配置IK分词器--&gt;&lt;fieldTypename=&quot;text_ik&quot;class=&quot;solr.TextField&quot;&gt;&lt;analyzerclass=&quot;org.wltea.analyzer.lucene.IKAnalyzer&quot;&gt;&lt;/analyzer&gt;&lt;/fieldType&gt;5重启tomcatcd/usr/soft/solr/tomcat7/bin./shutdown.sh./startup.sh6访问urlhttp://192.168.25.132:8080/solr/域域:相当于数据库表的字段&lt;!--name:指定域的名称type:指定域的类型indexed:是否索引stored:是否存储required:是否必须multiValued:是否多值--&gt;&lt;fieldname=&quot;id&quot;type=&quot;string&quot;indexed=&quot;true&quot;stored=&quot;true&quot;required=&quot;true&quot;multiValued=&quot;false&quot;/&gt;SpringDataSolrDemo1、引入依赖&lt;dependency&gt;&lt;groupId&gt;org.springframework.data&lt;/groupId&gt;&lt;artifactId&gt;spring-data-solr&lt;/artifactId&gt;&lt;version&gt;1.5.5.RELEASE&lt;/version&gt;&lt;/dependency&gt;2、applicationContext-solr.xml&lt;?xmlversion=&quot;1.0&quot;encoding=&quot;UTF-8&quot;?&gt;&lt;beansxmlns=&quot;http://www.springframework.org/schema/beans&quot;xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;xmlns:p=&quot;http://www.springframework.org/schema/p&quot;xmlns:context=&quot;http://www.springframework.org/schema/context&quot;xmlns:solr=&quot;http://www.springframework.org/schema/data/solr&quot;xsi:schemaLocation=&quot;http://www.springframework.org/schema/data/solrhttp://www.springframework.org/schema/data/solr/spring-solr-1.0.xsdhttp://www.springframework.org/schema/beanshttp://www.springframework.org/schema/beans/spring-beans.xsdhttp://www.springframework.org/schema/contexthttp://www.springframework.org/schema/context/spring-context.xsd&quot;&gt;&lt;!--solr服务器地址--&gt;&lt;solr:solr-serverid=&quot;solrServer&quot;url=&quot;http://127.0.0.1:8080/solr&quot;/&gt;&lt;!--solr模板，使用solr模板可对索引库进行CRUD的操作--&gt;&lt;beanid=&quot;solrTemplate&quot;class=&quot;org.springframework.data.solr.core.SolrTemplate&quot;&gt;&lt;constructor-argref=&quot;solrServer&quot;/&gt;&lt;/bean&gt;&lt;/beans&gt;3、@Field注解作用：如果在pojo上添加了这个注解，那么这个属性会被引用到solr，value为指定solr中field定义的name，如果一样可以省略@Dynamic注解，在属性上定义就表示是一个动态域4、添加@AutowiredprivateSolrTemplatesolrTemplate;solrTemplate.saveBean(item);//添加多条数据可以使用saveBeanssolrTemplate.commit();//提交事务5、按主键查询//参数1：要查询的主键ID//参数2：返回的数据类型solrTemplate.getById(1,TbItem.class)6、按主键删除solrTemplate.deleteById(&quot;1&quot;);7、分页查询//条件Queryquery=newSimpleQuery(&quot;*:*&quot;);//查询条件Criteriacriteria=newCriteria();//and：查询的域//contains：查询的关键字criteria.and(&quot;item_title&quot;).contains(&quot;手机&quot;);//将查询条件添加到queyr中query.addCriteria(criteria);query.setOffset(0);//开始索引，默认为0，翻页规则(pageNow-1)*pageSizequery.setRows(20);//每页记录条数//ScoredPage：solr的分页查询//参数1：查询条件//参数2：返回类型ScoredPage&lt;TbItem&gt;page=solrTemplate.queryForPage(query,TbItem.class)System.out.pringln(&quot;总记录数:&quot;+page.getTotalElements());List&lt;TbItem&gt;list=page.getContent();8、高亮查询@ResourceprivateSolrTemplatesolrTemplate;@OverridepublicMap&lt;String,Object&gt;search(Map&lt;String,Object&gt;searchMap){Map&lt;String,Object&gt;map=newHashMap&lt;String,Object&gt;();//设置搜索高亮HighlightQueryquery=newSimpleHighlightQuery();//设置高亮的域HighlightOptionshighlightOptions=newHighlightOptions().addField(&quot;item_title&quot;);//设置高亮前缀highlightOptions.setSimplePrefix(&quot;&lt;emstyle='color:red'&gt;&quot;);//设置高亮后缀highlightOptions.setSimplePostfix(&quot;&lt;/em&gt;&quot;);//设置高亮选项query.setHighlightOptions(highlightOptions);//按照关键字查询Criteriacriteria=newCriteria(&quot;item_keywords&quot;).is(searchMap.get(&quot;keywords&quot;));//添加条件query.addCriteria(criteria);//到solr中查询HighlightPage&lt;TbItem&gt;page=solrTemplate.queryForHighlightPage(query,TbItem.class);//循环高亮入口集合for(HighlightEntry&lt;TbItem&gt;entry:page.getHighlighted()){//获取原实体类TbItemtbItem=entry.getEntity();//判断是否有高亮内容if(entry.getHighlights().size()&gt;0&amp;&amp;entry.getHighlights().get(0).getSnipplets().size()&gt;0){//设置高亮的结果tbItem.setTitle(entry.getHighlights().get(0).getSnipplets().get(0));}}map.put(&quot;rows&quot;,page.getContent());returnmap;}","link":"https://haohanya.github.io/post/solr-an-zhuang-shi-yong/"},{"title":"Spring-Security","content":"SpringSecurity简介SpringSecurity是一个能够为基于Spring的企业应用系统提供声明式的安全访问控制解决方案的安全框架。它提供了一组可以在Spring应用上下文中配置的Bean，充分利用了SpringIoC，DI（控制反转InversionofControl,DI:DependencyInjection依赖注入）和AOP（面向切面编程）功能，为应用系统提供声明式的安全访问控制功能，减少了为企业系统安全控制编写大量重复代码的工作。单机版1.引入依赖&lt;!--身份验证--&gt;&lt;dependency&gt;&lt;groupId&gt;org.springframework.security&lt;/groupId&gt;&lt;artifactId&gt;spring-security-web&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt;&lt;groupId&gt;org.springframework.security&lt;/groupId&gt;&lt;artifactId&gt;spring-security-config&lt;/artifactId&gt;&lt;/dependency&gt;2.配置核心配置文件&lt;?xmlversion=&quot;1.0&quot;encoding=&quot;UTF-8&quot;?&gt;&lt;beans:beansxmlns=&quot;http://www.springframework.org/schema/security&quot;xmlns:beans=&quot;http://www.springframework.org/schema/beans&quot;xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;xsi:schemaLocation=&quot;http://www.springframework.org/schema/beanshttp://www.springframework.org/schema/beans/spring-beans.xsdhttp://www.springframework.org/schema/securityhttp://www.springframework.org/schema/security/spring-security.xsd&quot;&gt;&lt;!--以下页面不被拦截--&gt;&lt;httppattern=&quot;/login.html&quot;security=&quot;none&quot;/&gt;&lt;httppattern=&quot;/css/**&quot;security=&quot;none&quot;/&gt;&lt;httppattern=&quot;/img/**&quot;security=&quot;none&quot;/&gt;&lt;httppattern=&quot;/js/**&quot;security=&quot;none&quot;/&gt;&lt;httppattern=&quot;/plugins/**&quot;security=&quot;none&quot;/&gt;&lt;!--页面拦截规则use-expressions:是否启用spel表达式,如果为true那么access=&quot;hasRole('ROLE_USER')&quot;--&gt;&lt;!--页面拦截规则--&gt;&lt;httpuse-expressions=&quot;false&quot;&gt;&lt;!--pattern:拦截的urlaccess:拥有如下权限允许访问--&gt;&lt;intercept-urlpattern=&quot;/**&quot;access=&quot;ROLE_ADMIN&quot;/&gt;&lt;!--login-page:自定义登陆页面default-target-url:登陆成功后跳转的页面,不设定默认跳转上一次访问的页面authentication-failure-url:登陆失败时跳转的urlalways-use-default-target:登陆成功后总是跳转到default-target-url设定的url--&gt;&lt;form-loginlogin-page=&quot;/login.html&quot;default-target-url=&quot;/admin/index.html&quot;authentication-failure-url=&quot;/login.html&quot;always-use-default-target=&quot;true&quot;/&gt;&lt;csrfdisabled=&quot;true&quot;/&gt;&lt;!--logout-url:退出的地址logout-success-url:退出后跳转的地址--&gt;&lt;logoutlogout-url=&quot;/logout&quot;logout-success-url=&quot;/login.html&quot;/&gt;&lt;!--如果使用了iframe,需要指定框架页的策略为SAMEORIGIN--&gt;&lt;headers&gt;&lt;frame-optionspolicy=&quot;SAMEORIGIN&quot;/&gt;&lt;!--允许使用frameset--&gt;&lt;/headers&gt;&lt;/http&gt;&lt;!--认证管理器--&gt;&lt;authentication-manager&gt;&lt;authentication-provider&gt;&lt;user-service&gt;&lt;!--用户名和密码,权限--&gt;&lt;username=&quot;root&quot;password=&quot;root&quot;authorities=&quot;ROLE_ADMIN&quot;/&gt;&lt;/user-service&gt;&lt;/authentication-provider&gt;&lt;/authentication-manager&gt;&lt;/beans:beans&gt;3.配置web.xml&lt;context-param&gt;&lt;param-name&gt;contextConfigLocation&lt;/param-name&gt;&lt;param-value&gt;classpath:spring/spring-security.xml&lt;/param-value&gt;&lt;/context-param&gt;&lt;listener&gt;&lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt;&lt;/listener&gt;&lt;filter&gt;&lt;filter-name&gt;springSecurityFilterChain&lt;/filter-name&gt;&lt;filter-class&gt;org.springframework.web.filter.DelegatingFilterProxy&lt;/filter-class&gt;&lt;/filter&gt;&lt;filter-mapping&gt;&lt;filter-name&gt;springSecurityFilterChain&lt;/filter-name&gt;&lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt;连接数据库1.引入依赖2.实现UserDetailsService接口packagecom.jd.shop.service.impl;importcom.jd.pojo.TbSeller;importcom.jd.sellergoods.service.TbSellerService;importorg.springframework.security.core.GrantedAuthority;importorg.springframework.security.core.authority.SimpleGrantedAuthority;importorg.springframework.security.core.userdetails.User;importorg.springframework.security.core.userdetails.UserDetails;importorg.springframework.security.core.userdetails.UserDetailsService;importorg.springframework.security.core.userdetails.UsernameNotFoundException;importjava.util.ArrayList;importjava.util.List;/***认证类*@program:jd*@author:潘*@create:2020-04-2922:43**/publicclassUserDetailsServiceImplimplementsUserDetailsService{privateTbSellerServicetbSellerService;publicvoidsetTbSellerService(TbSellerServicetbSellerService){this.tbSellerService=tbSellerService;}@OverridepublicUserDetailsloadUserByUsername(Stringusername)throwsUsernameNotFoundException{if(username==null){returnnull;}TbSellerbyId=tbSellerService.findById(username);if(byId==null){returnnull;}//构建角色列表List&lt;GrantedAuthority&gt;list=newArrayList&lt;&gt;();//用户的权限集合list.add(newSimpleGrantedAuthority(&quot;ROLE_USER&quot;));returnnewUser(username,byId.getPassword(),list);}}3.配置核心配置文件&lt;?xmlversion=&quot;1.0&quot;encoding=&quot;UTF-8&quot;?&gt;&lt;beans:beansxmlns=&quot;http://www.springframework.org/schema/security&quot;xmlns:beans=&quot;http://www.springframework.org/schema/beans&quot;xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;xmlns:dubbo=&quot;http://code.alibabatech.com/schema/dubbo&quot;xsi:schemaLocation=&quot;http://www.springframework.org/schema/beanshttp://www.springframework.org/schema/beans/spring-beans.xsdhttp://www.springframework.org/schema/securityhttp://www.springframework.org/schema/security/spring-security.xsdhttp://code.alibabatech.com/schema/dubbohttp://code.alibabatech.com/schema/dubbo/dubbo.xsd&quot;&gt;&lt;!--以下页面不被拦截--&gt;&lt;httppattern=&quot;/login.html&quot;security=&quot;none&quot;/&gt;&lt;httppattern=&quot;/css/**&quot;security=&quot;none&quot;/&gt;&lt;httppattern=&quot;/img/**&quot;security=&quot;none&quot;/&gt;&lt;httppattern=&quot;/js/**&quot;security=&quot;none&quot;/&gt;&lt;httppattern=&quot;/plugins/**&quot;security=&quot;none&quot;/&gt;&lt;httppattern=&quot;/*.html&quot;security=&quot;none&quot;/&gt;&lt;!--&lt;httppattern=&quot;/login&quot;security=&quot;none&quot;/&gt;--&gt;&lt;!--页面拦截规则use-expressions:是否启用spel表达式,如果为true那么access=&quot;hasRole('ROLE_USER')&quot;--&gt;&lt;!--页面拦截规则--&gt;&lt;httpuse-expressions=&quot;false&quot;&gt;&lt;!--pattern:拦截的urlaccess:拥有如下权限允许访问--&gt;&lt;intercept-urlpattern=&quot;/**&quot;access=&quot;ROLE_USER&quot;/&gt;&lt;!--login-page:自定义登陆页面default-target-url:登陆成功后跳转的页面,不设定默认跳转上一次访问的页面authentication-failure-url:登陆失败时跳转的urlalways-use-default-target:登陆成功后总是跳转到default-target-url设定的url--&gt;&lt;form-loginlogin-processing-url=&quot;/login&quot;login-page=&quot;/shoplogin.html&quot;default-target-url=&quot;/admin/index.html&quot;authentication-failure-url=&quot;/shoplogin.html&quot;always-use-default-target=&quot;true&quot;/&gt;&lt;csrfdisabled=&quot;true&quot;/&gt;&lt;!--logout-url:退出的地址logout-success-url:退出后跳转的地址--&gt;&lt;logoutlogout-url=&quot;/logout&quot;logout-success-url=&quot;/shoplogin.html&quot;/&gt;&lt;!--如果使用了iframe,需要指定框架页的策略为SAMEORIGIN--&gt;&lt;headers&gt;&lt;frame-optionspolicy=&quot;SAMEORIGIN&quot;/&gt;&lt;!--允许使用frameset--&gt;&lt;/headers&gt;&lt;/http&gt;&lt;!--认证管理器--&gt;&lt;authentication-manager&gt;&lt;authentication-provideruser-service-ref=&quot;userDetailsServiceImpl&quot;/&gt;&lt;/authentication-manager&gt;&lt;!--引用dubbo服务--&gt;&lt;dubbo:applicationname=&quot;jd-shop-web&quot;/&gt;&lt;dubbo:registryaddress=&quot;zookeeper://47.98.157.69:2181&quot;timeout=&quot;30000&quot;/&gt;&lt;dubbo:annotationpackage=&quot;com.jd.shop.controller&quot;/&gt;&lt;dubbo:referenceinterface=&quot;com.jd.sellergoods.service.TbSellerService&quot;id=&quot;tbSellerService&quot;/&gt;&lt;beans:beanid=&quot;userDetailsServiceImpl&quot;class=&quot;com.jd.shop.service.impl.UserDetailsServiceImpl&quot;&gt;&lt;beans:propertyname=&quot;tbSellerService&quot;ref=&quot;tbSellerService&quot;/&gt;&lt;/beans:bean&gt;&lt;/beans:beans&gt;4.配置web.xml文件Brcy加密1.编写javaBCryptPasswordEncoderpasswordEncoder=newBCryptPasswordEncoder();Stringencode=passwordEncoder.encode(tbSeller.getPassword());2.编写配置文件&lt;!--认证管理器--&gt;&lt;authentication-manager&gt;&lt;authentication-provideruser-service-ref=&quot;userDetailsServiceImpl&quot;&gt;&lt;!--这句话表示在登陆时使用bcry加密验证--&gt;&lt;password-encoderref=&quot;bCryptPasswordEncoder&quot;/&gt;&lt;/authentication-provider&gt;&lt;/authentication-manager&gt;&lt;!--配置加密,在认证管理器中引用--&gt;&lt;beans:beanid=&quot;bCryptPasswordEncoder&quot;class=&quot;org.springframework.security.crypto.bcrypt.BCryptPasswordEncoder&quot;/&gt;记住我&lt;inputvalue=&quot;1&quot;name=&quot;remember-me&quot;/&gt;","link":"https://haohanya.github.io/post/spring-security/"},{"title":"MyBatis","content":"快速开始1、MyBatis核心配置文件&lt;?xmlversion=&quot;1.0&quot;encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPEconfigurationPUBLIC&quot;-//mybatis.org//DTDConfig3.0//EN&quot;&quot;http://mybatis.org/dtd/mybatis-3-config.dtd&quot;&gt;&lt;configuration&gt;&lt;!--配置数据源--&gt;&lt;environmentsdefault=&quot;development&quot;&gt;&lt;environmentid=&quot;development&quot;&gt;&lt;!--事务处理方式--&gt;&lt;transactionManagertype=&quot;JDBC&quot;/&gt;&lt;dataSourcetype=&quot;POOLED&quot;&gt;&lt;propertyname=&quot;driver&quot;value=&quot;com.mysql.jdbc.Driver&quot;/&gt;&lt;propertyname=&quot;url&quot;value=&quot;jdbc:mysql://localhost:3306/mybatis&quot;/&gt;&lt;propertyname=&quot;username&quot;value=&quot;root&quot;/&gt;&lt;propertyname=&quot;password&quot;value=&quot;root&quot;/&gt;&lt;/dataSource&gt;&lt;/environment&gt;&lt;/environments&gt;&lt;!--映射器：每一个Mapper接口都应该在核心配置文件&lt;mappers&gt;标签中注册--&gt;&lt;mappers&gt;&lt;!--使用XML配置文件注册--&gt;&lt;mapperresource=&quot;com/cn/mybatis/dao/IcpInfoMapper.xml&quot;/&gt;&lt;!--使用类注册方式--&gt;&lt;mapperclass=&quot;com.cn.mybatis.dao.IcpInfoMapper&quot;/&gt;&lt;/mappers&gt;&lt;/configuration&gt;2、ORM映射文件mapper.xml&lt;?xmlversion=&quot;1.0&quot;encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPEmapperPUBLIC&quot;-//mybatis.org//DTDMapper3.0//EN&quot;&quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;&lt;!--这个配置文件主要是配置实体类和数据库中的表映射关系--&gt;&lt;!--mapper：映射信息配置namesapce:如果是在ibatis的开发中，名字可以随便取，但是在mybatis中将有特殊的意义--&gt;&lt;mappernamespace=&quot;test&quot;&gt;&lt;!--查询所有的书籍信息select:专门用于查询的statementid:是statement的唯一标识符resultType:返回值得类型（跟返回的个数无关），将返回类型的全限定名写到这里--&gt;&lt;selectid=&quot;selectAllBooks&quot;resultType=&quot;cn.kgc.pojo.Book&quot;&gt;select*frombook&lt;/select&gt;&lt;/mapper&gt;3、日志文件log4j.propertieslog4j.rootLogger=DEBUG,A1log4j.logger.org.mybatis=DEBUGlog4j.appender.A1=org.apache.log4j.ConsoleAppenderlog4j.appender.A1.layout=org.apache.log4j.PatternLayoutlog4j.appender.A1.layout.ConversionPattern=%-d{yyyy-MM-ddHH:mm:ss,SSS}[%t][%c]-[%p]%m%n4、测试//查询全部@TestpublicvoidtestFindAll()throwsException{//通过流的方式读取配置文件InputStreaminputStream=Resources.getResourceAsStream(&quot;mybatis-config.xml&quot;);//1.读取配置文件,得到SqlSessionFactorySqlSessionFactorysqlSessionFactory=newSqlSessionFactoryBuilder().build(inputStream);//2.创建SqlSessionSqlSessionsqlSession=sqlSessionFactory.openSession();//3.查询所有(参数：是namespace.statementId)List&lt;Book&gt;list=sqlSession.selectList(&quot;test.selectAllBooks&quot;);System.out.println(list);}properties属性创建一个外部的properties文件jdbc.dirver=com.mysql.jdbc.Driverjdbc.url=jdbc:mysql://localhost:3306/mybatis?useUnicode=true&amp;amp;characterEncoding=utf-8jdbc.username=rootjdbc.password=root在核心配置文件中引用properties文件&lt;propertiesresource=&quot;jdbc.properties&quot;/&gt;使用${jdbc.dirver}${jdbc.url}${jdbc.username}settingsmapUnderscoreToCamelCase:开启驼峰命名，可以帮助我们完成数据库的经典命名规则，到java的经典命名规则（驼峰命名发）如：数据库叫user_name到java类（pojo）中是userName&lt;settings&gt;&lt;!--开启驼峰命名--&gt;&lt;settingname=&quot;mapUnderscoreToCamelCase&quot;value=&quot;true&quot;/&gt;&lt;!--指定MyBatis所用日志的具体实现，未指定时将自动查找。日志类型：STDOUT_LOGGING不需要导入jar包，因为是mybatis自带NO_LOGGING代表不需要日志输出SLF4J|LOG4J|LOG4J2|JDK_LOGGING|COMMONS_LOGGING|STDOUT_LOGGING|NO_LOGGING--&gt;&lt;settingname=&quot;logImpl&quot;value=&quot;STDOUT_LOGGING&quot;/&gt;&lt;/settings&gt;分析日志输出typeAliases（类型别名）自定义别名&lt;!--别名，用于简化--&gt;&lt;typeAliases&gt;&lt;!--type：包+类名，alias：别名--&gt;&lt;typeAliastype=&quot;com.cn.mybatis.entity.IcpInfo&quot;alias=&quot;Icp&quot;/&gt;&lt;!--使用包的方式每一个在包domain.blog中的JavaBean，在没有注解的情况下会使用Bean的首字母小写的非限定类名来作为它的别名(这句话意思是：@Alias(&quot;author&quot;)在使用包方式时，javaBean没有添加注解指定别名时自动使用类名{首字母小写})--&gt;&lt;packagename=&quot;com.cn.mybatis.entity&quot;/&gt;&lt;/typeAliases&gt;plugins（插件）XML映射cache–对给定命名空间的缓存配置。cache-ref–对其他命名空间缓存配置的引用。resultMap–是最复杂也是最强大的元素，用来描述如何从数据库结果集中来加载对象。parameterMap–已被废弃！老式风格的参数映射。更好的办法是使用内联参数，此元素可能在将来被移除。文档中不会介绍此元素。sql–可被其他语句引用的可重用语句块。insert–映射插入语句update–映射更新语句delete–映射删除语句select–映射查询语句select查询语句&lt;!--id：一般和Mepper接口的方法名称相同，在命名空间中唯一的标识符，可以被用来引用这条语句。parameterType：接收一个int类型的参数接收参数使用#{}包裹着，这个参数对应着接口的参数resultType：返回一个hashmap类型的数据--&gt;&lt;selectid=&quot;selectPerson&quot;parameterType=&quot;int&quot;resultType=&quot;hashmap&quot;&gt;SELECT*FROMPERSONWHEREID=#{id}&lt;/select&gt;insertupdateadelete在使用这些语句的时候需要提交事务：session.commit();&lt;insertid=&quot;addIcpInfo&quot;parameterType=&quot;icpInfo&quot;&gt;insertintoicpinfo(icp,name,address,home,introduce,author,email,date,type)values(#{icp},#{name},#{address},#{home},#{introduce},#{author},#{email},#{date},#{type})&lt;/insert&gt;获取插入数据后的主键id：useGeneratedKeys=&quot;true&quot;keyProperty=&quot;cip&quot;&lt;insertid=&quot;addIcpInfo&quot;useGeneratedKeys=&quot;true&quot;keyProperty=&quot;cip&quot;&gt;insertintoicpinfo(icp,name,address,home,introduce,author,email,date,type)values(#{icp},#{name},#{address},#{home},#{introduce},#{author},#{email},#{date},#{type})&lt;/insert&gt;插入多条数据：传入一个数组或集合，并返回自动生成的主键。&lt;insertid=&quot;addIcpInfoList&quot;useGeneratedKeys=&quot;true&quot;keyProperty=&quot;cip&quot;&gt;insertintoicpinfo(icp,name,address,home,introduce,author,email,date,type)values&lt;foreachcollection=&quot;list&quot;item=&quot;item&quot;separator=&quot;,&quot;&gt;(#{item.icp},#{item.name},#{item.address},#{item.home},#{item.introduce},#{item.author},#{item.email},#{item.date},#{item.type})&lt;/foreach&gt;&lt;/insert&gt;动态SQLif对于输入映射类型为pojo类型：#{pojo中的属性名}${pojo中的属性名}&lt;iftest=&quot;gradeId!=null&quot;&gt;andgrade_id=#{gradeId}&lt;/if&gt;sql注入的问题在使用${}会出现sql注入的问题（拼接字符串，没有使用预编译）如果为简单数据类型需要把name换成_parameter&lt;bindname=&quot;n&quot;value=&quot;'%'+name+'%'&quot;/&gt;andnamelike#{n}when应用场景：可能查询全部，有可能根据条件查询，并且如果第一个条件前面有and，where子句会自动把这个and删除再作为sql语句运行&lt;selectid=&quot;findStudentByLike&quot;resultType=&quot;student&quot;parameterType=&quot;student&quot;&gt;select*fromstudent&lt;where&gt;&lt;iftest=&quot;name!=nullandname!=''&quot;&gt;&lt;bindname=&quot;n&quot;value=&quot;'%'+name+'%'&quot;/&gt;andnamelike#{n}&lt;/if&gt;&lt;iftest=&quot;gradeId!=null&quot;&gt;andgrade_id=#{gradeId}&lt;/if&gt;&lt;/where&gt;&lt;/select&gt;choose其实就是java中的switch或者if...elseif...elsesetset标签作用：能自动的判断是否在sql语句的结尾处是否要添加逗号，如果不需要逗号它自动帮我们删除(和where一样不会自动添加)&lt;updateid=&quot;updateStudentByById&quot;parameterType=&quot;student&quot;&gt;updatestudent&lt;set&gt;&lt;iftest=&quot;name!=null&quot;&gt;name=#{name},&lt;/if&gt;&lt;iftest=&quot;gradeId!=null&quot;&gt;grade_id=#{gradeId}&lt;/if&gt;&lt;/set&gt;whereid=#{id}&lt;/update&gt;foreach&lt;selectid=&quot;findStudentsById&quot;parameterType=&quot;int&quot;resultType=&quot;student&quot;&gt;select*fromstudentwhereidin&lt;foreachcollection=&quot;list&quot;open=&quot;(&quot;separator=&quot;,&quot;close=&quot;)&quot;item=&quot;item&quot;&gt;#{item}&lt;/foreach&gt;&lt;/select&gt;SQL片段&lt;sqlid=&quot;sql&quot;&gt;select*fromstudent&lt;/sql&gt;调用&lt;includerefid=&quot;sql&quot;&gt;&lt;/include&gt;多表联合查询VO解决思路：要求返回的是一个对象，如果pojo不能满足(要返回的列不存在pojo中)，那么创建一个VO对象，这个VO对象中包含了所有要返回的字段创建一个VOpackagecn.kgc.vo;importcn.kgc.pojo.Student;//继承的原则：要返回的字段哪个pojo中多，那么就继承哪个pojopublicclassStudentVOextendsStudent{privateStringgradeName;publicStringgetGradeName(){returngradeName;}publicvoidsetGradeName(StringgradeName){this.gradeName=gradeName;}}编写mapper接口publicinterfaceStudentMapper{/***查询学生信息，要求展示学生信息中年级名称(联合查询)*/List&lt;StudentVO&gt;getStudentVO();}编写mapper.xml&lt;selectid=&quot;getStudentVO&quot;resultType=&quot;cn.kgc.vo.StudentVO&quot;&gt;SELECTs.*,g.namegradeNameFROMstudents,gradegWHEREs.grade_id=g.id&lt;/select&gt;一对一按照查询嵌套处理&lt;resultMapid=&quot;IcpInfoType&quot;type=&quot;icpInfo&quot;&gt;&lt;!--property：实体类的对象属性名，column：数据库中关联的列，javaType：实体类对象，select：一个sql语句查询的是实体对象的sql--&gt;&lt;associationproperty=&quot;type&quot;column=&quot;type&quot;javaType=&quot;type&quot;select=&quot;getTypeList&quot;/&gt;&lt;/resultMap&gt;&lt;selectid=&quot;getList&quot;resultMap=&quot;IcpInfoType&quot;&gt;select*fromicpinfo&lt;/select&gt;&lt;!--这个typeID获取的是column=&quot;type&quot;这个列的值--&gt;&lt;selectid=&quot;getTypeList&quot;resultType=&quot;type&quot;&gt;select*fromtypewheretid=#{id}&lt;/select&gt;按照结果嵌套处理&lt;selectid=&quot;getList2&quot;resultMap=&quot;getList2&quot;&gt;selecticp,name,address,home,introduce,author,email,`date`,type,tid,tnamefromicpinfoi,typetwherei.type=t.tid&lt;/select&gt;&lt;!--type=要查询的对象--&gt;&lt;resultMapid=&quot;getList2&quot;type=&quot;icpInfo&quot;&gt;&lt;!--property=实体类的属性名column=列名or别名--&gt;&lt;resultproperty=&quot;icp&quot;column=&quot;icp&quot;/&gt;&lt;resultproperty=&quot;name&quot;column=&quot;name&quot;/&gt;&lt;resultproperty=&quot;address&quot;column=&quot;address&quot;/&gt;&lt;resultproperty=&quot;home&quot;column=&quot;home&quot;/&gt;&lt;resultproperty=&quot;introduce&quot;column=&quot;introduce&quot;/&gt;&lt;resultproperty=&quot;author&quot;column=&quot;author&quot;/&gt;&lt;resultproperty=&quot;email&quot;column=&quot;email&quot;/&gt;&lt;resultproperty=&quot;date&quot;column=&quot;date&quot;/&gt;&lt;!--复杂类型property=在icpInfo里的属性是typejavaType=type的对象--&gt;&lt;associationproperty=&quot;type&quot;javaType=&quot;type&quot;&gt;&lt;resultproperty=&quot;tid&quot;column=&quot;tid&quot;/&gt;&lt;resultproperty=&quot;tname&quot;column=&quot;tname&quot;/&gt;&lt;/association&gt;&lt;/resultMap&gt;一对多一对多只需要把association换成&lt;!--ofType=&quot;&quot;集合中的泛型信息--&gt;&lt;collectionproperty=&quot;&quot;ofType=&quot;&quot;&gt;&lt;/collection&gt;&lt;?xmlversion=&quot;1.0&quot;encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPEmapperPUBLIC&quot;-//mybatis.org//DTDMapper3.0//EN&quot;&quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;&lt;mappernamespace=&quot;cn.kgc.mapper.GradeMapper&quot;&gt;&lt;!--查询年级，把属于这个年级的所有学生查询出来--&gt;&lt;resultMaptype=&quot;cn.kgc.pojo.Grade&quot;id=&quot;gradeStudentMap&quot;&gt;&lt;idcolumn=&quot;id&quot;property=&quot;id&quot;javaType=&quot;int&quot;/&gt;&lt;resultcolumn=&quot;name&quot;property=&quot;name&quot;javaType=&quot;string&quot;/&gt;&lt;!--collection:一对多的映射关系property:表示一对多映射关系在pojo中的属性名ofType:表示该集合的泛型的全限定名--&gt;&lt;collectionproperty=&quot;studentList&quot;ofType=&quot;cn.kgc.pojo.Student&quot;&gt;&lt;idcolumn=&quot;sid&quot;property=&quot;id&quot;javaType=&quot;int&quot;/&gt;&lt;resultcolumn=&quot;sname&quot;property=&quot;name&quot;javaType=&quot;string&quot;/&gt;&lt;!--gradeid因为在grade中已经有了，所以不需要再配置--&gt;&lt;/collection&gt;&lt;/resultMap&gt;&lt;selectid=&quot;getGradeById&quot;parameterType=&quot;int&quot;resultMap=&quot;gradeStudentMap&quot;&gt;SELECTg.*,s.idsid,s.namesnameFROMgradeg,studentsWHEREg.id=s.grade_idANDg.id=#{id}&lt;/select&gt;&lt;/mapper&gt;多对多&lt;?xmlversion=&quot;1.0&quot;encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPEmapperPUBLIC&quot;-//mybatis.org//DTDMapper3.0//EN&quot;&quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;&lt;mappernamespace=&quot;cn.kgc.mapper.StudentMapper&quot;&gt;&lt;resultMaptype=&quot;cn.kgc.pojo.Student&quot;id=&quot;studentMap&quot;&gt;&lt;idcolumn=&quot;id&quot;property=&quot;id&quot;javaType=&quot;int&quot;/&gt;&lt;resultcolumn=&quot;name&quot;property=&quot;name&quot;javaType=&quot;string&quot;/&gt;&lt;resultcolumn=&quot;grade_id&quot;property=&quot;gradeId&quot;javaType=&quot;int&quot;/&gt;&lt;!--一对多的映射关系--&gt;&lt;collectionproperty=&quot;studentCourseList&quot;ofType=&quot;cn.kgc.pojo.StudentCourse&quot;&gt;&lt;idcolumn=&quot;scid&quot;property=&quot;id&quot;javaType=&quot;int&quot;/&gt;&lt;!--studentCourse和course是一对一的映射俄关系--&gt;&lt;associationproperty=&quot;course&quot;javaType=&quot;cn.kgc.pojo.Course&quot;&gt;&lt;idcolumn=&quot;cid&quot;property=&quot;id&quot;javaType=&quot;int&quot;/&gt;&lt;resultcolumn=&quot;cname&quot;property=&quot;name&quot;javaType=&quot;string&quot;/&gt;&lt;/association&gt;&lt;/collection&gt;&lt;/resultMap&gt;&lt;selectid=&quot;getStudentById&quot;parameterType=&quot;int&quot;resultMap=&quot;studentMap&quot;&gt;SELECTs.*,sc.idscid,c.idcid,c.namecnameFROMstudents,student_coursesc,coursecWHEREs.id=sc.sidANDc.id=sc.cidANDs.id=#{id}&lt;/select&gt;&lt;/mapper&gt;延迟加载什么是懒加载懒加载：就是在需要数据的时候才加载，不需要数据的时候不加载，这样有利于系统性能的提升，这就是懒加载（也叫做延迟加载）好处：在关联查询的时候，根据需求进行关联查询，大大提高了数据库的查询性能。（单表的查询效率永远要比多表联合查询的效率高）坏处：因为需要用到数据的时候才去做查询，这样大批量的数据查询的时候等待时间会变得更长，造成用户的体验下降(select*fromstudent)会把所有的学生的年级编号也在里面突然要查询年级信息，它底层操作是：根据年级id一个一个去执行查询使用association实现懒加载核心配置开启懒加载&lt;settings&gt;&lt;!--开启懒加载--&gt;&lt;settingname=&quot;lazyLoadingEnabled&quot;value=&quot;true&quot;/&gt;&lt;!--mybatis3.4.1之前默认值是true，需要设置为false（将积极加载改为消息加载也就是按需加载）--&gt;&lt;settingname=&quot;aggressiveLazyLoading&quot;value=&quot;false&quot;/&gt;&lt;!--因为我这里为了打印对象里信息的方便，所以都重写了toString方法，mybatis中默认是如果使用(equals,clone,hashCode,toString任意一个方法)那么就不再延迟加载--&gt;&lt;settingname=&quot;lazyLoadTriggerMethods&quot;value=&quot;&quot;/&gt;&lt;/settings&gt;GradeMapper.xml&lt;?xmlversion=&quot;1.0&quot;encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPEmapperPUBLIC&quot;-//mybatis.org//DTDMapper3.0//EN&quot;&quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;&lt;mappernamespace=&quot;cn.kgc.mapper.GradeMapper&quot;&gt;&lt;!--根据id查询年级对象--&gt;&lt;selectid=&quot;getGradeById&quot;parameterType=&quot;int&quot;resultType=&quot;cn.kgc.pojo.Grade&quot;&gt;select*fromgradewhereid=#{id}&lt;/select&gt;&lt;/mapper&gt;StudentMapper.xml&lt;?xmlversion=&quot;1.0&quot;encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPEmapperPUBLIC&quot;-//mybatis.org//DTDMapper3.0//EN&quot;&quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;&lt;mappernamespace=&quot;cn.kgc.mapper.StudentMapper&quot;&gt;&lt;resultMaptype=&quot;cn.kgc.pojo.Student&quot;id=&quot;studentMap&quot;&gt;&lt;idcolumn=&quot;id&quot;property=&quot;id&quot;javaType=&quot;int&quot;/&gt;&lt;resultcolumn=&quot;name&quot;property=&quot;name&quot;javaType=&quot;string&quot;/&gt;&lt;!--一个学生对应一个年级：一对一的关系映射对于association方式的懒加载：select:此处要求是根据年级的id查询年级对象的mapper接口中方法的全限定名column:在数据库中表与表之间关系的外键--&gt;&lt;associationproperty=&quot;grade&quot;javaType=&quot;cn.kgc.pojo.Grade&quot;select=&quot;cn.kgc.mapper.GradeMapper.getGradeById&quot;column=&quot;grade_id&quot;&gt;&lt;/association&gt;&lt;/resultMap&gt;&lt;selectid=&quot;getAllStudents&quot;resultMap=&quot;studentMap&quot;&gt;select*fromstudent&lt;/select&gt;&lt;/mapper&gt;使用collection实现懒加载核心配置开启懒加载&lt;settings&gt;&lt;!--开启懒加载--&gt;&lt;settingname=&quot;lazyLoadingEnabled&quot;value=&quot;true&quot;/&gt;&lt;!--mybatis3.4.1之前默认值是true，需要设置为false（将积极加载改为消息加载也就是按需加载）--&gt;&lt;settingname=&quot;aggressiveLazyLoading&quot;value=&quot;false&quot;/&gt;&lt;!--因为我这里为了打印对象里信息的方便，所以都重写了toString方法，mybatis中默认是如果使用(equals,clone,hashCode,toString任意一个方法)那么就不再延迟加载--&gt;&lt;settingname=&quot;lazyLoadTriggerMethods&quot;value=&quot;&quot;/&gt;&lt;/settings&gt;StudentMapper.xml&lt;selectid=&quot;getStudentsByGradeId&quot;parameterType=&quot;int&quot;resultType=&quot;cn.kgc.pojo.Student&quot;&gt;select*fromstudentwheregrade_id=#{gradeId}&lt;/select&gt;GradeMapper.xml&lt;!--查询年级信息，有可能查询年级中所有的学生信息--&gt;&lt;resultMaptype=&quot;cn.kgc.pojo.Grade&quot;id=&quot;gradeMap&quot;&gt;&lt;idcolumn=&quot;id&quot;property=&quot;id&quot;javaType=&quot;int&quot;/&gt;&lt;resultcolumn=&quot;name&quot;property=&quot;name&quot;javaType=&quot;string&quot;/&gt;&lt;!--一对多的映射关系select:根据年级编号查询学生列表的方法column:就是grade的id（它就是grade表的主键）--&gt;&lt;collectionproperty=&quot;studentList&quot;ofType=&quot;cn.kgc.pojo.Student&quot;select=&quot;cn.kgc.mapper.StudentMapper.getStudentsByGradeId&quot;column=&quot;id&quot;&gt;&lt;/collection&gt;&lt;/resultMap&gt;&lt;selectid=&quot;getAllGrades&quot;resultMap=&quot;gradeMap&quot;&gt;select*fromgrade&lt;/select&gt;mybatis缓存一级缓存它是SqlSession级别的，同一个SqlSession才涉及到一级缓存一级缓存是默认存在，它不需要去做任何的设置二级缓存它是mapper级别的，需要开启才能使用缓存在实际开发中是很有用的，它能大大的提升查询的效率，提高程序的性能在核心配置文件中开启二级缓存&lt;!--开启二级缓存(默认值就是true，准备我们使用二级缓存，可以不用设置)--&gt;&lt;settingname=&quot;cacheEnabled&quot;value=&quot;true&quot;/&gt;在mappe.xml中开启二级缓存&lt;mappernamespace=&quot;cn.kgc.mapper.StudentMapper&quot;&gt;&lt;!--在StudentMapper.xml中开启二级缓存,因为mybatis中二级缓存的实现类只有一个，默认就是这个，type可以省略不写--&gt;&lt;cachetype=&quot;org.apache.ibatis.cache.impl.PerpetualCache&quot;&gt;&lt;/cache&gt;&lt;/mapper&gt;pojo需要实现序列化接口因为缓存的时候要将pojo流化然后存储在内存中，查询再取出publicclassStudentimplementsSerializable{}补充：在mapper应用二级缓存后，默认是所有的查询方法都开启二级缓存，如果要某个查询不使用二级缓存可以添加useCache=&quot;false&quot;注解开发入门在spring4.x开始就推荐我们使用注解，完全去取代xml的配置文件目前最主流的开发方式就是：只使用注解，不再使用xml配置mybatis注解方式的开发是一种未来的趋势,这种方式比传统的xml的开发要简单并且高效导入jar包&lt;dependencies&gt;&lt;!--mysql驱动--&gt;&lt;dependency&gt;&lt;groupId&gt;mysql&lt;/groupId&gt;&lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;&lt;version&gt;5.1.38&lt;/version&gt;&lt;/dependency&gt;&lt;!--mybatis的核心包--&gt;&lt;dependency&gt;&lt;groupId&gt;org.mybatis&lt;/groupId&gt;&lt;artifactId&gt;mybatis&lt;/artifactId&gt;&lt;version&gt;3.4.6&lt;/version&gt;&lt;/dependency&gt;&lt;!--junit单元测试--&gt;&lt;dependency&gt;&lt;groupId&gt;junit&lt;/groupId&gt;&lt;artifactId&gt;junit&lt;/artifactId&gt;&lt;version&gt;4.12&lt;/version&gt;&lt;/dependency&gt;&lt;!--slf4j-log4j12(slf4j:酸辣粉)--&gt;&lt;dependency&gt;&lt;groupId&gt;org.slf4j&lt;/groupId&gt;&lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt;&lt;version&gt;1.7.25&lt;/version&gt;&lt;/dependency&gt;&lt;/dependencies&gt;配置文件log4j.propertieslog4j.rootLogger=DEBUG,A1log4j.logger.org.mybatis=DEBUGlog4j.appender.A1=org.apache.log4j.ConsoleAppenderlog4j.appender.A1.layout=org.apache.log4j.PatternLayoutlog4j.appender.A1.layout.ConversionPattern=%-d{yyyy-MM-ddHH:mm:ss,SSS}[%t][%c]-[%p]%m%njdbc.propertiesjdbc.dirver=com.mysql.jdbc.Driverjdbc.url=jdbc:mysql://localhost:3306/mybatis?useUnicode=true&amp;amp;characterEncoding=utf-8jdbc.username=rootjdbc.password=rootmybatis-config.xml&lt;?xmlversion=&quot;1.0&quot;encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPEconfigurationPUBLIC&quot;-//mybatis.org//DTDConfig3.0//EN&quot;&quot;http://mybatis.org/dtd/mybatis-3-config.dtd&quot;&gt;&lt;configuration&gt;&lt;!--引入外部的属性文件--&gt;&lt;propertiesresource=&quot;jdbc.properties&quot;&gt;&lt;/properties&gt;&lt;settings&gt;&lt;!--开启驼峰命名--&gt;&lt;settingname=&quot;mapUnderscoreToCamelCase&quot;value=&quot;true&quot;/&gt;&lt;/settings&gt;&lt;!--配置数据源--&gt;&lt;environmentsdefault=&quot;development&quot;&gt;&lt;environmentid=&quot;development&quot;&gt;&lt;transactionManagertype=&quot;JDBC&quot;/&gt;&lt;dataSourcetype=&quot;POOLED&quot;&gt;&lt;propertyname=&quot;driver&quot;value=&quot;${jdbc.dirver}&quot;/&gt;&lt;propertyname=&quot;url&quot;value=&quot;${jdbc.url}&quot;/&gt;&lt;propertyname=&quot;username&quot;value=&quot;${jdbc.username}&quot;/&gt;&lt;propertyname=&quot;password&quot;value=&quot;${jdbc.password}&quot;/&gt;&lt;/dataSource&gt;&lt;/environment&gt;&lt;/environments&gt;&lt;mappers&gt;&lt;packagename=&quot;cn.kgc.mapper&quot;/&gt;&lt;/mappers&gt;&lt;/configuration&gt;@Select(&quot;SQL&quot;)@Insert(&quot;SQL&quot;)@Delete(&quot;SQL&quot;)@Update(&quot;SQL&quot;)解决数据库表中的列名和pojo中属性名不一致第一种给sql语句起别名第二种@Results相当于是resultMap@Select(&quot;select*frombook&quot;)@Results(id=&quot;bookMap&quot;,value={@Result(id=true,column=&quot;id&quot;,property=&quot;id&quot;),@Result(column=&quot;book_name&quot;,property=&quot;name&quot;),@Result(column=&quot;price&quot;,property=&quot;price&quot;)})List&lt;Book&gt;getAllBooks();注解开发中的动态sql输入映射类型为简单类型/***有可能查询全部，有可能根据id查询*动态sql中输入映射为简单类型，输入映射为简单类型test中变量名必须叫_parameter*/@Select(&quot;&lt;script&gt;SELECT*FROMbook&lt;iftest='_parameter!=null'&gt;WHEREid=#{id}&lt;/if&gt;&lt;/script&gt;&quot;)List&lt;Book&gt;getBooksOrById(Integerid);输入映射类型为pojo开发产生SQL语句的类和方法packagecn.kgc.sql.provider;importcn.kgc.pojo.Book;publicclassBookMapperProvider{/***专门用来给BookMapper接口来提供动态sql语句的*@parambook*@return*/publicStringgetBooks(Bookbook){Stringsql=&quot;select*frombook&quot;;if(book!=null){if(book.getId()!=null){//id有值sql=&quot;select*frombookwhereid=#{id}&quot;;}if(book.getName()!=null&amp;&amp;!book.getName().equals(&quot;&quot;)){sql=&quot;select*frombookwherenamelike#{name}&quot;;}if(book.getId()!=null&amp;&amp;(book.getName()!=null&amp;&amp;!book.getName().equals(&quot;&quot;))){sql=&quot;select*frombookwhereid=#{id}andnamelike#{name}&quot;;}}returnsql;}}接口/***查询：有可能查询全部，有可能根据id查询，有可能根据name做模糊查询*@parambook*@return*/@SelectProvider(type=BookMapperProvider.class,method=&quot;getBooks&quot;)List&lt;Book&gt;getBooks(Bookbook);注解开发实现复杂的映射关系复杂的映射开发本质是两种一对一、一对多注解就对应的是：@One(一对一)@Many(一对多)要求我们使用懒加载一对一关系在核心配置文件中开启懒加载&lt;settings&gt;&lt;!--开启驼峰命名--&gt;&lt;settingname=&quot;mapUnderscoreToCamelCase&quot;value=&quot;true&quot;/&gt;&lt;!--开启懒加载--&gt;&lt;settingname=&quot;lazyLoadingEnabled&quot;value=&quot;true&quot;/&gt;&lt;!--mybatis3.4.1之前默认值是true，需要设置为false（将积极加载改为消息加载也就是按需加载）--&gt;&lt;settingname=&quot;aggressiveLazyLoading&quot;value=&quot;false&quot;/&gt;&lt;!--因为我这里为了打印对象里信息的方便，所以都重写了toString方法，mybatis中默认是如果使用(equals,clone,hashCode,toString任意一个方法)那么就不再延迟加载--&gt;&lt;settingname=&quot;lazyLoadTriggerMethods&quot;value=&quot;&quot;/&gt;&lt;/settings&gt;publicinterfaceGradeMapper{/***根据id查询对象*@paramid*@return*/@Select(&quot;select*fromgradewhereid=#{id}&quot;)GradegetGradeById(Integerid);}publicinterfaceStudentMapper{/***查询学生顺便将学生所在的年级名称查询出来*/@Select(&quot;select*fromstudent&quot;)@Results(id=&quot;studentMap&quot;,value={@Result(id=true,column=&quot;id&quot;,property=&quot;id&quot;),@Result(column=&quot;name&quot;,property=&quot;name&quot;),@Result(column=&quot;grade_id&quot;,property=&quot;grade&quot;,one=@One(select=&quot;cn.kgc.mapper.GradeMapper.getGradeById&quot;,fetchType=FetchType.LAZY))})List&lt;Student&gt;getAllStudents();}FetchType.LAZY表示加载的方式是懒加载,FetchType.EAGER表示一定联合查询如果不添加fetchType，默认就是懒加载一对多的关系publicinterfaceStudentMapper{/***根据年级编号查询学生列表*@paramid*@return*/@Select(&quot;select*fromstudentwheregrade_id=#{gid}&quot;)List&lt;Student&gt;findStudentsListByGradeId(Integerid);}packagecn.kgc.mapper;importjava.util.List;importorg.apache.ibatis.annotations.Many;importorg.apache.ibatis.annotations.Result;importorg.apache.ibatis.annotations.Results;importorg.apache.ibatis.annotations.Select;importorg.apache.ibatis.mapping.FetchType;importcn.kgc.pojo.Grade;publicinterfaceGradeMapper{@Select(&quot;select*fromgrade&quot;)@Results(id=&quot;gradeMap&quot;,value={@Result(id=true,column=&quot;id&quot;,property=&quot;id&quot;),@Result(column=&quot;name&quot;,property=&quot;name&quot;),@Result(column=&quot;id&quot;,property=&quot;studentList&quot;,many=@Many(select=&quot;cn.kgc.mapper.StudentMapper.findStudentsListByGradeId&quot;,fetchType=FetchType.LAZY))})List&lt;Grade&gt;getGrades();}mybatis基于二级缓存的开发一级缓存基于sqlSession的，默认就存在的，咱们可以不用管，它一定会存在4-1在核心配置文件中开启二级缓存&lt;!--开启二级缓存(新版本的mybatis默认就已经开启了，所以我们不用专门开)--&gt;&lt;settingname=&quot;cacheEnabled&quot;value=&quot;true&quot;/&gt;4-2在mapper接口中使用注解配置开启二级缓存&lt;!--开启二级缓存(新版本的mybatis默认就已经开启了，所以我们不用专门开)--&gt;&lt;settingname=&quot;cacheEnabled&quot;value=&quot;true&quot;/&gt;4-2pojo需要实现序列化接口publicclassBookimplementsSerializable{}4-3mapper开启二级缓存@CacheNamespace(blocking=true)//在mapper接口中开启二级缓存，默认是所有的查询都使用二级缓存publicinterfaceBookMapper{/***查询:根据主键查询*同样准守：输入映射类型为简单类型#{随便写}*如果列名不一样,可以直接引用上面已经写好的@Results定义的列和pojo属性映射的关系，方式：@ResultMap(&quot;@Results的id&quot;)*/@Select(&quot;SELECT*FROMbookWHEREid=#{id}&quot;)@ResultMap(&quot;bookMap&quot;)//@Options(useCache=true)//默认就是开启二级缓存，可以不用添加该注解BookgetBookById(Integerid);}分页查询添加分页插件的jar包依赖&lt;!--pageHelper--&gt;&lt;dependency&gt;&lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt;&lt;artifactId&gt;pagehelper&lt;/artifactId&gt;&lt;version&gt;5.1.6&lt;/version&gt;&lt;/dependency&gt;在核心配置文件中配置分页拦截器&lt;!--添加分页插件--&gt;&lt;plugins&gt;&lt;plugininterceptor=&quot;com.github.pagehelper.PageInterceptor&quot;&gt;&lt;/plugin&gt;&lt;/plugins&gt;实现分页操作/***分页查询:在实际开发中我们都会去使用分页插件来完成*pageHelper是国人做的分页插件，非常的优秀*/@TestpublicvoidtestPage(){//1.开始分页(参数一：当前要展示的页码(1,2..)，参数二：每页显示的信息条数)PageHelper.startPage(1,3);//2.执行查询(正常的执行)BookExampleexample=newBookExample();/*如果分页中有条件Criteriacriteria=example.createCriteria();criteria.andNameLike(&quot;%龙%&quot;);*/List&lt;Book&gt;list=bookMapper.selectByExample(example);//3.分页就通过pageHelper拦截器来实现分页PageInfo&lt;Book&gt;pageInfo=newPageInfo&lt;Book&gt;(list);//一页信息List&lt;Book&gt;bookList=pageInfo.getList();for(Bookbook:bookList){System.out.println(book);}System.out.println(&quot;总的页数：&quot;+pageInfo.getPages());}","link":"https://haohanya.github.io/post/mybatis/"},{"title":"Java反射","content":"获取Class对象的方式Class.forName(&quot;全类名&quot;);//将字节码文件加载进内存，返回Class对象多用于配置文件，将类名定义在配置文件中。读取文件，加载类类名.class：通过类名的属性class获取多用于参数的传递对象.getClass()：getClass()方法在Object类中定义着。//多用于对象的获取字节码的方式Classclazz=News.class;Objectobj=clazz.newInstance();//实例化一个对象：等同于new一个对象System.out.println(clazz.getSimpleName());//获取类名System.out.println(clazz.getName());//获取完整的包名+类名Class对象功能获取成员变量​Field[]getFields()：获取所有public修饰的成员变量​FieldgetField(Stringname)获取指定名称的public修饰的成员变量​Field[]getDeclaredFields();//获取所有的成员变量，不考虑修饰符​FieldgetDeclaredField(Stringname);//获取指定名称的成员变量，不考虑修饰符Classclazz=News.class;System.out.println(clazz.getSimpleName());//获取类名System.out.println(clazz.getName());//获取包名+类名Objectobj=clazz.newInstance();//实例化News的这个对象Tabletable=obj.getClass().getAnnotation(Table.class);//获取obj对象的Table注解，没有返回nullSystem.out.println(table.value());Field[]fields=clazz.getDeclaredFields();for(Fieldfield:fields){field.setAccessible(true);//暴力反射,如果不写这个将会报错//获取属性的注解//Fieldfield1=obj.getClass().getDeclaredField(field.getName());//获取obj对象的指定属性PKpk=field.getAnnotation(PK.class);//获取属性的注解if(pk!=null){System.out.println(field.getName()+&quot;&gt;&gt;&gt;&quot;+pk);//获取属性名称}field.set(obj,null);//给当前clazz对象的field属性赋值为iSystem.out.println(field.get(obj));//输出clazz对象的field的属性值}获取构造方法​Constructor&lt;?&gt;[]getConstructors()​ConstructorgetConstructor(类&lt;?&gt;...parameterTypes)​ConstructorgetDeclaredConstructor(类&lt;?&gt;...parameterTypes)​Constructor&lt;?&gt;[]getDeclaredConstructors()获取成员方法​Method[]getMethods()​MethodgetMethod(Stringname,类&lt;?&gt;...parameterTypes)​Method[]getDeclaredMethods()​MethodgetDeclaredMethod(Stringname,类&lt;?&gt;...parameterTypes)Field：成员变量设置值voidset(Objectobj,Objectvalue)获取值，传的是对象get(Objectobj)忽略访问权限修饰符的安全检查setAccessible(true)Constructor:构造方法创建对象，如果使用空参数构造方法创建对象，操作可以简化：Class对象的newInstance方法TnewInstance(Object...initargs)Method：方法对象执行方法Objectinvoke(Objectobj,Object...args)获取方法名称StringgetName反射获取注解获取obj对象的Table注解，没有返回null，obj是要获取的对象Tabletable=obj.getClass().getAnnotation(Table.class);获取属性的注解，获取obj对象的field.getName()的属性注解Fieldfield1=obj.getClass().getDeclaredField(field.getName());//获取obj对象的指定属性PKpk=field1.getAnnotation(PK.class);//获取属性的注解获取当前调用的方法上的注解StackTraceElement[]stack=newThrowable().getStackTrace();Methodmethod=this.getClass().getMethod(stack[1].getMethodName());//这里0是当前方法的注解，1是调用者方法的注解for(Annotationan:method.getAnnotations()){System.out.println(an);}","link":"https://haohanya.github.io/post/java-fan-she/"},{"title":"FastDFS","content":"什么是FastDFSFastDFS是用c语言编写的一款开源的分布式文件系统。FastDFS为互联网量身定制，充分考虑了冗余备份、负载均衡、线性扩容等机制，并注重高可用、高性能等指标，使用FastDFS很容易搭建一套高性能的文件服务器集群提供文件上传、下载等服务。FastDFS架构包括Trackerserver和Storageserver。客户端请求Trackerserver进行文件上传、下载，通过Trackerserver调度最终由Storageserver完成文件上传和下载。Trackerserver作用是负载均衡和调度，通过Trackerserver在文件上传时可以根据一些策略找到Storageserver提供文件上传服务。可以将tracker称为追踪服务器或调度服务器。Storageserver作用是文件存储，客户端上传的文件最终存储在Storage服务器上，Storageserver没有实现自己的文件系统而是利用操作系统的文件系统来管理文件。可以将storage称为存储服务器。服务端两个角色：Tracker：管理集群，tracker也可以实现集群。每个tracker节点地位平等。收集Storage集群的状态。Storage：实际保存文件Storage分为多个组，每个组之间保存的文件是不同的。每个组内部可以有多个成员，组成员内部保存的内容是一样的，组成员的地位是一致的，没有主从的概念。文件上传流程客户端上传文件后存储服务器将文件ID返回给客户端，此文件ID用于以后访问该文件的索引信息。文件索引信息包括：组名，虚拟磁盘路径，数据两级目录，文件名。组名：文件上传后所在的storage组名称，在文件上传成功后有storage服务器返回，需要客户端自行保存。虚拟磁盘路径：storage配置的虚拟路径，与磁盘选项store_path*对应。如果配置了store_path0则是M00，如果配置了store_path1则是M01，以此类推。数据两级目录：storage服务器在每个虚拟磁盘路径下创建的两级目录，用于存储数据文件。文件名：与文件上传时不同。是由存储服务器根据特定信息生成，文件名包含：源存储服务器IP地址、文件创建时间戳、文件大小、随机数和文件拓展名等信息。文件下载流程0.准备安装包上传到/usr/local/FastDFS_v5.05.tar.gz（FastDFS安装包）libfastcommonV1.0.7.tar.gz（FastDFS依赖程序）nginx-1.8.0.tar.gz（nginx安装包，用于做文件请求http代理服务器）fastdfs-nginx-module_v1.16.tar.gz（nginx和fastdfs的桥梁插件模块）1.安装c/c++编译环境yuminstallgcc-c++2.安装libeventyum-yinstalllibevent3.安装libfastcommon将libfastcommonV1.0.7.tar.gz拷贝至/usr/local/下cd/usr/localtar-zxvflibfastcommonV1.0.7.tar.gzcdlibfastcommon-1.0.7./make.sh./make.shinstallcp/usr/lib64/libfastcommon.so/usr/lib4.创建数据存储目录mkdir-p/home/FastDFS/tracker/home/FastDFS/storage/home/FastDFS/client5.tracker编译安装将FastDFS_v5.05.tar.gz拷贝至/usr/local/下tar-zxvfFastDFS_v5.05.tar.gzcdFastDFS./make.sh./make.shinstallcdconfcp*/etc/fdfs6.编辑/etc/fdfs/tracker.confvi/etc/fdfs/tracker.confbase_path=/home/FastDFS/tracker7.启动tracker/usr/bin/fdfs_trackerd/etc/fdfs/tracker.conf[restart](重启)8.配置storage节点vi/etc/fdfs/storage.confbase_path=/home/FastDFS/storagestore_path0=/home/FastDFS/storagetracker_server=192.168.100.151:221229.启动storage节点/usr/bin/fdfs_storage{fdfs_storaged}/etc/fdfs/storage.conffdfs_storage不存在就使用fdfs_storaged10.安装nginxyuminstall-ygcc-c++(已安装)yuminstall-ypcrepcre-develyuminstall-yzlibzlib-develyuminstall-yopensslopenssl-devel11.解压fastdfs-nginx-module_v1.16.tar.gzcd/usr/local/tar-zxffastdfs-nginx-module_v1.16.tar.gz12.修改fastdfs-nginx-module/src/config配置文件vifastdfs-nginx-module/src/config把CORE_INCS=&quot;$CORE_INCS/usr/local/include/fastdfs/usr/include/fastcommon/&quot;修改为：CORE_INCS=&quot;$CORE_INCS/usr/include/fastdfs/usr/include/fastcommon/&quot;把CORE_LIBS=&quot;$CORE_LIBS-L/usr/local/lib-lfastcommon-lfdfsclient&quot;修改为：CORE_LIBS=&quot;$CORE_LIBS-L/usr/lib-lfastcommon-lfdfsclient&quot;实际就是把路径中的local这一层删除掉13.复制fastdfs-nginx-module/src/mod_fastdfs.conf到/etc/fdfs目录下并编辑cpfastdfs-nginx-module/src/mod_fastdfs.conf/etc/fdfs/vi/etc/fdfs/mod_fastdfs.conftracker_server=192.168.100.151:22122url_have_group_name=truestorage_server_port=23000group_name=group1store_path0=/home/FastDFS/storage14.安装nginxcd/usr/local/tar-zxfnginx-1.8.1.tar.gzcdnginx-1.8.1./configure--add-module=/usr/local/fastdfs-nginx-module/src/makemakeinstall15.配置nginxcd/usr/local/nginx/confvinginx.confserver{listen80;server_namelocalhost;location/group1/M00/{ngx_fastdfs_module;}}重启nginx/usr/local/nginx/sbin/nginx测试引入依赖&lt;!--文件上传组件--&gt;&lt;dependency&gt;&lt;groupId&gt;commons-fileupload&lt;/groupId&gt;&lt;artifactId&gt;commons-fileupload&lt;/artifactId&gt;&lt;version&gt;1.3.1&lt;/version&gt;&lt;/dependency&gt;&lt;!--fastdfs--&gt;&lt;dependency&gt;&lt;groupId&gt;org.csource.fastdfs&lt;/groupId&gt;&lt;artifactId&gt;fastdfs&lt;/artifactId&gt;&lt;version&gt;1.2&lt;/version&gt;&lt;/dependency&gt;编写配置文件&lt;!--配置多媒体解析器--&gt;&lt;beanid=&quot;multipartResolver&quot;class=&quot;org.springframework.web.multipart.commons.CommonsMultipartResolver&quot;&gt;&lt;propertyname=&quot;defaultEncoding&quot;value=&quot;UTF-8&quot;/&gt;&lt;!--设定文件上传的最大值5MB，5*1024*1024--&gt;&lt;propertyname=&quot;maxUploadSize&quot;value=&quot;5242880&quot;/&gt;&lt;/bean&gt;UploadController/***文件服务器地址*/@Value(&quot;${FILE_SERVER_URL}&quot;)privateStringFILE_SERVER_URL;@RequestMapping(&quot;/upload&quot;)publicJdResultupload(MultipartFilefile){//1、取文件的扩展名StringoriginalFilename=file.getOriginalFilename();StringextName=originalFilename.substring(originalFilename.lastIndexOf(&quot;.&quot;)+1);try{//2、创建一个FastDFS的客户端FastDFSClientdfsClient=newFastDFSClient(&quot;classpath:conf/fdfs_client.conf&quot;);//3、执行上传处理Stringpath=dfsClient.uploadFile(file.getBytes(),extName);//4、拼接返回的url和ip地址，拼装成完整的urlStringurl=FILE_SERVER_URL+path;returnJdResult.ok(url);}catch(Exceptione){e.printStackTrace();returnJdResult.error(&quot;文件上传失败&quot;);}}","link":"https://haohanya.github.io/post/FastDFS/"},{"title":"freemarker","content":"1、freemarker入门1.依赖核心包&lt;!--依赖freemarker--&gt;&lt;dependency&gt;&lt;groupId&gt;org.freemarker&lt;/groupId&gt;&lt;artifactId&gt;freemarker&lt;/artifactId&gt;&lt;version&gt;2.3.23&lt;/version&gt;&lt;/dependency&gt;2.创建模板文件&lt;!DOCTYPEhtml&gt;&lt;html&gt;&lt;head&gt;&lt;metacharset=&quot;UTF-8&quot;&gt;&lt;title&gt;这个是模板&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;#--这是我的注释，不会被输出--&gt;hello${name}&lt;/body&gt;&lt;/html&gt;3.生成文件第一步：创建Configuration对象（直接new，在构造方法中添加freemarker的版本号）第二步：设置模板所在的路径第三步：设置模板文件的编码字符集（一般使用utf-8）第四步：加载一个模板，创建一个模板对象第五步：创建数据模型（使用的是Map&lt;String,Object&gt;还可以使用自定义的pojo实际开发中都用map）第六步：创建writer对象，一般用FileWriter对象进行实例化，执行生成的文件第七步：调用模板对象的process方法输出文件第八步：关闭流publicstaticvoidmain(String[]args)throwsException{//1.创建配置类Configurationconfiguration=newConfiguration(Configuration.getVersion());//2.设置模板所在目录configuration.setDirectoryForTemplateLoading(newFile(&quot;F:\\\\workspace002\\\\freemarker-demo01\\\\src\\\\main\\\\resources&quot;));//3.设置编码集configuration.setDefaultEncoding(&quot;UTF-8&quot;);//4.加载模板Templatetemplate=configuration.getTemplate(&quot;hello.html&quot;);//5.创建数据模型Map&lt;String,Object&gt;data=newHashMap&lt;String,Object&gt;();data.put(&quot;name&quot;,&quot;张三&quot;);//6.创建writer对象，准备用来输出文件Writerout=newFileWriter(newFile(&quot;E:\\\\freemarker\\\\hello.html&quot;));//7,输出文件template.process(data,out);//8.关闭流out.close();}FTL指令1.assign作用：用于在页面上定义一个变量&lt;#--assign：用来在页面上定义一个变量--&gt;&lt;#assignname=&quot;张三&quot;&gt;获取变量：${name}&lt;hr/&gt;&lt;#--assign:还可以用来定义一个对象--&gt;&lt;#assigninfo={&quot;name&quot;:&quot;李四&quot;,&quot;age&quot;:18,&quot;hobs&quot;:&quot;java&quot;}&gt;获取到对象的属性:姓名-${info.name},年龄-${info.age},爱好-${info.hobs}2.include作用：此指令用于模板文件之间的相互嵌套&lt;#include&quot;head.ftl&quot;&gt;3.if作用：用于条件判断data.put(&quot;success&quot;,true);&lt;#ifsuccess=true&gt;success的值是true&lt;#else&gt;success的值是false&lt;/#if&gt;4.list作用：在页面中遍历集合&lt;ul&gt;&lt;#listmylistasuser&gt;&lt;li&gt;${user.name}&lt;/li&gt;&lt;/#list&gt;&lt;/ul&gt;5.内建函数语法：变量+?+函数名5-1获取集合的大小(size)${mylist?size}5-2转换json字符串为json对象&lt;#--定义一个json字符串--&gt;&lt;#assigntext=&quot;{'name':'张三','sex':'男'}&quot;&gt;&lt;#--将json字符串转换成json对象--&gt;&lt;#assignperson=text?eval&gt;姓名：${person.name}，性别:${person.sex}5-3日期年月日：${mydate?date}&lt;br/&gt;时分秒：${mydate?time}&lt;br/&gt;年月日时分秒：${mydate?datetime}&lt;br/&gt;自定义日期：${mydate?string('yyyy年MM月dd日hh时mm分ss秒')}5-4数字转换成字符串${mynum?c}6.空值处理6-1处理方案一(缺值表达式)${mytest!&quot;值为null&quot;}&lt;/br&gt;${mytest!}6-2处理方案二&lt;#ifmytest??&gt;mytest值是存在的:${mytest}&lt;#else&gt;mytest的值为null&lt;/#if&gt;7.运算符7-1算术运算符+-*/%7-2逻辑运算符&amp;&amp;、||、!7-3比较运算符=或者==!=&gt;或者是gt&lt;或者是lt&gt;=或者是gte&lt;=或者是lte","link":"https://haohanya.github.io/post/freemarker/"}]}